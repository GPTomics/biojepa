{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe968dc-a937-469a-89d8-7ba179a2e01a",
   "metadata": {},
   "source": [
    "# Bio-JEPA AC \n",
    "\n",
    "Based on [V-JEPA 2 AC](https://arxiv.org/abs/2506.09985)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b67dcd-a768-447b-ad7b-77e8cddd59c0",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "Our goal is to build a World Model for cell biology. In it's current configuration, our model calculates that hitting a cell with a specific gene knockout, or drug if we had it in the dataset, causes specific biological pathways to activate or shut down. Unlike an LLM, this is a predictive simulation that operates entirely within a compressed mathematical space to understand cause and effect.\n",
    "\n",
    "The process begins with the inputs, which feed the model three distinct pieces of information for every training step. \n",
    "\tFirst, it receives the **Before** state, which is data representing a healthy control cell. Instead of a messy list of 20,000 raw gene counts, the tokenizer has already compressed this into a structured set of pathway scores (using [Reactome Pathway 2024 data](https://maayanlab.cloud/Harmonizome/dataset/Reactome+Pathways+2024)). This essentially tells the model that the cell currently has high energy, low stress, and normal growth. \n",
    "\tSecond, the model receives the **Action**, which is the specific perturbation performed in the lab, in our case a CRISPR knockdown of a specific gene. This could also be a drug application or protein introduction if we had the data. This is converted into a learnable \"Action Embedding,\" effectively serving as the command that tells the simulation what event just occurred. \n",
    "\tThird, the model is given the **After** state, which is the actual knockdown cell observed in the experiment. This third input serves purely as the target or \"ground truth\"; the model is not allowed to see it while making its prediction, but uses it afterwards in the loss calculation and backprop.\n",
    "\n",
    "Inside the model, a three-step simulation plays out to process these inputs. It starts with the **Student Encoder**, or the *Perception* module, which looks at the healthy **Before** cellinput  and compresses it into a Latent State. At this stage, the model is simply understanding the baseline biological status of the cell. This latent representation is then passed to the **Action-Conditioned Predictor**, which acts as the *Physics Engine.* This component combines the cell's current state with the Action vector. Using a mechanism called Adaptive Layer Normalization (AdaLN), the action actually modulates the internal weights of the neural network, effectively shifting the physical rules of the simulation to match the drug's effects. The **Predictor** then tries to predict, or hellucinate, what the future state of the cell will be, calculating a new vector that represents the cell's condition after the knockout, or drug impact. \n",
    "\n",
    "To validate the predictor, simultaneously the **Teacher Encoder** looks at the real **After** data from the lab and encodes it into that same latent space to serve as the judge. To learn, the model compares the predictor output against the Teacher's reality. With backprop, we attempt to minimize the difference between the prediction and the actual outcome, trying to minimize this error over millions of examples. \n",
    "\n",
    "In theory, by forcing its predictions to match reality, the model moves beyond simply memorizing data and begins to learn the underlying causal rules of biology. It figures out gene regulatory logicâ€”understanding that if Gene A is knocked down, Pathway B must functionally fail. It learns how different pathways, like inflammation and cell death, are causally linked. Ultimately, we hope it learns the \"physics\" of how perturbations work, allowing us to eventually simulate the effects of gene mutations, drugs or genetic interventions on cells without having to perform the physical experiment in a wet lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a357f2-d497-4dfc-9920-568422b5403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9242cf00-c812-41d0-ae92-9c7dd0af6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158bffc-f24a-4471-a463-7241c2ad6784",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "### ROTARY POSITIONAL EMBEDDINGS (RoPE)\n",
    "V-JEPA 2 uses 3D-RoPE. We adapt this to 1D-RoPE for our list of Pathway Tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ffafca-b99d-4cde-884f-a6347c5eafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len=2048):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        t = torch.arange(max_seq_len).type_as(inv_freq)\n",
    "        freqs = torch.einsum('i,j->ij', t, inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer('emb', emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Seq, Dim]\n",
    "        # returns cos, sin for the sequence length of x\n",
    "        n = x.shape[1]\n",
    "        return self.emb[:n, :].cos(), self.emb[:n, :].sin()\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    # Standard RoPE rotation\n",
    "    # split x into half\n",
    "    d = x.shape[-1] // 2\n",
    "    x1, x2 = x[..., :d], x[..., d:]\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    return (x * cos) + (rotated * sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b51720-0b30-466c-b5ea-5cac69175e1e",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "### COMPONENT 1: THE ENCODER (STUDENT/TEACHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602e56c8-779a-4cab-a23e-a360682aa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioEncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, int(dim * mlp_ratio)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(int(dim * mlp_ratio), dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cos, sin):\n",
    "        # 1. Attention with RoPE\n",
    "        x_norm = self.norm1(x)\n",
    "        \n",
    "        # Apply RoPE to queries and keys inside attention? \n",
    "        # For simplicity in standard PyTorch MHA, we apply it to x before attention\n",
    "        # (Technically RoPE is applied to Q and K inside, but this approximation works \n",
    "        # if we treat x as the carrier of position).\n",
    "        # STRICT IMPLEMENTATION: manually project Q,K,V, apply RoPE to Q,K, then Attn.\n",
    "        # We will use the simplified \"Inject Position\" approach for readability here.\n",
    "        x_rope = apply_rotary_pos_emb(x_norm, cos, sin)\n",
    "        \n",
    "        attn_out, _ = self.attn(x_rope, x_rope, x_norm) # V is not rotated usually\n",
    "        x = x + attn_out\n",
    "        \n",
    "        # 2. MLP\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32aadea7-3614-4d4e-afe7-812fb0e21551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathwayEncoder(nn.Module):\n",
    "    def __init__(self, num_pathways=1024, embed_dim=384, depth=12, heads=2):\n",
    "        super().__init__()\n",
    "        # Input: [Batch, Pathways] (Float) -> Project to [Batch, Pathways, Dim]\n",
    "        self.input_proj = nn.Linear(1, embed_dim)\n",
    "        \n",
    "        self.rope = RotaryEmbedding(embed_dim // heads * heads) # Ensure divisibility\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            BioEncoderBlock(embed_dim, heads) for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Num_Pathways]\n",
    "        x = x.unsqueeze(-1) # [B, N, 1]\n",
    "        x = self.input_proj(x) # [B, N, Dim]\n",
    "        \n",
    "        # Generate RoPE cache\n",
    "        cos, sin = self.rope(x)\n",
    "        cos, sin = cos.to(x.device), sin.to(x.device)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x, cos, sin)\n",
    "            \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64874bc-9e76-4715-bee3-08fd86598823",
   "metadata": {},
   "source": [
    "### COMPONENT 2: ACTION-CONDITIONED PREDICTOR (AdaLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce1c88f-fb19-4084-96fa-520202fe783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLN(nn.Module):\n",
    "    \"\"\"\n",
    "    V-JEPA 2 / DiT Style Conditioning.\n",
    "    The action vector regresses the Scale (gamma) and Shift (beta) of the normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embed_dim, elementwise_affine=False)\n",
    "        self.action_mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(action_dim, 2 * embed_dim)\n",
    "        )\n",
    "        # Initialize to identity (gamma=0, beta=0 originally, effectively gamma=1 after logic)\n",
    "        # Standard practice: zero-init the last layer so action starts as \"no-op\"\n",
    "        nn.init.zeros_(self.action_mlp[1].weight)\n",
    "        nn.init.zeros_(self.action_mlp[1].bias)\n",
    "\n",
    "    def forward(self, x, action_emb):\n",
    "        # action_emb: [Batch, Action_Dim]\n",
    "        style = self.action_mlp(action_emb).unsqueeze(1) # [B, 1, 2*D]\n",
    "        gamma, beta = style.chunk(2, dim=-1)\n",
    "        return self.norm(x) * (1 + gamma) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec41393d-a173-4ce6-9894-4c8684dd913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, action_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 4 * dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * dim, dim)\n",
    "        )\n",
    "        self.ada_ln1 = AdaLN(dim, action_dim)\n",
    "        self.ada_ln2 = AdaLN(dim, action_dim)\n",
    "\n",
    "    def forward(self, x, action_emb, cos, sin):\n",
    "        # AdaLN -> Attn (with RoPE) -> Residual\n",
    "        x_norm = self.ada_ln1(x, action_emb)\n",
    "        \n",
    "        # Apply RoPE to Q, K\n",
    "        x_rope = apply_rotary_pos_emb(x_norm, cos, sin)\n",
    "        \n",
    "        attn_out, _ = self.attn(x_rope, x_rope, x_norm) \n",
    "        x = x + attn_out\n",
    "        \n",
    "        # AdaLN -> MLP -> Residual\n",
    "        x_norm = self.ada_ln2(x, action_emb)\n",
    "        x = x + self.mlp(x_norm)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53d09da-e83a-480a-9ccb-1c6159b567a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACPredictor(nn.Module):\n",
    "    def __init__(self, embed_dim=384, action_dim=256, depth=6, heads=2, num_pathways=1024):\n",
    "        super().__init__()\n",
    "        self.num_pathways = num_pathways\n",
    "        \n",
    "        # Action Embedding (Discrete ID -> Vector)\n",
    "        # We assume action_ids are passed in\n",
    "        self.action_embed = nn.Embedding(3000, action_dim) # 3000 max perturbations\n",
    "        \n",
    "        # Learnable Queries (The \"Mask Tokens\" for the future state)\n",
    "        # We learn one query vector per pathway position\n",
    "        self.mask_queries = nn.Parameter(torch.randn(1, num_pathways, embed_dim) * 0.02)\n",
    "        \n",
    "        self.rope = RotaryEmbedding(embed_dim)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            PredictorBlock(embed_dim, heads, action_dim) for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = AdaLN(embed_dim, action_dim)\n",
    "\n",
    "    def forward(self, context_latents, action_ids):\n",
    "        \"\"\"\n",
    "        context_latents: [Batch, N, Dim] (From Student Encoder)\n",
    "        action_ids: [Batch] (Ints)\n",
    "        \"\"\"\n",
    "        B, N, D = context_latents.shape\n",
    "        \n",
    "        # 1. Embed Action\n",
    "        action_emb = self.action_embed(action_ids) # [B, Action_Dim]\n",
    "        \n",
    "        # 2. Construct Input: Context + Mask Queries\n",
    "        # In V-JEPA, the predictor takes the context AND the queries for what to predict.\n",
    "        # Since we are predicting the *entire* next state (Treated), we concatenate:\n",
    "        # [Context_State (RoPE pos 0..N), Mask_Queries (RoPE pos N..2N)]\n",
    "        # However, for biological simplicity, we can just treat this as a transformation:\n",
    "        # We want to transform Context -> Predicted Target.\n",
    "        \n",
    "        # STRICT V-JEPA APPROACH:\n",
    "        # The predictor runs on the Queries, attending to the Context.\n",
    "        # It does NOT process the context deeply again.\n",
    "        \n",
    "        queries = self.mask_queries.repeat(B, 1, 1) # [B, N, D]\n",
    "        \n",
    "        # We concat for attention purposes (Cross-attention is cleaner, but V-JEPA uses single stream)\n",
    "        # Input Sequence: [Context, Queries]\n",
    "        sequence = torch.cat([context_latents, queries], dim=1)\n",
    "        \n",
    "        # RoPE: Need to handle the extended sequence length (2N)\n",
    "        cos, sin = self.rope(sequence)\n",
    "        cos, sin = cos.to(sequence.device), sin.to(sequence.device)\n",
    "        \n",
    "        # 3. Pass through AdaLN Blocks\n",
    "        for block in self.blocks:\n",
    "            sequence = block(sequence, action_emb, cos, sin)\n",
    "            \n",
    "        sequence = self.final_norm(sequence, action_emb)\n",
    "        \n",
    "        # 4. Return only the predicted part (The Queries)\n",
    "        # We discard the processed context\n",
    "        predictions = sequence[:, N:, :] \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb48919-caa3-4d81-93d0-dca2d4d30f96",
   "metadata": {},
   "source": [
    "## Bio-JEPA AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16297aa1-3670-4b89-9e3a-19cfab546ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioVJepa2(nn.Module):\n",
    "    def __init__(self, num_pathways=1024, embed_dim=384):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.student = PathwayEncoder(num_pathways, embed_dim)\n",
    "        self.teacher = copy.deepcopy(self.student)\n",
    "        \n",
    "        # Freeze teacher\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.predictor = ACPredictor(embed_dim=embed_dim, action_dim=256, num_pathways=num_pathways)\n",
    "        \n",
    "    def forward(self, x_control, x_treated, action_id):\n",
    "        # 1. Teacher encodes the Target (Treated)\n",
    "        with torch.no_grad():\n",
    "            target_latents = self.teacher(x_treated)\n",
    "            \n",
    "        # 2. Student encodes the Context (Control)\n",
    "        # (Optional: Add masking here if you want extra difficulty, \n",
    "        # but the task Control->Treated is already hard enough)\n",
    "        context_latents = self.student(x_control)\n",
    "        \n",
    "        # 3. Predictor tries to guess Target given Context + Action\n",
    "        predicted_latents = self.predictor(context_latents, action_id)\n",
    "        \n",
    "        # 4. Latent Loss (L1)\n",
    "        loss = F.l1_loss(predicted_latents, target_latents)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_teacher(self, m=0.996):\n",
    "        for param_s, param_t in zip(self.student.parameters(), self.teacher.parameters()):\n",
    "            param_t.data.mul_(m).add_((1 - m) * param_s.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbd6fb-ec72-4af9-ba48-13d7731c3343",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96184936-3410-4d44-8be1-e01ed3c7cc9e",
   "metadata": {},
   "source": [
    "#### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6dfbb5f-2a56-4709-a9a2-9ab3fe0973a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa')\n",
    "shard_dir = data_dir / 'tokenized'\n",
    "metadata_path = data_dir / 'perturbation_map.json'\n",
    "checkpoint_dir = data_dir / 'checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7885c628-45b4-4c23-97e5-e3ee6f0400e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "# Steps/epoch = 29 (files) *10000 (chunk size) /8 (batch size) \n",
    "epoch_steps = 150\n",
    "n_embd = 8\n",
    "n_pathways = 1024\n",
    "LR = 1e-3\n",
    "EPOCHS = 4\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "QUANTIZATION_MAX = 20.0 # Must match tokenizer\n",
    "tok_file_chunk_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a1967a-562d-4772-904a-d1092ba2cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedShardDataset(Dataset):\n",
    "    def __init__(self, shard_dir):\n",
    "        self.files = sorted(shard_dir.glob('*.npz'))\n",
    "        print(f'Found {len(self.files)} shards.')\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Approx length for progress bar (10k per shard)\n",
    "        return len(self.files) * tok_file_chunk_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Stochastic loading: Pick random shard, then random row\n",
    "        # This avoids loading 100MB files for just one item in strict order\n",
    "        file_path = self.files[np.random.randint(len(self.files))]\n",
    "        \n",
    "        # Load shard (fast if on SSD)\n",
    "        try:\n",
    "            with np.load(file_path) as data:\n",
    "                # Keys: 'control', 'treated', 'action_ids'\n",
    "                n_rows = data['action_ids'].shape[0]\n",
    "                row_idx = np.random.randint(n_rows)\n",
    "                \n",
    "                c_raw = data['control'][row_idx]\n",
    "                t_raw = data['treated'][row_idx]\n",
    "                act_id = data['action_ids'][row_idx]\n",
    "        except Exception as e:\n",
    "            # Fallback for corrupt shard\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return self.__getitem__(0)\n",
    "\n",
    "        # Dequantize\n",
    "        scale = QUANTIZATION_MAX / (2**32 - 1)\n",
    "        x_control = torch.tensor(c_raw.astype(np.float32) * scale)\n",
    "        x_treated = torch.tensor(t_raw.astype(np.float32) * scale)\n",
    "        action_id = torch.tensor(act_id, dtype=torch.long)\n",
    "        \n",
    "        return x_control, x_treated, action_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0202749-f533-40fd-a891-08f9c9ff8edb",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "723366c9-4869-408a-b1bc-f2dba2f913ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BioVJepa2(num_pathways=n_pathways, embed_dim=n_embd).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff27eb-93fa-439c-a31d-366dff143d7d",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ff8ba83-7ff9-4a99-92c7-1fec94759781",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57196ead-30ec-4098-a645-9ec7bdf3a300",
   "metadata": {},
   "source": [
    "#### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e95819c7-d216-4a1b-93cc-467a20311ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LR, steps_per_epoch=epoch_steps, epochs=EPOCHS, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f022bc1-b281-4ba4-a38a-5c245ce354df",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "037e931a-d57a-4e2a-b7e1-349126321bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 shards.\n"
     ]
    }
   ],
   "source": [
    "dataset = PairedShardDataset(shard_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69bfd331-4e87-4957-8ff9-94fe5d1233c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89952bd9-d632-44db-ae1e-0063389ff31f",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62bc4b56-b682-4b56-922e-ef040ab8d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96cee680-aa5a-464f-99ef-27b5c758d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 0 | Loss: 1.56848 | LR: 4.28e-05\n",
      "Epoch 0 | Step 10 | Loss: 1.08972 | LR: 3.42e-04\n",
      "Epoch 0 | Step 20 | Loss: 0.39926 | LR: 8.31e-04\n",
      "Epoch 0 | Step 30 | Loss: 0.14334 | LR: 1.00e-03\n",
      "Epoch 0 | Step 40 | Loss: 0.10633 | LR: 9.99e-04\n",
      "Epoch 0 | Step 50 | Loss: 0.10266 | LR: 9.96e-04\n",
      "Epoch 0 | Step 60 | Loss: 0.11970 | LR: 9.92e-04\n",
      "Epoch 0 | Step 70 | Loss: 0.10585 | LR: 9.87e-04\n",
      "Epoch 0 | Step 80 | Loss: 0.08833 | LR: 9.80e-04\n",
      "Epoch 0 | Step 90 | Loss: 0.09671 | LR: 9.71e-04\n",
      "Epoch 0 | Step 100 | Loss: 0.08971 | LR: 9.61e-04\n",
      "Epoch 0 | Step 110 | Loss: 0.08205 | LR: 9.50e-04\n",
      "Epoch 0 | Step 120 | Loss: 0.08740 | LR: 9.37e-04\n",
      "Epoch 0 | Step 130 | Loss: 0.08190 | LR: 9.23e-04\n",
      "Epoch 0 | Step 140 | Loss: 0.08963 | LR: 9.08e-04\n",
      "Epoch 0 | Step 150 | Loss: 0.07945 | LR: 8.91e-04\n",
      "=== Epoch 0 Done. Avg Loss: 0.24476 ===\n",
      "Epoch 1 | Step 0 | Loss: 0.08357 | LR: 8.89e-04\n",
      "Epoch 1 | Step 10 | Loss: 0.08154 | LR: 8.72e-04\n",
      "Epoch 1 | Step 20 | Loss: 0.08390 | LR: 8.53e-04\n",
      "Epoch 1 | Step 30 | Loss: 0.08734 | LR: 8.33e-04\n",
      "Epoch 1 | Step 40 | Loss: 0.06638 | LR: 8.11e-04\n",
      "Epoch 1 | Step 50 | Loss: 0.07266 | LR: 7.89e-04\n",
      "Epoch 1 | Step 60 | Loss: 0.06560 | LR: 7.67e-04\n",
      "Epoch 1 | Step 70 | Loss: 0.06760 | LR: 7.43e-04\n",
      "Epoch 1 | Step 80 | Loss: 0.06988 | LR: 7.18e-04\n",
      "Epoch 1 | Step 90 | Loss: 0.06273 | LR: 6.93e-04\n",
      "Epoch 1 | Step 100 | Loss: 0.06681 | LR: 6.68e-04\n",
      "Epoch 1 | Step 110 | Loss: 0.05983 | LR: 6.41e-04\n",
      "Epoch 1 | Step 120 | Loss: 0.05271 | LR: 6.15e-04\n",
      "Epoch 1 | Step 130 | Loss: 0.05919 | LR: 5.88e-04\n",
      "Epoch 1 | Step 140 | Loss: 0.05531 | LR: 5.60e-04\n",
      "Epoch 1 | Step 150 | Loss: 0.04307 | LR: 5.33e-04\n",
      "=== Epoch 1 Done. Avg Loss: 0.06639 ===\n",
      "Epoch 2 | Step 0 | Loss: 0.04856 | LR: 5.30e-04\n",
      "Epoch 2 | Step 10 | Loss: 0.04988 | LR: 5.03e-04\n",
      "Epoch 2 | Step 20 | Loss: 0.04807 | LR: 4.75e-04\n",
      "Epoch 2 | Step 30 | Loss: 0.04193 | LR: 4.48e-04\n",
      "Epoch 2 | Step 40 | Loss: 0.04469 | LR: 4.20e-04\n",
      "Epoch 2 | Step 50 | Loss: 0.03513 | LR: 3.93e-04\n",
      "Epoch 2 | Step 60 | Loss: 0.03507 | LR: 3.67e-04\n",
      "Epoch 2 | Step 70 | Loss: 0.03229 | LR: 3.40e-04\n",
      "Epoch 2 | Step 80 | Loss: 0.03007 | LR: 3.14e-04\n",
      "Epoch 2 | Step 90 | Loss: 0.03401 | LR: 2.89e-04\n",
      "Epoch 2 | Step 100 | Loss: 0.02996 | LR: 2.64e-04\n",
      "Epoch 2 | Step 110 | Loss: 0.02687 | LR: 2.41e-04\n",
      "Epoch 2 | Step 120 | Loss: 0.02722 | LR: 2.17e-04\n",
      "Epoch 2 | Step 130 | Loss: 0.02687 | LR: 1.95e-04\n",
      "Epoch 2 | Step 140 | Loss: 0.02561 | LR: 1.74e-04\n",
      "Epoch 2 | Step 150 | Loss: 0.03129 | LR: 1.53e-04\n",
      "=== Epoch 2 Done. Avg Loss: 0.03654 ===\n",
      "Epoch 3 | Step 0 | Loss: 0.02845 | LR: 1.51e-04\n",
      "Epoch 3 | Step 10 | Loss: 0.02285 | LR: 1.32e-04\n",
      "Epoch 3 | Step 20 | Loss: 0.02824 | LR: 1.14e-04\n",
      "Epoch 3 | Step 30 | Loss: 0.02694 | LR: 9.71e-05\n",
      "Epoch 3 | Step 40 | Loss: 0.02609 | LR: 8.14e-05\n",
      "Epoch 3 | Step 50 | Loss: 0.02217 | LR: 6.70e-05\n",
      "Epoch 3 | Step 60 | Loss: 0.02415 | LR: 5.39e-05\n",
      "Epoch 3 | Step 70 | Loss: 0.02060 | LR: 4.21e-05\n",
      "Epoch 3 | Step 80 | Loss: 0.01906 | LR: 3.17e-05\n",
      "Epoch 3 | Step 90 | Loss: 0.02090 | LR: 2.28e-05\n",
      "Epoch 3 | Step 100 | Loss: 0.02296 | LR: 1.53e-05\n",
      "Epoch 3 | Step 110 | Loss: 0.01981 | LR: 9.28e-06\n",
      "Epoch 3 | Step 120 | Loss: 0.02346 | LR: 4.74e-06\n",
      "Epoch 3 | Step 130 | Loss: 0.02194 | LR: 1.71e-06\n",
      "Epoch 3 | Step 140 | Loss: 0.02472 | LR: 1.94e-07\n",
      "Epoch 3 | Step 150 | Loss: 0.02855 | LR: 1.16e-08\n",
      "=== Epoch 3 Done. Avg Loss: 0.02367 ===\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # We manually limit steps per epoch to avoid iterating infinite stochastic loader\n",
    "    # or just iterate a fixed number of batches\n",
    "    for i, (xc, xt, aid) in enumerate(loader):\n",
    "        xc, xt, aid = xc.to(DEVICE), xt.to(DEVICE), aid.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model(xc, xt, aid)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Teacher (V-JEPA Momentum)\n",
    "        model.update_teacher(m=0.996)\n",
    "\n",
    "        if scheduler.last_epoch < scheduler.total_steps:\n",
    "            scheduler.step()\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {i} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "        \n",
    "        if i >= epoch_steps: # End epoch after 2000 batches\n",
    "            break\n",
    "            \n",
    "    avg_loss = total_loss / epoch_steps\n",
    "    \n",
    "    print(f\"=== Epoch {epoch} Done. Avg Loss: {avg_loss:.5f} ===\")\n",
    "    \n",
    "    # Save Checkpoint\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_dir / f'bio_jepa_ckpt_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972cdbf-7fd0-4b3b-a541-16135d079c2c",
   "metadata": {},
   "source": [
    "#### Training Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43c293fa-2067-45b9-ad55-e6127515bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fe89a-0447-48d3-9252-9153efcab902",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "45916c9b-5f07-4aec-a9ac-e0635bae92a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/djemec/data/jepa/perturbation_map.json'),\n",
       " PosixPath('/Users/djemec/data/jepa/tokenized'))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path, shard_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54c35355-2ff6-486d-9ce8-e4cbbbee1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Map (ID -> Name)\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    pert_map = json.load(f)\n",
    "# Invert map to: ID -> Name\n",
    "id_to_name = {v: k for k, v in pert_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24ae854c-4e74-42f5-9cfd-0c487ff22549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BioVJepa2(\n",
       "  (student): PathwayEncoder(\n",
       "    (input_proj): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (rope): RotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x BioEncoderBlock(\n",
       "        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (teacher): PathwayEncoder(\n",
       "    (input_proj): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (rope): RotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x BioEncoderBlock(\n",
       "        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (predictor): ACPredictor(\n",
       "    (action_embed): Embedding(3000, 256)\n",
       "    (rope): RotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x PredictorBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "        (ada_ln1): AdaLN(\n",
       "          (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=False)\n",
       "          (action_mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ada_ln2): AdaLN(\n",
       "          (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=False)\n",
       "          (action_mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): AdaLN(\n",
       "      (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=False)\n",
       "      (action_mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09550430-309d-436c-a140-2bda3fb8bde3",
   "metadata": {},
   "source": [
    "**Get random data sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "189729ef-8852-466c-b05b-455948aa6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_test_pair(shard_dir):\n",
    "    '''Grab a single real pair from a random shard'''\n",
    "    files = sorted(shard_dir.glob('*.npz'))\n",
    "    file_path = files[np.random.randint(len(files))]\n",
    "    \n",
    "    with np.load(file_path) as data:\n",
    "        idx = np.random.randint(data['action_ids'].shape[0])\n",
    "        \n",
    "        # Extract raw uint32\n",
    "        c_raw = data['control'][idx]\n",
    "        t_raw = data['treated'][idx]\n",
    "        act_id = data['action_ids'][idx]\n",
    "        \n",
    "    # Dequantize\n",
    "    scale = QUANTIZATION_MAX / (2**32 - 1)\n",
    "    x_control = torch.tensor(c_raw.astype(np.float32) * scale).unsqueeze(0).to(DEVICE) # [1, 1024]\n",
    "    x_treated = torch.tensor(t_raw.astype(np.float32) * scale).unsqueeze(0).to(DEVICE)\n",
    "    action_id = torch.tensor([act_id], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    return x_control, x_treated, action_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "793361fe-baee-42b7-982d-72e604d28013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NSRP1'"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_control, x_real_treated, action_id = get_random_test_pair(shard_dir)\n",
    "pert_name = id_to_name[action_id.item()]\n",
    "pert_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "75e32d24-4c56-40fc-9d76-3048536eddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get Baselines (Teacher View)\n",
    "# We need the Teacher to tell us where the \"Control\" and \"Real Treated\" \n",
    "# sit in the abstract latent space.\n",
    "with torch.no_grad():\n",
    "    z_control = model.teacher(x_control)       # Where the cell started\n",
    "    z_real = model.teacher(x_real_treated)     # Where the cell actually went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "054228e3-73d0-48da-9b7f-2f80be87cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run The Physics Engine (Predictor)\n",
    "# Student encodes context -> Predictor adds Action -> Output\n",
    "with torch.no_grad():\n",
    "    z_context = model.student(x_control)\n",
    "    z_predicted = model.predictor(z_context, action_id) # Where the model thinks it went"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5360c5-2215-4fc8-858a-d1488cf54ab6",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "49851bf2-12f7-4de4-9b3f-efbd1bac2c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0411173477768898"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric 1: Baseline Drift (How much did the drug actually change the cell?)\n",
    "# If this is 0, the drug did nothing, so prediction is trivial.\n",
    "drift = F.l1_loss(z_control, z_real).item()\n",
    "drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "19a65de9-8f27-4f96-b304-07272e5367f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.035973504185676575"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric 2: Prediction Error (How close is our guess to the real result?)\n",
    "error = F.l1_loss(z_predicted, z_real).item()\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "00cbe219-8cfa-4d15-a09f-999de53f87bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02348235994577408"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric 3: Simulation Magnitude (How much did our model decide to move the cell?)\n",
    "sim_move = F.l1_loss(z_predicted, z_control).item()\n",
    "sim_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cdb7a8ae-c7ac-4bf5-8aca-ca82af1f57fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result Interpretation]\n",
      "âœ… SUCCESS: The model predicted the state shift!\n",
      "   The prediction is 12.5% closer to the truth than the Control state was.\n"
     ]
    }
   ],
   "source": [
    "# --- INTERPRETATION ---\n",
    "print(f\"[Result Interpretation]\")\n",
    "if drift < 0.01:\n",
    "    print(f\"âš ï¸  WEAK SIGNAL: This perturbation didn't change the cell much in reality.\")\n",
    "elif error < drift:\n",
    "    improvement = (1 - (error / drift)) * 100\n",
    "    print(f\"âœ… SUCCESS: The model predicted the state shift!\")\n",
    "    print(f\"   The prediction is {improvement:.1f}% closer to the truth than the Control state was.\")\n",
    "else:\n",
    "    print(f\"âŒ FAILURE: The model failed to capture the dynamics.\")\n",
    "    print(f\"   It would have been better to just guess 'Nothing Happened'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "03a7c686-6b68-4975-add4-f8178fdf3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Top Active Latent Dimensions]\n",
      "Dimensions [[6, 3, 2, 5, 1], [0, 2, 3, 5, 1], [6, 5, 3, 2, 1], [5, 0, 2, 1, 7], [6, 3, 5, 1, 7], [3, 2, 6, 7, 5], [2, 1, 5, 3, 0], [2, 3, 1, 6, 0], [3, 0, 1, 6, 5], [3, 0, 1, 6, 2], [6, 3, 1, 2, 5], [3, 7, 5, 6, 2], [6, 5, 3, 7, 1], [5, 6, 7, 3, 1], [6, 3, 5, 1, 2], [6, 3, 5, 7, 1], [6, 5, 3, 7, 1], [6, 5, 3, 7, 1], [6, 5, 3, 7, 1], [6, 3, 4, 2, 5], [3, 5, 7, 6, 2], [2, 1, 3, 6, 0], [2, 6, 3, 1, 5], [6, 5, 3, 4, 7], [3, 5, 7, 6, 2], [3, 7, 5, 6, 2], [2, 1, 5, 3, 0], [1, 3, 0, 2, 6], [3, 6, 5, 1, 7], [3, 6, 5, 7, 1], [2, 7, 5, 1, 0], [0, 3, 7, 2, 1], [0, 2, 1, 3, 7], [2, 6, 3, 5, 4], [2, 1, 7, 5, 0], [5, 2, 7, 3, 6], [2, 5, 7, 3, 1], [5, 3, 7, 6, 4], [5, 6, 7, 3, 1], [2, 1, 5, 3, 0], [5, 6, 3, 7, 1], [3, 5, 1, 6, 2], [5, 7, 6, 3, 2], [2, 5, 1, 0, 7], [3, 2, 0, 4, 1], [2, 3, 0, 1, 4], [6, 2, 3, 0, 1], [3, 0, 7, 6, 1], [6, 5, 3, 7, 2], [3, 5, 7, 0, 1], [0, 3, 7, 4, 2], [2, 1, 0, 5, 7], [3, 0, 5, 7, 4], [2, 3, 0, 1, 5], [3, 0, 1, 2, 6], [2, 1, 0, 3, 5], [2, 0, 5, 1, 3], [3, 0, 7, 4, 2], [6, 4, 3, 0, 2], [2, 5, 7, 1, 0], [3, 1, 2, 6, 0], [5, 2, 0, 1, 7], [5, 2, 0, 1, 7], [3, 0, 1, 2, 5], [2, 5, 1, 0, 7], [2, 5, 7, 1, 0], [0, 3, 5, 2, 1], [5, 7, 2, 3, 6], [3, 2, 6, 5, 7], [3, 0, 1, 2, 6], [2, 1, 3, 0, 5], [2, 6, 1, 3, 0], [6, 2, 3, 1, 0], [2, 5, 1, 3, 0], [6, 3, 2, 1, 7], [0, 3, 2, 5, 6], [2, 6, 0, 3, 1], [0, 3, 2, 5, 7], [3, 1, 0, 6, 7], [3, 2, 1, 0, 6], [3, 5, 7, 6, 2], [3, 7, 5, 6, 1], [6, 3, 2, 5, 1], [0, 7, 2, 5, 3], [3, 1, 6, 5, 7], [3, 2, 0, 7, 6], [3, 5, 7, 6, 2], [5, 3, 7, 6, 1], [3, 0, 1, 6, 4], [6, 5, 3, 7, 1], [3, 6, 1, 5, 2], [3, 5, 7, 2, 6], [5, 3, 7, 6, 1], [3, 6, 5, 7, 1], [6, 5, 3, 7, 1], [2, 0, 3, 1, 5], [3, 2, 6, 4, 0], [5, 3, 6, 7, 1], [2, 1, 5, 7, 6], [2, 1, 3, 0, 7], [5, 7, 3, 6, 2], [3, 0, 5, 4, 1], [5, 3, 7, 2, 0], [2, 6, 3, 1, 5], [2, 6, 3, 1, 0], [5, 7, 3, 6, 2], [0, 6, 5, 2, 7], [0, 3, 2, 4, 6], [0, 3, 4, 2, 6], [3, 5, 7, 6, 4], [6, 5, 3, 7, 2], [5, 7, 3, 6, 2], [6, 5, 3, 7, 2], [5, 7, 3, 2, 6], [3, 7, 5, 4, 2], [5, 6, 7, 2, 3], [6, 5, 3, 7, 1], [6, 5, 3, 4, 7], [3, 6, 7, 5, 2], [2, 3, 6, 5, 1], [3, 2, 5, 6, 4], [5, 6, 3, 7, 2], [1, 0, 2, 5, 3], [6, 3, 5, 2, 7], [3, 0, 2, 1, 6], [3, 0, 7, 5, 4], [2, 3, 6, 1, 0], [0, 3, 2, 6, 7], [6, 3, 5, 1, 2], [3, 1, 6, 0, 7], [0, 3, 2, 1, 5], [3, 0, 1, 6, 7], [3, 0, 1, 4, 7], [6, 3, 4, 2, 5], [6, 5, 7, 1, 2], [3, 1, 6, 2, 0], [3, 7, 5, 6, 0], [3, 7, 5, 6, 0], [3, 0, 6, 4, 7], [3, 7, 5, 2, 0], [0, 3, 6, 2, 5], [3, 0, 6, 2, 7], [3, 6, 2, 1, 0], [3, 7, 6, 5, 1], [0, 7, 3, 1, 5], [5, 3, 6, 7, 1], [3, 0, 7, 5, 6], [2, 5, 7, 1, 6], [5, 2, 7, 3, 6], [3, 7, 5, 6, 0], [3, 0, 1, 6, 4], [2, 3, 1, 6, 0], [3, 0, 6, 4, 7], [6, 5, 3, 1, 7], [3, 5, 2, 7, 6], [5, 6, 3, 7, 1], [3, 5, 7, 6, 4], [5, 3, 7, 6, 4], [3, 5, 7, 4, 6], [3, 0, 5, 6, 4], [2, 0, 3, 1, 7], [5, 3, 7, 6, 2], [0, 3, 6, 2, 4], [3, 0, 4, 5, 7], [3, 5, 7, 0, 4], [5, 3, 4, 0, 6], [3, 5, 7, 0, 6], [3, 5, 6, 2, 7], [3, 5, 7, 0, 6], [0, 3, 2, 7, 6], [3, 5, 7, 4, 0], [2, 0, 1, 3, 4], [3, 7, 5, 4, 0], [5, 3, 7, 6, 2], [0, 3, 7, 2, 5], [3, 5, 7, 0, 4], [2, 3, 6, 1, 0], [6, 0, 4, 2, 3], [5, 7, 3, 2, 6], [3, 0, 2, 1, 6], [3, 7, 0, 5, 6], [3, 1, 0, 2, 5], [2, 3, 4, 0, 6], [3, 5, 4, 6, 0], [0, 2, 7, 1, 5], [3, 0, 5, 6, 7], [0, 3, 1, 2, 6], [3, 0, 1, 6, 5], [3, 5, 7, 6, 2], [6, 5, 3, 7, 1], [3, 5, 6, 7, 1], [1, 2, 3, 6, 0], [3, 1, 6, 0, 5], [2, 6, 3, 1, 5], [3, 5, 7, 6, 1], [3, 1, 6, 0, 2], [3, 7, 6, 5, 0], [3, 1, 6, 5, 2], [3, 1, 6, 2, 0], [2, 5, 7, 3, 6], [6, 3, 1, 5, 2], [3, 6, 5, 7, 1], [6, 5, 3, 7, 1], [6, 4, 3, 1, 0], [3, 6, 1, 0, 2], [3, 7, 5, 6, 0], [6, 3, 4, 2, 1], [3, 6, 5, 7, 1], [5, 7, 2, 3, 1], [6, 3, 1, 2, 5], [5, 3, 7, 2, 6], [3, 0, 2, 6, 7], [3, 0, 6, 1, 2], [3, 0, 1, 6, 4], [3, 4, 6, 0, 5], [3, 6, 5, 4, 1], [3, 6, 2, 5, 4], [2, 6, 5, 0, 7], [2, 5, 7, 0, 6], [3, 5, 7, 6, 4], [2, 3, 0, 4, 1], [3, 5, 4, 7, 6], [0, 3, 1, 2, 7], [2, 1, 5, 7, 0], [0, 7, 3, 1, 6], [3, 5, 7, 6, 2], [0, 2, 1, 3, 7], [0, 2, 7, 3, 6], [3, 5, 6, 1, 4], [3, 0, 1, 6, 4], [3, 5, 7, 0, 6], [3, 0, 1, 2, 6], [2, 5, 1, 0, 7], [3, 5, 0, 4, 7], [0, 3, 2, 4, 1], [0, 7, 1, 2, 5], [3, 0, 7, 6, 5], [0, 7, 5, 1, 2], [0, 2, 3, 1, 4], [3, 1, 4, 0, 6], [6, 5, 3, 2, 1], [6, 2, 3, 5, 1], [2, 6, 3, 1, 0], [5, 3, 6, 7, 1], [3, 7, 5, 6, 1], [3, 0, 4, 1, 7], [3, 0, 4, 1, 6], [5, 3, 7, 6, 2], [6, 5, 3, 1, 7], [6, 2, 3, 1, 0], [3, 5, 2, 6, 1], [3, 2, 6, 5, 1], [3, 5, 6, 1, 7], [3, 1, 6, 4, 7], [6, 3, 1, 5, 2], [6, 5, 3, 1, 4], [3, 1, 0, 6, 5], [6, 2, 3, 1, 0], [0, 3, 2, 7, 6], [6, 2, 3, 1, 0], [6, 5, 3, 7, 1], [0, 3, 5, 6, 7], [3, 7, 5, 6, 2], [6, 3, 5, 1, 2], [5, 3, 6, 1, 7], [6, 5, 3, 1, 7], [3, 0, 2, 5, 6], [2, 5, 7, 1, 0], [6, 2, 3, 1, 0], [5, 7, 3, 2, 6], [3, 5, 6, 2, 7], [2, 1, 7, 0, 5], [6, 3, 5, 2, 1], [3, 7, 5, 6, 0], [3, 7, 5, 6, 0], [3, 5, 7, 6, 2], [3, 7, 5, 6, 4], [2, 5, 1, 7, 0], [5, 6, 3, 7, 4], [2, 3, 1, 6, 0], [6, 2, 3, 5, 1], [3, 2, 1, 0, 6], [3, 2, 6, 1, 5], [3, 2, 1, 0, 4], [3, 2, 0, 4, 6], [5, 3, 6, 7, 1], [5, 6, 3, 7, 1], [3, 1, 0, 6, 2], [2, 3, 1, 0, 5], [3, 5, 6, 7, 2], [5, 7, 3, 6, 4], [5, 7, 3, 6, 2], [3, 1, 0, 6, 5], [6, 5, 3, 7, 4], [5, 7, 2, 3, 1], [3, 0, 5, 7, 2], [0, 7, 2, 1, 5], [7, 2, 0, 5, 1], [0, 7, 2, 1, 5], [7, 0, 2, 5, 1], [6, 5, 3, 7, 1], [3, 0, 7, 5, 2], [3, 0, 5, 7, 2], [0, 2, 7, 3, 1], [0, 3, 2, 7, 1], [3, 0, 2, 1, 5], [3, 0, 1, 2, 5], [2, 3, 1, 0, 6], [3, 0, 7, 5, 4], [3, 1, 4, 6, 0], [1, 2, 5, 0, 3], [3, 1, 0, 2, 6], [3, 1, 0, 2, 5], [3, 0, 1, 2, 5], [3, 2, 1, 0, 4], [3, 0, 1, 4, 6], [3, 0, 7, 1, 6], [1, 3, 6, 2, 7], [0, 3, 5, 2, 6], [6, 3, 5, 1, 7], [6, 5, 3, 7, 1], [6, 5, 3, 7, 1], [6, 5, 3, 7, 1], [6, 5, 3, 7, 1], [3, 6, 0, 1, 2], [3, 2, 1, 5, 0], [3, 7, 6, 5, 1], [5, 7, 3, 6, 2], [3, 0, 1, 2, 6], [3, 5, 0, 7, 6], [2, 1, 5, 3, 6], [0, 3, 1, 5, 6], [6, 2, 3, 1, 5], [5, 3, 7, 6, 4], [0, 3, 2, 5, 7], [0, 5, 7, 1, 6], [3, 0, 2, 6, 1], [3, 0, 1, 6, 7], [3, 7, 2, 5, 0], [7, 2, 5, 0, 1], [3, 0, 7, 5, 6], [3, 0, 6, 1, 2], [0, 7, 1, 5, 3], [3, 5, 7, 2, 6], [0, 7, 3, 1, 5], [3, 2, 0, 1, 7], [2, 0, 1, 3, 5], [5, 3, 7, 2, 6], [0, 3, 1, 7, 6], [5, 7, 6, 3, 2], [3, 0, 1, 6, 5], [3, 2, 6, 5, 7], [3, 0, 5, 4, 1], [3, 2, 0, 1, 4], [2, 3, 1, 0, 4], [3, 5, 7, 6, 1], [0, 1, 7, 3, 5], [2, 5, 1, 3, 0], [2, 1, 0, 5, 3], [5, 3, 7, 6, 4], [2, 1, 0, 5, 3], [7, 5, 2, 1, 0], [6, 2, 3, 5, 1], [6, 2, 3, 0, 1], [2, 3, 6, 1, 0], [2, 6, 3, 1, 0], [5, 6, 3, 7, 1], [0, 1, 2, 3, 7], [5, 6, 3, 7, 1], [3, 0, 2, 1, 5], [3, 0, 1, 2, 4], [3, 1, 0, 4, 6], [3, 0, 1, 2, 4], [2, 1, 3, 6, 5], [5, 3, 6, 1, 7], [2, 3, 1, 6, 0], [3, 7, 0, 5, 1], [3, 6, 5, 2, 1], [0, 3, 1, 2, 6], [1, 3, 6, 2, 0], [3, 7, 2, 5, 6], [5, 3, 7, 6, 2], [5, 3, 6, 7, 1], [5, 7, 3, 6, 2], [5, 7, 3, 6, 2], [6, 5, 3, 1, 7], [2, 1, 3, 6, 0], [3, 1, 7, 6, 0], [6, 5, 3, 7, 1], [0, 3, 5, 2, 6], [5, 3, 6, 7, 1], [5, 7, 2, 3, 6], [3, 7, 0, 6, 1], [3, 1, 0, 6, 7], [3, 7, 6, 5, 1], [2, 6, 1, 3, 0], [1, 3, 0, 6, 2], [3, 0, 7, 5, 2], [0, 5, 2, 7, 3], [0, 3, 6, 5, 7], [5, 1, 7, 2, 6], [3, 0, 7, 5, 6], [3, 0, 5, 7, 2], [2, 3, 6, 1, 5], [3, 1, 5, 6, 0], [3, 1, 0, 6, 7], [6, 2, 3, 1, 0], [2, 1, 5, 3, 0], [3, 0, 7, 1, 6], [0, 3, 2, 4, 1], [1, 3, 0, 6, 4], [0, 1, 3, 2, 6], [3, 2, 5, 0, 7], [3, 0, 5, 2, 7], [3, 6, 7, 0, 1], [2, 3, 0, 1, 4], [5, 3, 7, 6, 4], [3, 0, 5, 1, 7], [1, 5, 3, 0, 2], [6, 0, 5, 2, 4], [6, 0, 4, 2, 5], [6, 0, 2, 5, 4], [2, 6, 3, 1, 0], [5, 7, 3, 6, 4], [0, 1, 7, 2, 5], [3, 1, 0, 2, 6], [3, 7, 5, 6, 1], [3, 0, 7, 1, 4], [6, 0, 2, 5, 4], [6, 5, 3, 7, 2], [5, 3, 7, 2, 0], [3, 0, 1, 6, 7], [6, 5, 3, 7, 1], [7, 3, 5, 2, 0], [3, 7, 5, 2, 0], [3, 5, 7, 6, 1], [0, 2, 1, 3, 5], [3, 0, 1, 2, 5], [0, 1, 5, 3, 2], [2, 1, 3, 6, 0], [7, 3, 5, 2, 0], [2, 3, 6, 5, 1], [7, 5, 2, 3, 0], [7, 5, 2, 3, 0], [7, 2, 5, 3, 1], [7, 2, 5, 3, 0], [7, 5, 3, 2, 0], [7, 5, 2, 3, 0], [0, 3, 1, 6, 2], [2, 1, 3, 6, 0], [2, 6, 3, 1, 0], [3, 1, 2, 0, 6], [3, 0, 1, 2, 6], [3, 0, 7, 2, 6], [3, 0, 1, 6, 7], [2, 5, 1, 0, 3], [5, 1, 2, 7, 6], [2, 0, 3, 1, 5], [2, 0, 1, 3, 5], [3, 0, 6, 1, 2], [3, 2, 6, 1, 0], [3, 1, 6, 0, 7], [0, 3, 6, 5, 7], [3, 1, 6, 0, 7], [5, 3, 6, 7, 1], [5, 3, 7, 6, 1], [3, 0, 7, 5, 2], [6, 5, 4, 0, 2], [6, 3, 2, 4, 7], [6, 3, 2, 5, 1], [3, 6, 5, 1, 2], [5, 3, 6, 1, 7], [6, 3, 5, 2, 7], [3, 1, 6, 5, 2], [5, 3, 6, 1, 2], [2, 1, 3, 6, 5], [3, 2, 7, 6, 1], [6, 0, 2, 5, 4], [6, 5, 3, 2, 7], [2, 1, 7, 5, 0], [0, 3, 1, 2, 5], [3, 0, 2, 1, 5], [6, 5, 3, 7, 1], [3, 5, 7, 6, 4], [3, 7, 5, 6, 4], [0, 2, 7, 1, 5], [5, 7, 3, 2, 6], [3, 1, 6, 5, 0], [3, 1, 0, 6, 5], [2, 7, 5, 1, 0], [6, 0, 4, 2, 5], [0, 3, 2, 1, 4], [6, 5, 3, 7, 4], [1, 5, 0, 2, 3], [2, 1, 3, 0, 5], [2, 5, 1, 0, 7], [3, 0, 7, 1, 2], [0, 2, 3, 1, 5], [3, 0, 2, 1, 4], [3, 1, 2, 0, 6], [2, 5, 1, 7, 0], [2, 5, 1, 0, 3], [2, 5, 1, 3, 0], [2, 5, 1, 7, 0], [2, 5, 1, 7, 0], [2, 5, 1, 7, 0], [2, 1, 5, 3, 0], [3, 7, 5, 6, 1], [3, 1, 2, 6, 0], [3, 1, 6, 7, 0], [6, 3, 2, 1, 7], [3, 6, 1, 5, 7], [3, 1, 6, 0, 2], [6, 3, 2, 1, 0], [3, 2, 1, 0, 6], [3, 5, 6, 7, 1], [2, 0, 5, 1, 3], [2, 1, 3, 6, 0], [3, 6, 1, 2, 7], [5, 7, 3, 6, 2], [6, 3, 5, 2, 4], [2, 6, 1, 3, 0], [2, 5, 1, 0, 3], [3, 5, 6, 1, 7], [3, 1, 6, 5, 7], [2, 5, 1, 7, 0], [2, 5, 1, 7, 0], [3, 1, 6, 5, 0], [6, 5, 3, 2, 1], [6, 0, 2, 5, 4], [5, 6, 3, 1, 7], [3, 0, 2, 7, 5], [3, 2, 0, 5, 7], [5, 7, 3, 6, 2], [5, 6, 7, 3, 0], [5, 6, 7, 3, 0], [5, 7, 6, 3, 2], [2, 1, 6, 3, 7], [2, 1, 3, 6, 0], [2, 5, 7, 1, 0], [5, 3, 6, 7, 1], [3, 2, 6, 4, 1], [6, 2, 3, 5, 1], [1, 0, 3, 2, 6], [1, 0, 5, 2, 7], [3, 1, 5, 6, 0], [2, 1, 3, 0, 5], [2, 3, 1, 4, 5], [2, 5, 1, 0, 7], [0, 2, 3, 7, 1], [5, 6, 7, 3, 1], [5, 3, 7, 6, 1], [0, 3, 7, 1, 6], [2, 5, 7, 1, 0], [5, 7, 3, 2, 4], [3, 5, 7, 0, 2], [2, 1, 3, 6, 5], [1, 3, 5, 0, 2], [3, 0, 1, 2, 5], [3, 7, 5, 0, 4], [6, 3, 2, 1, 7], [6, 5, 3, 4, 1], [6, 3, 4, 2, 1], [3, 1, 6, 7, 5], [0, 2, 5, 3, 1], [3, 0, 1, 7, 4], [3, 0, 7, 4, 6], [3, 0, 7, 1, 4], [3, 0, 1, 7, 6], [5, 3, 7, 6, 2], [3, 2, 6, 1, 5], [3, 7, 5, 6, 1], [3, 7, 6, 1, 5], [3, 1, 2, 0, 6], [3, 1, 6, 7, 0], [2, 1, 3, 6, 0], [2, 1, 3, 6, 5], [3, 2, 0, 1, 6], [3, 1, 7, 6, 0], [5, 2, 7, 0, 6], [0, 3, 1, 2, 5], [2, 1, 3, 5, 6], [2, 1, 3, 5, 6], [3, 2, 1, 0, 6], [2, 0, 1, 5, 3], [5, 3, 6, 7, 1], [5, 3, 6, 1, 7], [3, 6, 2, 1, 5], [3, 5, 7, 6, 2], [3, 6, 2, 1, 0], [3, 0, 1, 6, 5], [5, 7, 2, 3, 1], [6, 5, 7, 3, 2], [5, 6, 7, 3, 2], [5, 7, 6, 3, 2], [5, 6, 3, 7, 1], [5, 6, 7, 3, 1], [6, 5, 3, 7, 1], [3, 0, 7, 5, 4], [5, 2, 7, 3, 6], [1, 3, 7, 6, 0], [3, 0, 7, 2, 5], [6, 5, 3, 7, 1], [6, 5, 3, 7, 1], [3, 0, 5, 1, 4], [0, 2, 7, 3, 5], [1, 0, 3, 2, 7], [2, 1, 3, 5, 6], [0, 3, 2, 7, 5], [6, 3, 5, 7, 2], [2, 6, 3, 0, 1], [3, 0, 7, 5, 4], [3, 5, 7, 2, 0], [3, 1, 0, 6, 5], [6, 5, 3, 7, 2], [3, 0, 7, 4, 6], [6, 5, 3, 2, 7], [6, 2, 3, 5, 1], [2, 6, 3, 0, 1], [2, 6, 3, 0, 5], [5, 6, 3, 7, 2], [3, 7, 4, 0, 6], [5, 7, 6, 3, 2], [0, 3, 2, 1, 4], [0, 3, 1, 2, 5], [3, 1, 7, 6, 2], [3, 1, 0, 6, 2], [2, 3, 5, 0, 1], [2, 5, 0, 3, 1], [5, 3, 7, 6, 4], [6, 2, 3, 1, 0], [2, 5, 1, 0, 3], [2, 1, 5, 3, 6], [7, 2, 5, 3, 0], [6, 2, 3, 5, 1], [2, 6, 3, 1, 0], [6, 4, 3, 0, 5], [6, 4, 3, 0, 2], [2, 5, 1, 7, 0], [2, 1, 3, 5, 6], [3, 1, 6, 0, 2], [5, 3, 7, 6, 1], [2, 5, 7, 1, 0], [5, 7, 2, 3, 6], [6, 2, 3, 5, 4], [6, 3, 1, 5, 2], [3, 6, 0, 1, 5], [2, 3, 1, 6, 0], [2, 5, 1, 7, 0], [3, 1, 6, 2, 0], [3, 0, 1, 6, 2], [3, 6, 1, 0, 2], [6, 2, 3, 1, 0], [3, 7, 5, 6, 0], [3, 0, 7, 6, 4], [5, 7, 2, 3, 1], [6, 5, 7, 3, 4], [5, 3, 6, 1, 7], [3, 5, 6, 1, 7], [6, 3, 5, 7, 1], [3, 5, 7, 6, 4], [5, 3, 6, 1, 4], [3, 2, 1, 0, 6], [3, 0, 1, 6, 5], [5, 3, 6, 7, 1], [3, 5, 6, 7, 1], [3, 7, 0, 5, 4], [6, 2, 3, 5, 1], [6, 2, 3, 7, 5], [2, 1, 0, 5, 7], [3, 2, 1, 0, 6], [1, 0, 3, 5, 2], [2, 5, 0, 1, 7], [2, 0, 1, 5, 7], [2, 7, 1, 5, 0], [1, 3, 0, 2, 6], [2, 3, 1, 6, 0], [3, 2, 1, 0, 6], [3, 0, 2, 1, 4], [5, 3, 7, 6, 4], [3, 0, 4, 7, 6], [3, 0, 1, 7, 6], [1, 3, 0, 2, 6], [3, 7, 1, 0, 6], [3, 7, 0, 5, 4], [3, 7, 5, 4, 2], [3, 7, 5, 4, 0], [2, 3, 1, 0, 6], [6, 3, 5, 2, 7], [2, 5, 7, 1, 0], [3, 2, 1, 0, 6], [3, 0, 1, 4, 2], [2, 5, 3, 0, 1], [5, 7, 3, 6, 2], [2, 6, 3, 1, 0], [2, 6, 3, 1, 0], [6, 3, 2, 4, 5], [5, 6, 3, 7, 2], [3, 7, 5, 6, 4], [0, 3, 2, 1, 5], [3, 0, 2, 7, 6], [3, 0, 1, 6, 2], [3, 1, 6, 7, 2], [2, 0, 5, 7, 1], [3, 0, 2, 1, 6], [2, 1, 5, 0, 7], [3, 5, 7, 2, 6], [6, 0, 2, 4, 5], [3, 6, 5, 7, 1], [5, 3, 7, 6, 2], [0, 3, 2, 5, 7], [2, 1, 5, 0, 7], [2, 5, 7, 0, 1], [3, 6, 1, 7, 5], [3, 2, 6, 7, 1], [3, 6, 2, 1, 7], [2, 1, 5, 0, 3], [3, 0, 2, 1, 4], [3, 5, 6, 7, 2], [3, 5, 7, 6, 0], [3, 6, 5, 1, 7], [3, 0, 6, 1, 2], [6, 3, 5, 2, 7], [5, 3, 7, 4, 2], [3, 5, 7, 4, 6], [2, 1, 0, 3, 5], [3, 5, 7, 6, 0], [3, 0, 1, 5, 2], [3, 6, 5, 4, 7], [0, 2, 7, 5, 1], [3, 5, 7, 6, 4], [5, 7, 6, 3, 4], [2, 3, 1, 6, 0], [2, 3, 1, 6, 0], [2, 6, 3, 5, 1], [3, 5, 7, 6, 4], [0, 2, 3, 1, 4], [5, 3, 6, 7, 4], [1, 0, 2, 3, 5], [6, 5, 3, 1, 7], [3, 7, 5, 6, 4], [7, 5, 3, 4, 6], [2, 0, 3, 4, 1], [2, 1, 3, 0, 4], [3, 5, 7, 2, 0], [2, 3, 1, 0, 5], [2, 5, 7, 1, 0], [5, 3, 7, 4, 6], [3, 5, 4, 0, 7], [3, 7, 5, 4, 6], [3, 0, 1, 2, 6], [3, 5, 7, 6, 1], [3, 6, 5, 2, 7], [6, 3, 4, 2, 5], [5, 3, 7, 6, 4], [3, 7, 0, 4, 5], [6, 3, 5, 1, 7], [3, 6, 5, 1, 7], [5, 7, 3, 6, 2], [3, 0, 1, 5, 6], [0, 3, 2, 1, 6], [2, 3, 0, 1, 5], [2, 5, 1, 3, 0], [1, 2, 5, 7, 0], [2, 5, 1, 7, 3], [2, 6, 3, 1, 0], [3, 0, 1, 6, 4], [2, 7, 5, 1, 0], [2, 5, 0, 7, 1], [6, 3, 2, 4, 1], [3, 6, 7, 5, 1], [3, 6, 1, 7, 2], [3, 0, 6, 7, 1], [3, 0, 1, 2, 4], [5, 3, 7, 6, 4], [3, 6, 5, 2, 7], [3, 6, 2, 1, 5], [6, 5, 3, 1, 7], [3, 5, 7, 2, 6], [3, 0, 4, 6, 1], [3, 0, 4, 6, 1], [3, 0, 6, 1, 5], [3, 0, 1, 6, 7], [3, 5, 7, 6, 2], [2, 6, 1, 3, 0], [0, 3, 2, 6, 1], [2, 7, 1, 5, 0], [3, 5, 6, 1, 4], [5, 7, 6, 3, 2], [0, 7, 3, 2, 5], [3, 0, 1, 6, 4], [2, 5, 7, 1, 0], [2, 0, 1, 5, 7], [2, 7, 5, 1, 0], [3, 5, 7, 6, 4], [6, 4, 3, 1, 0], [2, 3, 6, 1, 0], [5, 3, 7, 6, 0], [3, 5, 7, 4, 0], [5, 6, 3, 7, 2], [5, 6, 3, 7, 1], [0, 3, 1, 2, 6], [3, 6, 7, 2, 5], [3, 6, 2, 5, 7], [3, 5, 6, 2, 7], [5, 3, 6, 2, 1], [5, 7, 6, 3, 2], [6, 5, 3, 1, 7], [5, 3, 7, 6, 2], [5, 3, 6, 7, 1], [5, 3, 7, 6, 4], [5, 3, 7, 6, 4], [3, 7, 5, 6, 4], [3, 5, 1, 6, 0], [5, 3, 7, 6, 2], [3, 5, 6, 7, 1], [6, 3, 4, 5, 1], [2, 5, 0, 1, 7], [5, 7, 2, 3, 1], [3, 1, 2, 0, 6], [3, 1, 2, 0, 6], [6, 5, 3, 7, 1], [3, 1, 2, 6, 0], [3, 0, 5, 4, 6], [3, 0, 1, 2, 4], [3, 1, 6, 0, 7], [3, 2, 7, 5, 0], [3, 0, 6, 2, 7], [2, 6, 3, 1, 0], [2, 5, 1, 3, 0], [3, 5, 2, 7, 0], [3, 6, 1, 5, 4], [3, 7, 2, 5, 0], [6, 2, 3, 1, 0], [3, 6, 2, 1, 5], [3, 1, 0, 5, 6], [3, 5, 0, 7, 4], [6, 5, 3, 7, 1], [3, 2, 6, 1, 5], [3, 6, 5, 2, 1], [2, 6, 3, 1, 0], [3, 5, 7, 2, 0], [6, 3, 5, 2, 1], [3, 0, 4, 5, 6], [3, 6, 5, 0, 7], [3, 0, 2, 5, 6], [2, 1, 3, 6, 0], [3, 2, 0, 1, 4], [2, 3, 0, 1, 4], [2, 0, 7, 3, 1], [5, 6, 3, 7, 1], [3, 6, 4, 5, 1], [0, 7, 1, 5, 2], [3, 5, 6, 7, 4], [5, 3, 7, 6, 4], [5, 3, 7, 2, 4], [5, 3, 7, 6, 4], [3, 1, 4, 5, 6], [6, 5, 3, 2, 7], [6, 3, 5, 2, 7], [6, 3, 2, 5, 7], [6, 3, 5, 2, 1], [6, 2, 3, 0, 1], [3, 5, 6, 2, 4], [5, 6, 3, 7, 1], [5, 7, 3, 2, 6], [6, 5, 3, 7, 2], [0, 2, 7, 5, 1], [2, 1, 5, 7, 4], [0, 3, 1, 4, 2], [3, 6, 5, 1, 7], [2, 5, 0, 3, 1], [0, 7, 2, 3, 5], [3, 0, 5, 4, 1], [2, 7, 1, 5, 0], [2, 1, 7, 0, 3], [3, 1, 6, 4, 0], [0, 5, 2, 7, 1], [2, 5, 7, 1, 0], [3, 5, 7, 6, 0], [2, 3, 1, 0, 4], [5, 3, 6, 1, 4], [3, 0, 1, 6, 5], [3, 0, 1, 6, 7], [2, 5, 7, 3, 1], [3, 5, 0, 6, 1], [3, 0, 4, 6, 1], [2, 3, 1, 0, 6], [6, 4, 0, 2, 5], [6, 0, 2, 5, 4], [6, 4, 0, 2, 3], [2, 7, 5, 1, 0], [3, 0, 1, 6, 4], [5, 3, 7, 6, 2], [3, 5, 7, 6, 1], [3, 0, 6, 1, 7], [3, 6, 1, 7, 0], [1, 3, 0, 6, 5], [6, 3, 5, 7, 1], [5, 3, 6, 7, 1], [3, 6, 5, 1, 7], [2, 1, 5, 6, 3], [5, 3, 7, 6, 2], [3, 2, 1, 6, 0], [2, 1, 5, 3, 6], [3, 4, 6, 5, 0], [3, 2, 6, 4, 1], [2, 6, 3, 1, 5], [7, 5, 0, 1, 2], [7, 0, 5, 1, 2], [0, 3, 1, 6, 7], [0, 3, 6, 4, 1], [3, 5, 0, 7, 4], [1, 3, 2, 0, 4], [2, 7, 5, 1, 3], [3, 6, 2, 1, 5], [3, 6, 7, 1, 4], [3, 4, 0, 7, 6], [6, 5, 3, 7, 1], [3, 5, 4, 6, 7], [3, 2, 1, 6, 4], [5, 2, 7, 6, 0], [5, 2, 7, 3, 6], [1, 3, 0, 5, 2], [2, 5, 7, 1, 0], [5, 3, 6, 7, 4], [3, 5, 7, 6, 4], [6, 5, 3, 7, 1], [0, 3, 2, 5, 7], [2, 5, 1, 0, 3], [6, 5, 3, 7, 2], [2, 5, 7, 1, 0], [3, 5, 7, 2, 4], [5, 7, 3, 2, 6], [1, 0, 5, 7, 3], [0, 3, 2, 1, 5], [3, 0, 1, 2, 4], [3, 0, 1, 4, 6], [3, 0, 1, 2, 4], [3, 0, 1, 6, 2], [1, 0, 3, 2, 7], [3, 0, 7, 2, 5], [3, 0, 1, 6, 4], [3, 0, 1, 2, 4], [6, 3, 2, 1, 5], [3, 6, 2, 5, 1], [2, 6, 1, 3, 0], [3, 5, 7, 6, 1], [3, 6, 5, 1, 7], [3, 5, 7, 6, 4], [3, 1, 0, 2, 5], [5, 3, 7, 6, 2], [3, 1, 6, 0, 7], [3, 7, 5, 2, 6], [5, 2, 7, 3, 6], [3, 0, 1, 2, 6], [2, 1, 3, 6, 5], [3, 6, 5, 2, 1], [2, 1, 5, 3, 0], [3, 0, 1, 6, 2], [2, 5, 7, 1, 0], [5, 3, 6, 7, 1], [5, 3, 6, 7, 1], [3, 5, 6, 1, 7], [5, 7, 0, 1, 2], [3, 6, 2, 1, 7], [3, 6, 1, 2, 5], [3, 2, 1, 0, 6], [6, 0, 5, 2, 4], [0, 7, 5, 2, 1], [2, 5, 7, 1, 0], [3, 0, 1, 6, 5], [1, 5, 7, 0, 3], [3, 1, 2, 6, 0], [2, 1, 3, 0, 7], [2, 6, 3, 0, 7], [3, 1, 0, 6, 4], [2, 7, 5, 1, 3], [0, 7, 1, 5, 3], [3, 5, 7, 6, 2], [2, 3, 1, 0, 4], [3, 0, 4, 1, 7], [0, 3, 2, 5, 7], [5, 7, 2, 3, 1], [7, 2, 5, 3, 1], [7, 2, 5, 3, 1], [0, 3, 1, 2, 6], [0, 3, 1, 4, 7], [5, 7, 3, 2, 6], [0, 1, 2, 7, 3], [2, 5, 6, 1, 3], [3, 6, 5, 2, 1], [6, 5, 3, 7, 2], [3, 2, 6, 1, 4], [5, 7, 3, 6, 2], [5, 3, 7, 6, 1], [3, 1, 0, 2, 6], [3, 7, 0, 5, 6], [3, 7, 1, 6, 0], [3, 2, 1, 0, 4], [3, 0, 1, 4, 7], [5, 7, 3, 2, 6], [3, 1, 2, 0, 5], [3, 5, 1, 2, 0], [3, 5, 7, 6, 1], [3, 7, 0, 5, 1], [5, 3, 7, 6, 2], [3, 0, 1, 7, 5], [3, 2, 1, 0, 6], [3, 7, 5, 6, 1], [0, 5, 3, 1, 2], [2, 3, 1, 0, 6], [3, 5, 6, 2, 1], [3, 0, 1, 6, 2], [0, 3, 1, 2, 5], [3, 0, 1, 6, 7], [0, 5, 3, 7, 1], [6, 5, 3, 7, 4], [3, 0, 2, 6, 1], [0, 3, 2, 5, 6], [2, 5, 1, 7, 0], [0, 3, 5, 6, 2], [5, 1, 2, 7, 6], [6, 2, 3, 4, 1]] showed the highest activity during this simulation.\n",
      "(In a full analysis, you would regress these dimensions back to Pathways).\n"
     ]
    }
   ],
   "source": [
    "# Which latent dimensions changed the most?\n",
    "# This gives us a \"fingerprint\" of the predicted change\n",
    "diff_vector = (z_predicted - z_control).abs().mean(dim=0) # [Embed_Dim]\n",
    "top_dims = torch.topk(diff_vector, 5).indices.tolist()\n",
    "\n",
    "print(f\"\\n[Top Active Latent Dimensions]\")\n",
    "print(f\"Dimensions {top_dims} showed the highest activity during this simulation.\")\n",
    "print(\"(In a full analysis, you would regress these dimensions back to Pathways).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7a4bc-88e5-4903-bbad-6ffa382db26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30288334-6f6f-48a3-96e3-4f9144215288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
