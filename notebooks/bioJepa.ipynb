{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfe968dc-a937-469a-89d8-7ba179a2e01a",
   "metadata": {},
   "source": [
    "# Bio-JEPA AC \n",
    "\n",
    "Based on [V-JEPA 2 AC](https://arxiv.org/abs/2506.09985)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b67dcd-a768-447b-ad7b-77e8cddd59c0",
   "metadata": {},
   "source": [
    "**Goal**\n",
    "Our goal is to build a World Model for cell biology. In it's current configuration, our model calculates that hitting a cell with a specific gene knockout, or drug if we had it in the dataset, causes specific biological pathways to activate or shut down. Unlike an LLM, this is a predictive simulation that operates entirely within a compressed mathematical space to understand cause and effect.\n",
    "\n",
    "The process begins with the inputs, which feed the model three distinct pieces of information for every training step. \n",
    "\tFirst, it receives the **Before** state, which is data representing a healthy control cell. Instead of a messy list of 20,000 raw gene counts, the tokenizer has already compressed this into a structured set of pathway scores (using [Reactome Pathway 2024 data](https://maayanlab.cloud/Harmonizome/dataset/Reactome+Pathways+2024)). This essentially tells the model that the cell currently has high energy, low stress, and normal growth. \n",
    "\tSecond, the model receives the **Action**, which is the specific perturbation performed in the lab, in our case a CRISPR knockdown of a specific gene. This could also be a drug application or protein introduction if we had the data. This is converted into a learnable \"Action Embedding,\" effectively serving as the command that tells the simulation what event just occurred. \n",
    "\tThird, the model is given the **After** state, which is the actual knockdown cell observed in the experiment. This third input serves purely as the target or \"ground truth\"; the model is not allowed to see it while making its prediction, but uses it afterwards in the loss calculation and backprop.\n",
    "\n",
    "Inside the model, a three-step simulation plays out to process these inputs. It starts with the **Student Encoder**, or the *Perception* module, which looks at the healthy **Before** cell input  and compresses it into a Latent State. At this stage, the model is simply understanding the baseline biological status of the cell. This latent representation is then passed to the **Action-Conditioned Predictor**, which acts as the *Physics Engine.* This component combines the cell's current state with the Action vector. Using a mechanism called Adaptive Layer Normalization (AdaLN), the action actually modulates the internal weights of the neural network, effectively shifting the physical rules of the simulation to match the drug's effects. The **Predictor** then tries to predict, or hellucinate, what the future state of the cell will be, calculating a new vector that represents the cell's condition after the knockout, or drug impact. \n",
    "\n",
    "To validate the predictor, simultaneously the **Teacher Encoder** looks at the real **After** data from the lab and encodes it into that same latent space to serve as the judge. To learn, the model compares the predictor output against the Teacher's reality. With backprop, we attempt to minimize the difference between the prediction and the actual outcome, trying to minimize this error over millions of examples. \n",
    "\n",
    "In theory, by forcing its predictions to match reality, the model moves beyond simply memorizing data and begins to learn the underlying causal rules of biology. It figures out gene regulatory logicâ€”understanding that if Gene A is knocked down, Pathway B must functionally fail. It learns how different pathways, like inflammation and cell death, are causally linked. Ultimately, we hope it learns the \"physics\" of how perturbations work, allowing us to eventually simulate the effects of gene mutations, drugs or genetic interventions on cells without having to perform the physical experiment in a wet lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33a357f2-d497-4dfc-9920-568422b5403a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import copy\n",
    "import math\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9242cf00-c812-41d0-ae92-9c7dd0af6f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158bffc-f24a-4471-a463-7241c2ad6784",
   "metadata": {},
   "source": [
    "## Utils\n",
    "\n",
    "### ROTARY POSITIONAL EMBEDDINGS (RoPE)\n",
    "V-JEPA 2 uses 3D-RoPE. We adapt this to 1D-RoPE for our list of Pathway Tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "38ffafca-b99d-4cde-884f-a6347c5eafed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RotaryEmbedding(nn.Module):\n",
    "    def __init__(self, dim, max_seq_len=2048):\n",
    "        super().__init__()\n",
    "        inv_freq = 1.0 / (10000 ** (torch.arange(0, dim, 2).float() / dim))\n",
    "        t = torch.arange(max_seq_len).type_as(inv_freq)\n",
    "        freqs = torch.einsum('i,j->ij', t, inv_freq)\n",
    "        emb = torch.cat((freqs, freqs), dim=-1)\n",
    "        self.register_buffer('emb', emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Seq, Dim]\n",
    "        # returns cos, sin for the sequence length of x\n",
    "        n = x.shape[1]\n",
    "        return self.emb[:n, :].cos(), self.emb[:n, :].sin()\n",
    "\n",
    "def apply_rotary_pos_emb(x, cos, sin):\n",
    "    # Standard RoPE rotation\n",
    "    # split x into half\n",
    "    d = x.shape[-1] // 2\n",
    "    x1, x2 = x[..., :d], x[..., d:]\n",
    "    rotated = torch.cat((-x2, x1), dim=-1)\n",
    "    return (x * cos) + (rotated * sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b51720-0b30-466c-b5ea-5cac69175e1e",
   "metadata": {},
   "source": [
    "## Components\n",
    "\n",
    "### COMPONENT 1: THE ENCODER (STUDENT/TEACHER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "602e56c8-779a-4cab-a23e-a360682aa4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioEncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, int(dim * mlp_ratio)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(int(dim * mlp_ratio), dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, cos, sin):\n",
    "        # 1. Attention with RoPE\n",
    "        x_norm = self.norm1(x)\n",
    "        \n",
    "        # Apply RoPE to queries and keys inside attention? \n",
    "        # For simplicity in standard PyTorch MHA, we apply it to x before attention\n",
    "        # (Technically RoPE is applied to Q and K inside, but this approximation works \n",
    "        # if we treat x as the carrier of position).\n",
    "        # STRICT IMPLEMENTATION: manually project Q,K,V, apply RoPE to Q,K, then Attn.\n",
    "        # We will use the simplified \"Inject Position\" approach for readability here.\n",
    "        x_rope = apply_rotary_pos_emb(x_norm, cos, sin)\n",
    "        \n",
    "        attn_out, _ = self.attn(x_rope, x_rope, x_norm) # V is not rotated usually\n",
    "        x = x + attn_out\n",
    "        \n",
    "        # 2. MLP\n",
    "        x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32aadea7-3614-4d4e-afe7-812fb0e21551",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathwayEncoder(nn.Module):\n",
    "    def __init__(self, num_pathways=1024, embed_dim=384, depth=12, heads=2):\n",
    "        super().__init__()\n",
    "        # Input: [Batch, Pathways] (Float) -> Project to [Batch, Pathways, Dim]\n",
    "        self.input_proj = nn.Linear(1, embed_dim)\n",
    "        \n",
    "        self.rope = RotaryEmbedding(embed_dim // heads * heads) # Ensure divisibility\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            BioEncoderBlock(embed_dim, heads) for _ in range(depth)\n",
    "        ])\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [Batch, Num_Pathways]\n",
    "        x = x.unsqueeze(-1) # [B, N, 1]\n",
    "        x = self.input_proj(x) # [B, N, Dim]\n",
    "        \n",
    "        # Generate RoPE cache\n",
    "        cos, sin = self.rope(x)\n",
    "        cos, sin = cos.to(x.device), sin.to(x.device)\n",
    "        \n",
    "        for block in self.blocks:\n",
    "            x = block(x, cos, sin)\n",
    "            \n",
    "        return self.norm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b64874bc-9e76-4715-bee3-08fd86598823",
   "metadata": {},
   "source": [
    "### COMPONENT 2: ACTION-CONDITIONED PREDICTOR (AdaLN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ce1c88f-fb19-4084-96fa-520202fe783e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaLN(nn.Module):\n",
    "    \"\"\"\n",
    "    V-JEPA 2 / DiT Style Conditioning.\n",
    "    The action vector regresses the Scale (gamma) and Shift (beta) of the normalization.\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim, action_dim):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(embed_dim, elementwise_affine=False)\n",
    "        self.action_mlp = nn.Sequential(\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(action_dim, 2 * embed_dim)\n",
    "        )\n",
    "        # Initialize to identity (gamma=0, beta=0 originally, effectively gamma=1 after logic)\n",
    "        # Standard practice: zero-init the last layer so action starts as \"no-op\"\n",
    "        nn.init.zeros_(self.action_mlp[1].weight)\n",
    "        nn.init.zeros_(self.action_mlp[1].bias)\n",
    "\n",
    "    def forward(self, x, action_emb):\n",
    "        # action_emb: [Batch, Action_Dim]\n",
    "        style = self.action_mlp(action_emb).unsqueeze(1) # [B, 1, 2*D]\n",
    "        gamma, beta = style.chunk(2, dim=-1)\n",
    "        return self.norm(x) * (1 + gamma) + beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec41393d-a173-4ce6-9894-4c8684dd913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictorBlock(nn.Module):\n",
    "    def __init__(self, dim, heads, action_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(dim, 4 * dim),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(4 * dim, dim)\n",
    "        )\n",
    "        self.ada_ln1 = AdaLN(dim, action_dim)\n",
    "        self.ada_ln2 = AdaLN(dim, action_dim)\n",
    "\n",
    "    def forward(self, x, action_emb, cos, sin):\n",
    "        # AdaLN -> Attn (with RoPE) -> Residual\n",
    "        x_norm = self.ada_ln1(x, action_emb)\n",
    "        \n",
    "        # Apply RoPE to Q, K\n",
    "        x_rope = apply_rotary_pos_emb(x_norm, cos, sin)\n",
    "        \n",
    "        attn_out, _ = self.attn(x_rope, x_rope, x_norm) \n",
    "        x = x + attn_out\n",
    "        \n",
    "        # AdaLN -> MLP -> Residual\n",
    "        x_norm = self.ada_ln2(x, action_emb)\n",
    "        x = x + self.mlp(x_norm)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c53d09da-e83a-480a-9ccb-1c6159b567a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ACPredictor(nn.Module):\n",
    "    def __init__(self, embed_dim=384, action_dim=256, depth=6, heads=2, num_pathways=1024):\n",
    "        super().__init__()\n",
    "        self.num_pathways = num_pathways\n",
    "        \n",
    "        # Action Embedding (Discrete ID -> Vector)\n",
    "        # We assume action_ids are passed in\n",
    "        self.action_embed = nn.Embedding(3000, action_dim) # 3000 max perturbations\n",
    "        \n",
    "        # Learnable Queries (The \"Mask Tokens\" for the future state)\n",
    "        # We learn one query vector per pathway position\n",
    "        self.mask_queries = nn.Parameter(torch.randn(1, num_pathways, embed_dim) * 0.02)\n",
    "        \n",
    "        self.rope = RotaryEmbedding(embed_dim)\n",
    "        \n",
    "        self.blocks = nn.ModuleList([\n",
    "            PredictorBlock(embed_dim, heads, action_dim) for _ in range(depth)\n",
    "        ])\n",
    "        \n",
    "        self.final_norm = AdaLN(embed_dim, action_dim)\n",
    "\n",
    "    def forward(self, context_latents, action_ids):\n",
    "        \"\"\"\n",
    "        context_latents: [Batch, N, Dim] (From Student Encoder)\n",
    "        action_ids: [Batch] (Ints)\n",
    "        \"\"\"\n",
    "        B, N, D = context_latents.shape\n",
    "        \n",
    "        # 1. Embed Action\n",
    "        action_emb = self.action_embed(action_ids) # [B, Action_Dim]\n",
    "        \n",
    "        # 2. Construct Input: Context + Mask Queries\n",
    "        # In V-JEPA, the predictor takes the context AND the queries for what to predict.\n",
    "        # Since we are predicting the *entire* next state (Treated), we concatenate:\n",
    "        # [Context_State (RoPE pos 0..N), Mask_Queries (RoPE pos N..2N)]\n",
    "        # However, for biological simplicity, we can just treat this as a transformation:\n",
    "        # We want to transform Context -> Predicted Target.\n",
    "        \n",
    "        # STRICT V-JEPA APPROACH:\n",
    "        # The predictor runs on the Queries, attending to the Context.\n",
    "        # It does NOT process the context deeply again.\n",
    "        \n",
    "        queries = self.mask_queries.repeat(B, 1, 1) # [B, N, D]\n",
    "        \n",
    "        # We concat for attention purposes (Cross-attention is cleaner, but V-JEPA uses single stream)\n",
    "        # Input Sequence: [Context, Queries]\n",
    "        sequence = torch.cat([context_latents, queries], dim=1)\n",
    "        \n",
    "        # RoPE: Need to handle the extended sequence length (2N)\n",
    "        cos, sin = self.rope(sequence)\n",
    "        cos, sin = cos.to(sequence.device), sin.to(sequence.device)\n",
    "        \n",
    "        # 3. Pass through AdaLN Blocks\n",
    "        for block in self.blocks:\n",
    "            sequence = block(sequence, action_emb, cos, sin)\n",
    "            \n",
    "        sequence = self.final_norm(sequence, action_emb)\n",
    "        \n",
    "        # 4. Return only the predicted part (The Queries)\n",
    "        # We discard the processed context\n",
    "        predictions = sequence[:, N:, :] \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb48919-caa3-4d81-93d0-dca2d4d30f96",
   "metadata": {},
   "source": [
    "## Bio-JEPA AC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16297aa1-3670-4b89-9e3a-19cfab546ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BioVJepa2(nn.Module):\n",
    "    def __init__(self, num_pathways=1024, embed_dim=384):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.student = PathwayEncoder(num_pathways, embed_dim)\n",
    "        self.teacher = copy.deepcopy(self.student)\n",
    "        \n",
    "        # Freeze teacher\n",
    "        for p in self.teacher.parameters():\n",
    "            p.requires_grad = False\n",
    "            \n",
    "        self.predictor = ACPredictor(embed_dim=embed_dim, action_dim=256, num_pathways=num_pathways)\n",
    "        \n",
    "    def forward(self, x_control, x_treated, action_id):\n",
    "        # 1. Teacher encodes the Target (Treated)\n",
    "        with torch.no_grad():\n",
    "            target_latents = self.teacher(x_treated)\n",
    "            \n",
    "        # 2. Student encodes the Context (Control)\n",
    "        # (Optional: Add masking here if you want extra difficulty, \n",
    "        # but the task Control->Treated is already hard enough)\n",
    "        context_latents = self.student(x_control)\n",
    "        \n",
    "        # 3. Predictor tries to guess Target given Context + Action\n",
    "        predicted_latents = self.predictor(context_latents, action_id)\n",
    "        \n",
    "        # 4. Latent Loss (L1)\n",
    "        loss = F.l1_loss(predicted_latents, target_latents)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def update_teacher(self, m=0.996):\n",
    "        for param_s, param_t in zip(self.student.parameters(), self.teacher.parameters()):\n",
    "            param_t.data.mul_(m).add_((1 - m) * param_s.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdbd6fb-ec72-4af9-ba48-13d7731c3343",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96184936-3410-4d44-8be1-e01ed3c7cc9e",
   "metadata": {},
   "source": [
    "#### Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6dfbb5f-2a56-4709-a9a2-9ab3fe0973a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa')\n",
    "shard_dir = data_dir / 'tokenized'\n",
    "metadata_path = data_dir / 'perturbation_map.json'\n",
    "checkpoint_dir = data_dir / 'checkpoint'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7885c628-45b4-4c23-97e5-e3ee6f0400e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "# Steps/epoch = 29 (files) *10000 (chunk size) /8 (batch size) \n",
    "epoch_steps = 900\n",
    "n_embd = 8\n",
    "n_pathways = 1024\n",
    "LR = 1e-3\n",
    "EPOCHS = 2\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "QUANTIZATION_MAX = 20.0 # Must match tokenizer\n",
    "tok_file_chunk_size = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39a1967a-562d-4772-904a-d1092ba2cf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedShardDataset(Dataset):\n",
    "    def __init__(self, shard_dir):\n",
    "        self.files = sorted(shard_dir.glob('*.npz'))\n",
    "        print(f'Found {len(self.files)} shards.')\n",
    "        \n",
    "    def __len__(self):\n",
    "        # Approx length for progress bar (10k per shard)\n",
    "        return len(self.files) * tok_file_chunk_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Stochastic loading: Pick random shard, then random row\n",
    "        # This avoids loading 100MB files for just one item in strict order\n",
    "        file_path = self.files[np.random.randint(len(self.files))]\n",
    "        \n",
    "        # Load shard (fast if on SSD)\n",
    "        try:\n",
    "            with np.load(file_path) as data:\n",
    "                # Keys: 'control', 'treated', 'action_ids'\n",
    "                n_rows = data['action_ids'].shape[0]\n",
    "                row_idx = np.random.randint(n_rows)\n",
    "                \n",
    "                c_raw = data['control'][row_idx]\n",
    "                t_raw = data['treated'][row_idx]\n",
    "                act_id = data['action_ids'][row_idx]\n",
    "        except Exception as e:\n",
    "            # Fallback for corrupt shard\n",
    "            print(f\"Error loading {file_path}: {e}\")\n",
    "            return self.__getitem__(0)\n",
    "\n",
    "        # Dequantize\n",
    "        scale = QUANTIZATION_MAX / (2**32 - 1)\n",
    "        x_control = torch.tensor(c_raw.astype(np.float32) * scale)\n",
    "        x_treated = torch.tensor(t_raw.astype(np.float32) * scale)\n",
    "        action_id = torch.tensor(act_id, dtype=torch.long)\n",
    "        \n",
    "        return x_control, x_treated, action_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0202749-f533-40fd-a891-08f9c9ff8edb",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "723366c9-4869-408a-b1bc-f2dba2f913ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BioVJepa2(num_pathways=n_pathways, embed_dim=n_embd).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ff27eb-93fa-439c-a31d-366dff143d7d",
   "metadata": {},
   "source": [
    "#### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8ff8ba83-7ff9-4a99-92c7-1fec94759781",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57196ead-30ec-4098-a645-9ec7bdf3a300",
   "metadata": {},
   "source": [
    "#### Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e95819c7-d216-4a1b-93cc-467a20311ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=LR, steps_per_epoch=epoch_steps, epochs=EPOCHS, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f022bc1-b281-4ba4-a38a-5c245ce354df",
   "metadata": {},
   "source": [
    "#### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "037e931a-d57a-4e2a-b7e1-349126321bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 shards.\n"
     ]
    }
   ],
   "source": [
    "dataset = PairedShardDataset(shard_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69bfd331-4e87-4957-8ff9-94fe5d1233c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89952bd9-d632-44db-ae1e-0063389ff31f",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "62bc4b56-b682-4b56-922e-ef040ab8d29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "step = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "96cee680-aa5a-464f-99ef-27b5c758d21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Step 0 | Loss: 0.03244 | LR: 4.03e-05\n",
      "Epoch 0 | Step 10 | Loss: 0.03172 | LR: 7.57e-05\n",
      "Epoch 0 | Step 20 | Loss: 0.02705 | LR: 1.66e-04\n",
      "Epoch 0 | Step 30 | Loss: 0.02096 | LR: 3.00e-04\n",
      "Epoch 0 | Step 40 | Loss: 0.02006 | LR: 4.61e-04\n",
      "Epoch 0 | Step 50 | Loss: 0.02163 | LR: 6.29e-04\n",
      "Epoch 0 | Step 60 | Loss: 0.02477 | LR: 7.84e-04\n",
      "Epoch 0 | Step 70 | Loss: 0.02900 | LR: 9.06e-04\n",
      "Epoch 0 | Step 80 | Loss: 0.03065 | LR: 9.81e-04\n",
      "Epoch 0 | Step 90 | Loss: 0.03458 | LR: 1.00e-03\n",
      "Epoch 0 | Step 100 | Loss: 0.03511 | LR: 1.00e-03\n",
      "Epoch 0 | Step 110 | Loss: 0.02865 | LR: 1.00e-03\n",
      "Epoch 0 | Step 120 | Loss: 0.03264 | LR: 9.99e-04\n",
      "Epoch 0 | Step 130 | Loss: 0.02944 | LR: 9.99e-04\n",
      "Epoch 0 | Step 140 | Loss: 0.02590 | LR: 9.98e-04\n",
      "Epoch 0 | Step 150 | Loss: 0.03171 | LR: 9.97e-04\n",
      "Epoch 0 | Step 160 | Loss: 0.03044 | LR: 9.96e-04\n",
      "Epoch 0 | Step 170 | Loss: 0.03206 | LR: 9.94e-04\n",
      "Epoch 0 | Step 180 | Loss: 0.02859 | LR: 9.93e-04\n",
      "Epoch 0 | Step 190 | Loss: 0.02837 | LR: 9.91e-04\n",
      "Epoch 0 | Step 200 | Loss: 0.02724 | LR: 9.89e-04\n",
      "Epoch 0 | Step 210 | Loss: 0.02497 | LR: 9.87e-04\n",
      "Epoch 0 | Step 220 | Loss: 0.02691 | LR: 9.85e-04\n",
      "Epoch 0 | Step 230 | Loss: 0.02887 | LR: 9.83e-04\n",
      "Epoch 0 | Step 240 | Loss: 0.02380 | LR: 9.81e-04\n",
      "Epoch 0 | Step 250 | Loss: 0.02454 | LR: 9.78e-04\n",
      "Epoch 0 | Step 260 | Loss: 0.02429 | LR: 9.75e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m total_loss = \u001b[32m0\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# We manually limit steps per epoch to avoid iterating infinite stochastic loader\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# or just iterate a fixed number of batches\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maid\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mxc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/site-packages/torch/utils/data/dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/site-packages/torch/utils/data/dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mPairedShardDataset.__getitem__\u001b[39m\u001b[34m(self, idx)\u001b[39m\n\u001b[32m     20\u001b[39m         row_idx = np.random.randint(n_rows)\n\u001b[32m     22\u001b[39m         c_raw = data[\u001b[33m'\u001b[39m\u001b[33mcontrol\u001b[39m\u001b[33m'\u001b[39m][row_idx]\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m         t_raw = \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtreated\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m[row_idx]\n\u001b[32m     24\u001b[39m         act_id = data[\u001b[33m'\u001b[39m\u001b[33maction_ids\u001b[39m\u001b[33m'\u001b[39m][row_idx]\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     26\u001b[39m     \u001b[38;5;66;03m# Fallback for corrupt shard\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/site-packages/numpy/lib/_npyio_impl.py:257\u001b[39m, in \u001b[36mNpzFile.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28mbytes\u001b[39m.seek(\u001b[32m0\u001b[39m)\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m magic == \u001b[38;5;28mformat\u001b[39m.MAGIC_PREFIX:\n\u001b[32m    249\u001b[39m     \u001b[38;5;66;03m# FIXME: This seems like it will copy strings around\u001b[39;00m\n\u001b[32m    250\u001b[39m     \u001b[38;5;66;03m#   more than is strictly necessary.  The zipfile\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    255\u001b[39m     \u001b[38;5;66;03m#   (or at least uncompress) the data\u001b[39;00m\n\u001b[32m    256\u001b[39m     \u001b[38;5;66;03m#   directly into the array memory.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mbytes\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_header_size\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mbytes\u001b[39m.read()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/site-packages/numpy/lib/_format_impl.py:869\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    867\u001b[39m             read_count = \u001b[38;5;28mmin\u001b[39m(max_read_count, count - i)\n\u001b[32m    868\u001b[39m             read_size = \u001b[38;5;28mint\u001b[39m(read_count * dtype.itemsize)\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m             data = \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marray data\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    870\u001b[39m             array[i:i + read_count] = numpy.frombuffer(data, dtype=dtype,\n\u001b[32m    871\u001b[39m                                                      count=read_count)\n\u001b[32m    873\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m array.size != count:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/site-packages/numpy/lib/_format_impl.py:1013\u001b[39m, in \u001b[36m_read_bytes\u001b[39m\u001b[34m(fp, size, error_template)\u001b[39m\n\u001b[32m   1008\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1009\u001b[39m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[32m   1010\u001b[39m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[32m   1011\u001b[39m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[32m   1012\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m         r = \u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1014\u001b[39m         data += r\n\u001b[32m   1015\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) == \u001b[32m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) == size:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/zipfile/__init__.py:1015\u001b[39m, in \u001b[36mZipExtFile.read\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1013\u001b[39m \u001b[38;5;28mself\u001b[39m._offset = \u001b[32m0\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m n > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n\u001b[32m-> \u001b[39m\u001b[32m1015\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n < \u001b[38;5;28mlen\u001b[39m(data):\n\u001b[32m   1017\u001b[39m         \u001b[38;5;28mself\u001b[39m._readbuffer = data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/general/lib/python3.13/zipfile/__init__.py:1091\u001b[39m, in \u001b[36mZipExtFile._read1\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compress_type == ZIP_DEFLATED:\n\u001b[32m   1090\u001b[39m     n = \u001b[38;5;28mmax\u001b[39m(n, \u001b[38;5;28mself\u001b[39m.MIN_READ_SIZE)\n\u001b[32m-> \u001b[39m\u001b[32m1091\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decompressor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m     \u001b[38;5;28mself\u001b[39m._eof = (\u001b[38;5;28mself\u001b[39m._decompressor.eof \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1093\u001b[39m                  \u001b[38;5;28mself\u001b[39m._compress_left <= \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m   1094\u001b[39m                  \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decompressor.unconsumed_tail)\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._eof:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    # We manually limit steps per epoch to avoid iterating infinite stochastic loader\n",
    "    # or just iterate a fixed number of batches\n",
    "    for i, (xc, xt, aid) in enumerate(loader):\n",
    "        xc, xt, aid = xc.to(DEVICE), xt.to(DEVICE), aid.to(DEVICE)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = model(xc, xt, aid)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update Teacher (V-JEPA Momentum)\n",
    "        model.update_teacher(m=0.996)\n",
    "\n",
    "        if scheduler.last_epoch < scheduler.total_steps:\n",
    "            scheduler.step()\n",
    "\n",
    "        lossi.append(loss.item())\n",
    "        total_loss += loss.item()\n",
    "        step += 1\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(f\"Epoch {epoch} | Step {i} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "        \n",
    "        if i >= epoch_steps: # End epoch after 2000 batches\n",
    "            break\n",
    "            \n",
    "    avg_loss = total_loss / epoch_steps\n",
    "    \n",
    "    print(f\"=== Epoch {epoch} Done. Avg Loss: {avg_loss:.5f} ===\")\n",
    "    \n",
    "    # Save Checkpoint\n",
    "    torch.save({\n",
    "        'model': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "        'epoch': epoch\n",
    "    }, checkpoint_dir / f'bio_jepa_ckpt_{epoch}.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4972cdbf-7fd0-4b3b-a541-16135d079c2c",
   "metadata": {},
   "source": [
    "#### Training Loss Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "43c293fa-2067-45b9-ad55-e6127515bb37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lossi)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fe89a-0447-48d3-9252-9153efcab902",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "45916c9b-5f07-4aec-a9ac-e0635bae92a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PosixPath('/Users/djemec/data/jepa/perturbation_map.json'),\n",
       " PosixPath('/Users/djemec/data/jepa/tokenized'))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata_path, shard_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "54c35355-2ff6-486d-9ce8-e4cbbbee1599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load Map (ID -> Name)\n",
    "with open(metadata_path, \"r\") as f:\n",
    "    pert_map = json.load(f)\n",
    "# Invert map to: ID -> Name\n",
    "id_to_name = {v: k for k, v in pert_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "24ae854c-4e74-42f5-9cfd-0c487ff22549",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BioVJepa2(\n",
       "  (student): PathwayEncoder(\n",
       "    (input_proj): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (rope): RotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x BioEncoderBlock(\n",
       "        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (teacher): PathwayEncoder(\n",
       "    (input_proj): Linear(in_features=1, out_features=8, bias=True)\n",
       "    (rope): RotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-11): 12 x BioEncoderBlock(\n",
       "        (norm1): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (norm2): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (predictor): ACPredictor(\n",
       "    (action_embed): Embedding(3000, 256)\n",
       "    (rope): RotaryEmbedding()\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x PredictorBlock(\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=8, out_features=8, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=8, out_features=32, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=32, out_features=8, bias=True)\n",
       "        )\n",
       "        (ada_ln1): AdaLN(\n",
       "          (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=False)\n",
       "          (action_mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (ada_ln2): AdaLN(\n",
       "          (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=False)\n",
       "          (action_mlp): Sequential(\n",
       "            (0): SiLU()\n",
       "            (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_norm): AdaLN(\n",
       "      (norm): LayerNorm((8,), eps=1e-05, elementwise_affine=False)\n",
       "      (action_mlp): Sequential(\n",
       "        (0): SiLU()\n",
       "        (1): Linear(in_features=256, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09550430-309d-436c-a140-2bda3fb8bde3",
   "metadata": {},
   "source": [
    "**Get random data sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "189729ef-8852-466c-b05b-455948aa6cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_test_pair(shard_dir):\n",
    "    '''Grab a single real pair from a random shard'''\n",
    "    files = sorted(shard_dir.glob('*.npz'))\n",
    "    file_path = files[np.random.randint(len(files))]\n",
    "    \n",
    "    with np.load(file_path) as data:\n",
    "        idx = np.random.randint(data['action_ids'].shape[0])\n",
    "        \n",
    "        # Extract raw uint32\n",
    "        c_raw = data['control'][idx]\n",
    "        t_raw = data['treated'][idx]\n",
    "        act_id = data['action_ids'][idx]\n",
    "        \n",
    "    # Dequantize\n",
    "    scale = QUANTIZATION_MAX / (2**32 - 1)\n",
    "    x_control = torch.tensor(c_raw.astype(np.float32) * scale).unsqueeze(0).to(DEVICE) # [1, 1024]\n",
    "    x_treated = torch.tensor(t_raw.astype(np.float32) * scale).unsqueeze(0).to(DEVICE)\n",
    "    action_id = torch.tensor([act_id], dtype=torch.long).to(DEVICE)\n",
    "    \n",
    "    return x_control, x_treated, action_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "793361fe-baee-42b7-982d-72e604d28013",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ARGLU1'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_control, x_real_treated, action_id = get_random_test_pair(shard_dir)\n",
    "pert_name = id_to_name[action_id.item()]\n",
    "pert_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "75e32d24-4c56-40fc-9d76-3048536eddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Get Baselines (Teacher View)\n",
    "# We need the Teacher to tell us where the \"Control\" and \"Real Treated\" \n",
    "# sit in the abstract latent space.\n",
    "with torch.no_grad():\n",
    "    z_control = model.teacher(x_control)       # Where the cell started\n",
    "    z_real = model.teacher(x_real_treated)     # Where the cell actually went"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "054228e3-73d0-48da-9b7f-2f80be87cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Run The Physics Engine (Predictor)\n",
    "# Student encodes context -> Predictor adds Action -> Output\n",
    "with torch.no_grad():\n",
    "    z_context = model.student(x_control)\n",
    "    z_predicted = model.predictor(z_context, action_id) # Where the model thinks it went"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5360c5-2215-4fc8-858a-d1488cf54ab6",
   "metadata": {},
   "source": [
    "**Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "49851bf2-12f7-4de4-9b3f-efbd1bac2c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.013011535629630089"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric 1: Baseline Drift (How much did the drug actually change the cell?)\n",
    "# If this is 0, the drug did nothing, so prediction is trivial.\n",
    "drift = F.l1_loss(z_control, z_real).item()\n",
    "drift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "19a65de9-8f27-4f96-b304-07272e5367f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.012903341092169285"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric 2: Prediction Error (How close is our guess to the real result?)\n",
    "error = F.l1_loss(z_predicted, z_real).item()\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "00cbe219-8cfa-4d15-a09f-999de53f87bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.017940839752554893"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Metric 3: Simulation Magnitude (How much did our model decide to move the cell?)\n",
    "sim_move = F.l1_loss(z_predicted, z_control).item()\n",
    "sim_move"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "cdb7a8ae-c7ac-4bf5-8aca-ca82af1f57fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Result Interpretation]\n",
      "âœ… SUCCESS: The model predicted the state shift!\n",
      "   The prediction is 0.8% closer to the truth than the Control state was.\n"
     ]
    }
   ],
   "source": [
    "# --- INTERPRETATION ---\n",
    "print(f\"[Result Interpretation]\")\n",
    "if drift < 0.01:\n",
    "    print(f\"âš ï¸  WEAK SIGNAL: This perturbation didn't change the cell much in reality.\")\n",
    "elif error < drift:\n",
    "    improvement = (1 - (error / drift)) * 100\n",
    "    print(f\"âœ… SUCCESS: The model predicted the state shift!\")\n",
    "    print(f\"   The prediction is {improvement:.1f}% closer to the truth than the Control state was.\")\n",
    "else:\n",
    "    print(f\"âŒ FAILURE: The model failed to capture the dynamics.\")\n",
    "    print(f\"   It would have been better to just guess 'Nothing Happened'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "03a7c686-6b68-4975-add4-f8178fdf3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Top Active Latent Dimensions]\n",
      "Dimensions [[1, 0, 3, 7, 2], [1, 7, 5, 2, 3], [1, 0, 3, 7, 2], [0, 1, 7, 5, 3], [1, 0, 3, 2, 6], [0, 1, 7, 4, 3], [0, 7, 1, 2, 3], [0, 7, 1, 2, 5], [0, 1, 5, 3, 6], [1, 7, 5, 2, 3], [1, 7, 2, 5, 3], [1, 0, 5, 3, 7], [1, 0, 3, 7, 4], [1, 0, 3, 6, 4], [1, 0, 6, 3, 5], [1, 0, 3, 2, 5], [1, 0, 7, 3, 6], [1, 0, 2, 3, 4], [1, 0, 3, 4, 6], [1, 2, 7, 5, 6], [1, 0, 4, 3, 5], [0, 1, 7, 6, 2], [1, 0, 4, 7, 6], [1, 0, 7, 4, 3], [1, 7, 5, 4, 0], [1, 7, 0, 5, 3], [1, 7, 5, 2, 4], [1, 7, 5, 2, 4], [1, 7, 5, 2, 4], [1, 0, 5, 7, 4], [1, 7, 5, 2, 4], [1, 7, 5, 0, 4], [0, 7, 2, 3, 4], [0, 1, 7, 6, 4], [1, 0, 7, 5, 4], [1, 7, 2, 5, 0], [1, 7, 5, 4, 0], [0, 7, 1, 2, 4], [1, 0, 7, 3, 6], [1, 7, 5, 2, 0], [1, 0, 6, 3, 4], [1, 0, 7, 5, 2], [7, 0, 2, 5, 6], [7, 0, 2, 5, 3], [0, 7, 1, 2, 6], [1, 7, 5, 2, 6], [1, 2, 0, 4, 5], [7, 0, 2, 5, 3], [1, 0, 3, 6, 7], [0, 1, 7, 4, 3], [1, 0, 5, 7, 4], [1, 0, 3, 5, 6], [0, 1, 7, 2, 3], [1, 7, 5, 2, 3], [0, 1, 7, 3, 4], [7, 0, 2, 5, 3], [1, 5, 7, 0, 2], [1, 0, 7, 5, 3], [0, 2, 7, 6, 4], [7, 0, 2, 5, 6], [1, 7, 5, 2, 3], [1, 7, 5, 2, 0], [1, 7, 5, 2, 3], [1, 7, 2, 5, 0], [0, 7, 2, 3, 1], [1, 0, 5, 7, 4], [1, 5, 0, 3, 4], [1, 7, 5, 2, 3], [1, 7, 2, 5, 0], [1, 7, 5, 0, 3], [0, 7, 1, 2, 3], [1, 7, 2, 5, 0], [0, 1, 7, 5, 6], [1, 7, 2, 5, 0], [0, 1, 7, 5, 3], [1, 0, 5, 3, 4], [0, 7, 5, 1, 2], [1, 5, 0, 7, 4], [0, 1, 7, 2, 4], [0, 1, 7, 4, 3], [1, 0, 4, 3, 5], [1, 0, 3, 4, 5], [1, 0, 3, 6, 5], [1, 7, 5, 4, 0], [1, 7, 5, 4, 0], [1, 7, 5, 2, 0], [1, 0, 4, 3, 2], [1, 0, 4, 7, 3], [1, 0, 7, 5, 4], [1, 0, 3, 2, 6], [1, 0, 4, 7, 2], [0, 1, 7, 2, 4], [1, 0, 7, 4, 3], [1, 0, 3, 5, 7], [0, 1, 7, 3, 6], [1, 7, 2, 5, 0], [1, 7, 5, 2, 4], [1, 7, 2, 5, 0], [1, 0, 7, 5, 6], [0, 7, 2, 1, 5], [0, 1, 7, 3, 6], [1, 7, 5, 2, 0], [0, 7, 2, 1, 3], [1, 0, 2, 7, 6], [0, 1, 7, 6, 3], [7, 0, 2, 5, 6], [0, 7, 6, 4, 2], [1, 0, 5, 4, 6], [1, 7, 5, 0, 4], [1, 7, 5, 2, 6], [1, 7, 2, 5, 0], [1, 0, 3, 6, 4], [1, 0, 3, 7, 6], [7, 1, 2, 0, 5], [1, 7, 5, 2, 6], [7, 0, 2, 5, 6], [1, 0, 3, 6, 5], [1, 0, 5, 3, 2], [1, 0, 7, 3, 4], [7, 0, 2, 5, 6], [1, 7, 2, 5, 3], [1, 7, 2, 0, 5], [1, 0, 3, 7, 2], [1, 0, 3, 4, 7], [1, 7, 5, 2, 3], [1, 7, 5, 2, 4], [7, 0, 2, 5, 3], [1, 5, 0, 3, 6], [1, 7, 0, 2, 5], [1, 7, 5, 2, 3], [1, 7, 2, 5, 0], [1, 7, 2, 5, 0], [1, 0, 3, 5, 6], [0, 2, 5, 7, 6], [5, 7, 1, 2, 0], [1, 0, 4, 5, 3], [7, 0, 2, 5, 4], [7, 0, 2, 5, 4], [1, 7, 5, 3, 0], [1, 7, 5, 2, 3], [0, 1, 7, 5, 2], [1, 0, 5, 4, 3], [0, 1, 7, 4, 6], [1, 7, 5, 2, 3], [1, 7, 5, 0, 4], [1, 0, 6, 4, 3], [0, 7, 2, 1, 3], [0, 1, 2, 4, 7], [7, 0, 2, 5, 1], [1, 0, 4, 7, 3], [1, 0, 3, 4, 5], [1, 7, 2, 5, 3], [1, 7, 5, 4, 0], [1, 0, 6, 2, 3], [1, 0, 7, 4, 5], [1, 0, 3, 6, 4], [1, 0, 5, 3, 4], [0, 1, 2, 3, 7], [1, 7, 0, 5, 6], [1, 7, 5, 2, 4], [0, 7, 2, 5, 1], [1, 0, 3, 4, 5], [1, 7, 5, 2, 4], [1, 7, 5, 2, 4], [1, 0, 5, 6, 3], [1, 7, 5, 0, 2], [1, 7, 5, 0, 2], [1, 7, 5, 0, 2], [1, 7, 5, 0, 2], [1, 0, 5, 7, 4], [0, 1, 7, 2, 6], [1, 0, 5, 7, 6], [0, 1, 7, 2, 3], [0, 7, 2, 1, 5], [1, 0, 5, 7, 4], [0, 1, 7, 2, 3], [1, 7, 2, 5, 3], [0, 2, 4, 6, 7], [1, 0, 3, 7, 6], [1, 0, 3, 4, 5], [1, 7, 5, 2, 4], [1, 7, 5, 2, 4], [1, 7, 0, 5, 2], [1, 7, 0, 5, 2], [1, 7, 5, 2, 4], [0, 7, 2, 3, 1], [1, 7, 2, 5, 0], [1, 0, 3, 5, 4], [1, 7, 5, 2, 3], [1, 0, 3, 5, 7], [1, 0, 7, 3, 5], [1, 0, 5, 7, 3], [1, 7, 5, 2, 3], [7, 0, 2, 5, 6], [1, 0, 5, 3, 2], [1, 7, 5, 2, 0], [1, 7, 5, 2, 3], [1, 7, 2, 5, 3], [1, 7, 5, 2, 0], [0, 7, 2, 1, 3], [1, 0, 3, 4, 6], [0, 1, 7, 2, 3], [1, 0, 3, 7, 6], [0, 7, 2, 5, 4], [0, 1, 4, 7, 2], [1, 7, 0, 5, 4], [0, 7, 1, 2, 4], [0, 1, 7, 3, 2], [1, 7, 5, 0, 3], [1, 0, 7, 6, 3], [0, 1, 7, 2, 4], [0, 1, 4, 2, 5], [1, 7, 5, 4, 3], [1, 7, 5, 4, 3], [1, 0, 7, 5, 3], [1, 7, 0, 5, 4], [1, 7, 5, 0, 2], [0, 7, 1, 5, 6], [0, 7, 2, 4, 6], [1, 0, 7, 3, 5], [1, 7, 0, 5, 6], [1, 0, 5, 7, 6], [1, 0, 5, 7, 4], [0, 7, 2, 5, 1], [1, 5, 0, 7, 4], [1, 0, 3, 5, 7], [1, 7, 5, 2, 0], [1, 7, 5, 0, 3], [1, 7, 0, 5, 2], [1, 7, 5, 2, 4], [1, 7, 5, 2, 4], [1, 0, 5, 7, 3], [7, 1, 2, 5, 0], [1, 0, 7, 5, 4], [0, 7, 2, 5, 3], [0, 1, 2, 5, 4], [1, 7, 5, 0, 2], [0, 7, 2, 1, 3], [1, 7, 2, 5, 4], [0, 7, 2, 5, 3], [0, 1, 5, 7, 6], [1, 0, 7, 2, 3], [0, 7, 5, 1, 2], [1, 0, 3, 7, 4], [1, 0, 3, 5, 7], [1, 5, 7, 3, 0], [1, 0, 5, 7, 3], [1, 7, 5, 2, 0], [1, 7, 2, 0, 3], [0, 7, 5, 2, 1], [1, 0, 3, 5, 7], [1, 0, 3, 5, 2], [1, 7, 2, 5, 3], [1, 0, 7, 5, 3], [0, 1, 7, 5, 2], [1, 0, 7, 3, 5], [1, 0, 5, 3, 7], [1, 0, 3, 7, 5], [1, 0, 5, 3, 7], [0, 7, 5, 2, 6], [1, 0, 7, 3, 5], [1, 5, 0, 3, 7], [0, 7, 1, 2, 3], [1, 0, 3, 7, 4], [1, 0, 7, 5, 2], [1, 0, 7, 3, 2], [0, 1, 5, 4, 3], [1, 7, 2, 5, 4], [0, 7, 1, 2, 5], [1, 0, 5, 3, 4], [1, 7, 5, 0, 2], [1, 7, 5, 0, 4], [0, 7, 5, 6, 2], [1, 0, 4, 5, 3], [0, 1, 4, 7, 2], [0, 1, 2, 7, 4], [0, 1, 2, 7, 3], [0, 7, 2, 5, 3], [1, 7, 0, 2, 5], [1, 0, 7, 4, 5], [1, 0, 7, 6, 4], [1, 7, 5, 2, 4], [1, 7, 0, 5, 3], [1, 7, 0, 5, 6], [1, 0, 7, 5, 4], [1, 7, 2, 0, 5], [1, 7, 2, 5, 0], [0, 1, 2, 7, 3], [1, 7, 0, 5, 2], [1, 0, 3, 6, 5], [1, 0, 7, 5, 2], [1, 7, 0, 5, 2], [1, 0, 5, 7, 3], [1, 0, 3, 7, 6], [0, 7, 2, 3, 5], [1, 7, 5, 0, 4], [1, 7, 5, 0, 2], [1, 7, 5, 2, 4], [1, 5, 7, 0, 4], [7, 0, 2, 1, 5], [1, 0, 3, 7, 2], [1, 7, 5, 0, 4], [1, 7, 5, 0, 3], [1, 7, 5, 0, 4], [1, 5, 0, 7, 4], [1, 7, 2, 5, 0], [1, 7, 2, 5, 0], [1, 0, 7, 5, 3], [0, 1, 3, 5, 2], [0, 7, 1, 2, 3], [1, 7, 5, 2, 3], [1, 7, 2, 5, 0], [1, 7, 5, 2, 3], [1, 7, 2, 5, 0], [1, 7, 5, 2, 0], [1, 7, 5, 0, 2], [1, 7, 5, 0, 2], [1, 7, 5, 2, 3], [1, 5, 0, 3, 4], [1, 0, 3, 7, 2], [1, 0, 3, 7, 5], [1, 0, 3, 2, 7], [1, 0, 3, 2, 4], [1, 0, 7, 2, 3], [0, 7, 1, 2, 3], [1, 5, 7, 0, 3], [1, 0, 7, 5, 2], [1, 7, 5, 2, 3], [1, 7, 5, 2, 4], [1, 7, 2, 5, 4], [1, 7, 5, 2, 0], [1, 0, 5, 4, 3], [0, 7, 1, 3, 6], [1, 0, 7, 5, 4], [1, 5, 0, 7, 4], [1, 5, 0, 4, 7], [0, 7, 2, 1, 4], [1, 7, 5, 4, 0], [1, 7, 5, 4, 2], [1, 0, 5, 4, 7], [1, 7, 5, 2, 4], [1, 7, 5, 4, 0], [1, 5, 4, 0, 7], [1, 0, 4, 5, 3], [1, 7, 5, 4, 0], [1, 7, 5, 2, 3], [1, 7, 5, 2, 0], [1, 0, 5, 3, 6], [1, 0, 5, 4, 7], [1, 7, 2, 5, 0], [1, 7, 5, 4, 2], [1, 7, 5, 2, 0], [1, 7, 5, 0, 2], [1, 7, 5, 0, 2], [1, 7, 5, 0, 2], [1, 7, 0, 5, 2], [1, 5, 7, 0, 4], [1, 0, 5, 7, 3], [1, 0, 7, 5, 3], [1, 0, 6, 3, 4], [1, 7, 5, 2, 4], [1, 0, 5, 4, 7], [1, 0, 3, 7, 4], [0, 7, 2, 5, 1], [1, 0, 3, 6, 4], [1, 7, 2, 5, 3], [1, 0, 3, 6, 2], [1, 0, 4, 2, 3], [1, 0, 3, 4, 6], [1, 0, 5, 7, 3], [1, 0, 3, 5, 7], [1, 0, 5, 3, 7], [1, 0, 5, 3, 7], [1, 0, 7, 3, 4], [1, 7, 0, 5, 3], [1, 0, 3, 4, 5], [1, 7, 5, 2, 3], [1, 0, 3, 6, 2], [1, 7, 5, 2, 3], [1, 0, 3, 5, 2], [0, 7, 2, 1, 3], [1, 0, 3, 5, 4], [1, 7, 0, 5, 2], [1, 0, 3, 4, 7], [1, 7, 5, 2, 0], [1, 7, 2, 5, 0], [1, 7, 2, 5, 0], [1, 7, 5, 2, 0], [1, 0, 3, 4, 2], [1, 0, 5, 3, 7], [0, 7, 2, 5, 6], [1, 0, 5, 3, 7], [1, 0, 5, 7, 4], [1, 0, 4, 5, 3], [1, 0, 4, 5, 3], [1, 0, 3, 7, 4], [1, 0, 7, 5, 3], [1, 7, 5, 4, 2], [1, 5, 7, 4, 0], [1, 5, 0, 4, 7], [0, 1, 4, 2, 3], [1, 0, 4, 5, 2], [0, 1, 2, 3, 4], [1, 0, 4, 6, 3], [1, 7, 5, 2, 4], [1, 7, 5, 4, 0], [7, 1, 2, 5, 0], [1, 7, 5, 2, 0], [1, 7, 5, 4, 2], [1, 7, 5, 2, 4], [1, 7, 5, 0, 2], [1, 7, 5, 2, 4], [1, 7, 5, 2, 4], [0, 7, 2, 3, 1], [1, 0, 7, 5, 3], [1, 7, 5, 2, 4], [1, 0, 7, 5, 2], [0, 1, 5, 4, 2], [0, 1, 7, 2, 4], [0, 6, 4, 2, 7], [0, 4, 2, 6, 7], [0, 6, 4, 2, 7], [1, 0, 3, 5, 7], [0, 7, 1, 2, 4], [1, 7, 5, 4, 2], [1, 7, 5, 0, 4], [0, 1, 7, 3, 2], [1, 0, 5, 7, 4], [0, 6, 2, 4, 7], [1, 0, 3, 6, 4], [1, 0, 4, 5, 3], [1, 0, 4, 3, 5], [1, 0, 3, 4, 6], [1, 0, 5, 3, 4], [1, 0, 3, 5, 4], [1, 7, 5, 0, 2], [1, 0, 4, 3, 5], [1, 0, 3, 5, 4], [1, 0, 3, 5, 4], [1, 0, 3, 4, 5], [1, 7, 5, 3, 2], [1, 0, 7, 3, 5], [1, 5, 7, 3, 2], [1, 5, 7, 3, 4], [1, 5, 7, 3, 2], [1, 5, 7, 2, 3], [1, 5, 7, 2, 3], [1, 7, 5, 2, 3], [1, 7, 5, 2, 3], [1, 7, 5, 2, 0], [1, 0, 4, 3, 6], [0, 1, 3, 7, 4], [0, 1, 3, 5, 6], [1, 7, 5, 2, 4], [0, 1, 7, 3, 2], [1, 7, 5, 0, 4], [1, 0, 5, 7, 4], [1, 0, 5, 7, 4], [1, 0, 7, 5, 4], [1, 0, 7, 3, 6], [1, 0, 4, 6, 2], [1, 7, 5, 0, 4], [1, 5, 0, 4, 7], [1, 7, 5, 2, 4], [1, 0, 4, 3, 6], [1, 0, 7, 5, 3], [1, 7, 5, 4, 0], [1, 0, 5, 4, 3], [0, 7, 2, 5, 6], [0, 7, 1, 2, 4], [1, 0, 5, 4, 7], [1, 0, 7, 5, 3], [1, 0, 6, 3, 4], [1, 0, 5, 4, 7], [1, 7, 5, 2, 4], [1, 0, 7, 5, 2], [1, 7, 5, 0, 2], [0, 6, 4, 2, 7], [1, 7, 2, 5, 4], [1, 7, 5, 2, 0], [1, 7, 5, 0, 4], [1, 5, 0, 7, 4], [1, 0, 7, 3, 2], [1, 7, 5, 0, 2], [1, 7, 5, 2, 0], [1, 0, 5, 7, 4], [1, 0, 5, 4, 7], [0, 1, 7, 2, 4], [1, 7, 2, 5, 0], [0, 1, 3, 4, 5], [0, 2, 4, 6, 7], [1, 0, 7, 5, 4], [0, 7, 1, 2, 5], [1, 7, 5, 2, 4], [1, 7, 5, 2, 3], [1, 0, 3, 5, 4], [1, 0, 3, 7, 4], [1, 0, 5, 3, 7], [0, 1, 2, 3, 7], [0, 7, 1, 2, 4], [7, 0, 2, 5, 3], [0, 1, 7, 3, 2], [0, 7, 2, 1, 3], [0, 7, 2, 3, 1], [0, 7, 2, 5, 3], [0, 7, 2, 1, 3], [0, 7, 1, 2, 3], [1, 0, 3, 5, 6], [1, 7, 5, 2, 3], [1, 7, 0, 5, 3], [1, 0, 3, 7, 4], [1, 7, 0, 5, 2], [1, 7, 5, 2, 0], [1, 0, 7, 2, 5], [1, 0, 5, 3, 7], [1, 0, 3, 6, 7], [1, 7, 5, 0, 3], [0, 1, 7, 2, 4], [0, 1, 7, 4, 2], [1, 0, 4, 6, 3], [1, 0, 3, 4, 2], [1, 7, 2, 5, 0], [1, 0, 2, 3, 4], [0, 1, 2, 7, 4], [0, 1, 7, 4, 2], [1, 7, 5, 4, 2], [1, 7, 5, 2, 4], [1, 7, 5, 0, 4], [1, 0, 3, 7, 6], [0, 4, 6, 2, 7], [1, 0, 7, 2, 5], [0, 7, 2, 1, 4], [0, 7, 2, 4, 3], [7, 0, 2, 5, 6], [1, 7, 2, 5, 6], [1, 0, 6, 7, 3], [1, 0, 6, 3, 2], [1, 0, 7, 2, 5], [1, 0, 5, 7, 4], [1, 0, 5, 3, 4], [1, 0, 7, 5, 3], [1, 0, 5, 3, 6], [1, 0, 7, 3, 2], [1, 0, 5, 7, 4], [1, 7, 5, 2, 4], [1, 0, 5, 3, 7], [0, 7, 1, 2, 3], [1, 0, 5, 6, 3], [7, 0, 2, 5, 6], [1, 5, 7, 4, 0], [7, 0, 2, 5, 6], [0, 1, 7, 2, 3], [0, 7, 2, 3, 4], [7, 1, 2, 0, 5], [1, 7, 5, 0, 2], [0, 1, 2, 7, 3], [1, 0, 3, 6, 4], [1, 7, 2, 5, 0], [1, 0, 3, 5, 4], [0, 7, 2, 1, 3], [0, 7, 2, 5, 3], [0, 1, 2, 5, 3], [0, 2, 7, 5, 4], [0, 7, 1, 2, 3], [1, 7, 5, 2, 3], [1, 5, 7, 3, 2], [1, 7, 5, 2, 3], [1, 7, 5, 2, 3], [1, 7, 5, 2, 3], [1, 7, 5, 2, 0], [1, 0, 3, 6, 4], [0, 1, 7, 3, 2], [1, 0, 5, 3, 6], [1, 7, 5, 0, 2], [1, 0, 5, 3, 4], [0, 1, 7, 4, 3], [0, 1, 7, 4, 2], [0, 1, 7, 2, 3], [1, 0, 5, 7, 3], [0, 2, 7, 6, 4], [1, 7, 5, 2, 4], [1, 7, 5, 2, 0], [1, 7, 5, 0, 2], [1, 7, 0, 5, 4], [1, 0, 5, 4, 3], [1, 0, 4, 3, 6], [0, 1, 4, 2, 7], [1, 0, 4, 7, 5], [1, 7, 0, 5, 4], [1, 0, 4, 3, 6], [1, 0, 5, 4, 7], [1, 7, 5, 2, 4], [0, 7, 2, 5, 6], [7, 0, 2, 5, 6], [7, 0, 5, 2, 6], [1, 0, 3, 7, 6], [1, 0, 2, 3, 7], [1, 0, 2, 7, 3], [1, 0, 5, 2, 4], [1, 0, 5, 7, 4], [1, 7, 5, 0, 4], [1, 7, 5, 4, 2], [1, 0, 2, 3, 5], [1, 0, 2, 3, 5], [0, 1, 6, 3, 5], [1, 7, 5, 0, 4], [1, 7, 5, 2, 4], [1, 7, 5, 0, 2], [1, 5, 7, 0, 4], [1, 0, 7, 3, 6], [0, 1, 6, 3, 5], [1, 7, 5, 2, 4], [1, 5, 7, 0, 4], [1, 0, 5, 4, 6], [1, 0, 3, 7, 4], [1, 7, 5, 2, 0], [0, 1, 7, 5, 2], [0, 7, 1, 2, 5], [0, 7, 2, 5, 1], [0, 7, 2, 5, 1], [0, 7, 1, 2, 5], [1, 7, 5, 2, 3], [1, 0, 3, 7, 2], [0, 1, 3, 2, 5], [1, 0, 3, 5, 4], [1, 0, 3, 6, 7], [0, 1, 7, 3, 2], [1, 7, 2, 5, 3], [1, 7, 5, 3, 2], [1, 0, 3, 6, 5], [1, 0, 3, 7, 2], [0, 7, 2, 3, 6], [1, 7, 2, 5, 3], [0, 7, 2, 1, 3], [1, 0, 3, 7, 2], [7, 0, 2, 5, 6], [0, 2, 7, 4, 5], [0, 2, 4, 7, 6], [0, 7, 2, 5, 6], [1, 0, 3, 5, 4], [1, 7, 5, 0, 2], [1, 0, 3, 6, 2], [7, 0, 2, 5, 6], [0, 1, 7, 2, 6], [1, 2, 7, 5, 6], [1, 0, 3, 4, 6], [1, 0, 5, 4, 3], [1, 0, 3, 4, 6], [1, 7, 5, 0, 3], [0, 7, 2, 5, 4], [1, 0, 4, 3, 5], [1, 0, 4, 3, 5], [1, 2, 0, 7, 3], [1, 0, 4, 3, 5], [1, 7, 5, 2, 4], [1, 7, 5, 4, 6], [1, 2, 7, 5, 6], [0, 7, 2, 5, 6], [0, 1, 7, 4, 3], [1, 0, 3, 4, 7], [1, 0, 3, 6, 2], [1, 0, 7, 5, 3], [1, 0, 5, 7, 4], [1, 7, 5, 2, 4], [1, 0, 3, 6, 4], [1, 0, 3, 6, 7], [1, 7, 5, 2, 4], [1, 0, 3, 6, 2], [1, 0, 2, 5, 3], [1, 7, 5, 2, 4], [1, 0, 5, 3, 6], [1, 0, 5, 7, 3], [1, 7, 5, 0, 2], [0, 1, 2, 6, 3], [0, 1, 7, 2, 3], [1, 0, 4, 5, 6], [1, 0, 7, 5, 6], [1, 0, 3, 4, 6], [1, 0, 5, 3, 4], [1, 0, 7, 5, 3], [1, 0, 6, 3, 5], [1, 0, 3, 5, 6], [1, 5, 0, 7, 3], [1, 0, 3, 5, 4], [0, 1, 3, 5, 7], [1, 0, 5, 3, 7], [0, 7, 2, 1, 3], [1, 0, 3, 5, 6], [0, 1, 7, 3, 5], [0, 7, 2, 5, 6], [1, 0, 3, 7, 4], [1, 0, 3, 5, 7], [0, 7, 1, 3, 2], [7, 0, 2, 5, 6], [1, 0, 7, 3, 6], [0, 7, 2, 5, 6], [1, 7, 0, 3, 2], [1, 0, 3, 7, 2], [1, 7, 5, 0, 2], [1, 7, 5, 2, 3], [1, 7, 2, 5, 0], [1, 7, 2, 5, 3], [0, 1, 7, 2, 3], [0, 7, 2, 3, 1], [1, 7, 5, 2, 3], [1, 7, 5, 2, 3], [1, 0, 3, 4, 6], [0, 4, 2, 7, 6], [1, 0, 4, 7, 3], [1, 7, 5, 2, 4], [1, 0, 5, 7, 4], [1, 7, 0, 5, 4], [0, 7, 2, 1, 4], [1, 0, 4, 6, 7], [1, 7, 2, 5, 0], [1, 0, 7, 4, 3], [7, 1, 2, 0, 5], [1, 7, 5, 2, 4], [1, 0, 6, 7, 4], [1, 0, 4, 6, 3], [1, 7, 5, 0, 2], [1, 7, 5, 4, 3], [1, 7, 0, 2, 3], [7, 0, 2, 5, 1], [1, 7, 5, 0, 2], [1, 0, 7, 5, 6], [1, 7, 5, 0, 2], [1, 7, 5, 2, 4], [1, 7, 0, 5, 2], [1, 7, 5, 2, 4], [1, 0, 5, 6, 7], [1, 0, 7, 2, 5], [1, 0, 5, 6, 3], [1, 7, 5, 2, 0], [1, 7, 0, 2, 3], [1, 7, 5, 2, 0], [1, 7, 5, 0, 3], [1, 7, 0, 5, 2], [1, 7, 5, 2, 4], [1, 7, 2, 5, 3], [0, 1, 7, 3, 2], [0, 1, 3, 7, 2], [0, 1, 2, 3, 6], [1, 0, 7, 5, 2], [1, 7, 5, 2, 4], [1, 0, 3, 6, 7], [0, 1, 7, 3, 2], [1, 0, 5, 7, 3], [1, 0, 3, 7, 5], [1, 0, 5, 3, 7], [1, 7, 5, 2, 4], [1, 7, 5, 2, 3], [0, 1, 3, 7, 2], [0, 7, 2, 5, 4], [1, 0, 3, 6, 5], [0, 7, 2, 1, 3], [1, 7, 2, 5, 4], [0, 1, 7, 3, 2], [0, 7, 1, 2, 5], [0, 7, 1, 2, 3], [0, 7, 1, 2, 3], [1, 7, 2, 5, 6], [1, 7, 2, 5, 3], [1, 7, 5, 0, 2], [1, 7, 2, 5, 0], [0, 1, 7, 3, 2], [1, 0, 5, 3, 7], [7, 1, 2, 5, 0], [1, 7, 5, 2, 6], [0, 7, 1, 5, 2], [1, 0, 4, 6, 3], [1, 0, 3, 5, 4], [1, 7, 0, 5, 4], [0, 1, 2, 3, 6], [1, 0, 3, 6, 7], [1, 0, 6, 4, 7], [1, 0, 7, 4, 5], [0, 1, 7, 3, 4], [1, 0, 4, 3, 5], [1, 7, 5, 2, 4], [1, 0, 2, 4, 6], [1, 7, 0, 5, 4], [1, 7, 5, 4, 0], [1, 0, 4, 6, 3], [1, 0, 3, 7, 2], [1, 7, 5, 2, 4], [1, 0, 7, 5, 6], [1, 7, 5, 2, 0], [7, 0, 2, 5, 6], [1, 5, 7, 0, 4], [0, 1, 5, 4, 2], [1, 7, 0, 5, 3], [1, 0, 7, 5, 6], [1, 7, 5, 0, 2], [1, 0, 5, 6, 3], [0, 7, 4, 2, 6], [0, 1, 7, 3, 6], [1, 7, 2, 5, 3], [1, 7, 5, 2, 0], [1, 0, 6, 3, 5], [0, 1, 7, 6, 2], [0, 1, 7, 2, 3], [0, 7, 2, 5, 3], [0, 7, 2, 5, 6], [0, 7, 2, 5, 6], [0, 7, 2, 5, 6], [7, 0, 2, 5, 6], [0, 7, 2, 5, 6], [1, 0, 3, 6, 4], [1, 7, 0, 3, 5], [1, 0, 3, 6, 7], [1, 0, 3, 6, 7], [1, 0, 3, 6, 5], [1, 0, 3, 2, 6], [1, 0, 3, 5, 7], [1, 7, 2, 5, 0], [0, 2, 4, 7, 1], [1, 0, 7, 5, 3], [1, 7, 5, 2, 3], [1, 0, 5, 3, 7], [1, 0, 3, 5, 6], [0, 7, 2, 5, 6], [1, 0, 3, 5, 4], [1, 0, 3, 5, 7], [1, 0, 3, 7, 5], [1, 7, 2, 5, 3], [1, 7, 5, 2, 3], [1, 0, 5, 7, 4], [1, 7, 2, 5, 3], [1, 7, 5, 2, 3], [1, 7, 5, 2, 3], [0, 1, 7, 2, 3], [1, 7, 5, 2, 4], [0, 1, 7, 3, 6], [0, 7, 1, 2, 4], [0, 7, 2, 5, 3], [1, 7, 5, 0, 3], [1, 0, 3, 5, 4], [0, 7, 1, 2, 5], [1, 7, 0, 5, 2], [0, 7, 1, 2, 5], [1, 7, 5, 4, 3], [0, 7, 2, 5, 6], [1, 0, 4, 6, 5], [7, 0, 2, 5, 4], [1, 0, 4, 2, 5], [0, 7, 1, 2, 4], [1, 7, 2, 5, 3], [1, 7, 5, 2, 4], [1, 7, 5, 0, 2], [0, 1, 6, 5, 7], [1, 0, 4, 2, 6], [1, 5, 7, 0, 4], [1, 0, 7, 5, 3], [1, 7, 2, 5, 3], [1, 0, 7, 5, 6], [1, 7, 5, 2, 0], [1, 7, 0, 5, 6], [1, 7, 0, 2, 3], [1, 0, 3, 7, 5], [1, 0, 7, 3, 2], [1, 0, 7, 3, 6], [1, 7, 2, 5, 6], [1, 7, 0, 5, 2], [1, 0, 7, 2, 3], [7, 0, 2, 5, 1], [1, 0, 3, 2, 5], [1, 7, 5, 3, 2], [1, 0, 5, 3, 7], [0, 1, 2, 3, 5], [1, 7, 5, 2, 0], [0, 1, 3, 4, 5], [1, 5, 7, 0, 3], [0, 7, 2, 1, 3], [1, 0, 5, 3, 7], [1, 7, 0, 5, 2], [1, 0, 3, 2, 4], [1, 7, 5, 2, 3], [0, 7, 2, 5, 3], [0, 1, 3, 7, 2], [1, 7, 0, 5, 3], [1, 0, 3, 7, 6], [1, 5, 0, 3, 7], [1, 7, 5, 2, 3], [1, 7, 5, 3, 0], [1, 0, 5, 7, 3], [1, 0, 5, 3, 2], [1, 7, 0, 5, 3], [0, 4, 2, 6, 7], [0, 6, 2, 4, 7], [0, 4, 2, 7, 6], [1, 7, 5, 2, 3], [1, 0, 5, 3, 7], [0, 7, 2, 5, 1], [0, 1, 7, 2, 3], [1, 7, 5, 0, 2], [0, 7, 2, 1, 4], [1, 7, 5, 0, 4], [1, 0, 3, 6, 4], [1, 0, 7, 3, 2], [0, 7, 2, 5, 1], [0, 1, 7, 4, 2], [1, 7, 2, 5, 4], [1, 0, 4, 3, 6], [1, 0, 3, 4, 5], [1, 7, 5, 0, 2], [1, 7, 5, 2, 0], [0, 7, 2, 5, 1], [1, 5, 4, 0, 7], [1, 7, 5, 4, 0], [1, 0, 7, 5, 4], [1, 0, 5, 7, 4], [1, 7, 5, 2, 0], [1, 0, 3, 5, 6], [0, 7, 2, 1, 5], [1, 7, 5, 2, 0], [1, 7, 5, 2, 0], [0, 1, 3, 5, 7], [1, 7, 2, 0, 5], [1, 0, 5, 6, 7], [1, 7, 5, 2, 4], [7, 0, 2, 5, 1], [7, 0, 2, 5, 3], [1, 7, 5, 2, 0], [1, 0, 5, 3, 6], [1, 7, 0, 5, 2], [1, 7, 2, 5, 0], [0, 1, 7, 2, 3], [1, 0, 5, 4, 7], [1, 7, 5, 2, 0], [1, 0, 3, 6, 7], [1, 0, 5, 7, 3], [1, 0, 5, 4, 3], [1, 0, 4, 2, 3], [1, 0, 3, 5, 4], [1, 5, 7, 3, 0], [1, 0, 5, 3, 7], [1, 7, 0, 5, 3], [1, 7, 0, 5, 3], [0, 1, 3, 2, 4], [1, 7, 5, 3, 0], [7, 0, 2, 3, 5], [1, 5, 0, 3, 7], [0, 1, 3, 5, 2], [0, 7, 2, 5, 1], [1, 0, 7, 5, 3], [0, 1, 3, 7, 2], [0, 7, 1, 2, 3], [0, 1, 3, 7, 2], [1, 0, 3, 5, 6], [1, 7, 5, 2, 3], [0, 1, 7, 3, 2], [1, 0, 5, 3, 4], [0, 7, 2, 1, 4], [1, 7, 5, 2, 3], [1, 0, 5, 3, 7], [1, 0, 3, 7, 6], [1, 0, 7, 2, 6], [1, 0, 4, 5, 3], [1, 7, 5, 2, 4], [1, 7, 0, 5, 3], [1, 7, 2, 5, 0], [1, 7, 0, 5, 2], [1, 0, 7, 5, 3], [1, 5, 4, 0, 7], [1, 0, 4, 7, 3], [1, 0, 4, 2, 3], [1, 0, 4, 3, 2], [0, 6, 4, 2, 7], [1, 5, 7, 0, 4], [1, 7, 5, 2, 4], [1, 0, 4, 5, 3], [1, 7, 0, 5, 4], [1, 0, 5, 4, 3], [1, 0, 7, 5, 3], [0, 7, 1, 2, 5], [7, 0, 2, 5, 1], [7, 1, 2, 0, 5], [1, 5, 0, 7, 4], [1, 0, 3, 5, 4], [0, 1, 3, 2, 5], [1, 7, 5, 2, 0], [1, 7, 5, 2, 4], [1, 7, 5, 4, 0], [1, 7, 5, 4, 0], [1, 7, 5, 4, 0], [1, 0, 5, 3, 4], [1, 7, 5, 2, 4], [1, 0, 7, 5, 3], [1, 7, 5, 2, 0], [0, 1, 7, 2, 3], [1, 7, 5, 2, 0], [1, 7, 2, 5, 3], [0, 7, 1, 2, 3], [1, 0, 3, 7, 6], [1, 7, 5, 2, 4], [1, 0, 5, 7, 3], [0, 7, 2, 1, 3], [1, 0, 7, 3, 5], [0, 7, 1, 3, 2], [1, 0, 5, 7, 3], [1, 0, 3, 5, 4], [1, 7, 5, 2, 4], [1, 7, 5, 2, 3], [1, 7, 5, 0, 3], [0, 1, 7, 3, 2], [1, 0, 3, 6, 2], [1, 7, 5, 2, 3], [1, 0, 7, 5, 3], [7, 0, 2, 5, 3], [1, 5, 0, 3, 7], [0, 1, 7, 3, 2], [1, 0, 3, 7, 5], [1, 7, 5, 2, 3], [0, 1, 7, 2, 3], [1, 7, 5, 2, 4], [1, 0, 5, 3, 4], [0, 1, 3, 7, 2], [1, 7, 5, 2, 0], [1, 5, 0, 7, 3], [0, 7, 2, 1, 5], [1, 5, 0, 4, 7], [1, 7, 5, 2, 4], [1, 7, 2, 5, 6]] showed the highest activity during this simulation.\n",
      "(In a full analysis, you would regress these dimensions back to Pathways).\n"
     ]
    }
   ],
   "source": [
    "# Which latent dimensions changed the most?\n",
    "# This gives us a \"fingerprint\" of the predicted change\n",
    "diff_vector = (z_predicted - z_control).abs().mean(dim=0) # [Embed_Dim]\n",
    "top_dims = torch.topk(diff_vector, 5).indices.tolist()\n",
    "\n",
    "print(f\"\\n[Top Active Latent Dimensions]\")\n",
    "print(f\"Dimensions {top_dims} showed the highest activity during this simulation.\")\n",
    "print(\"(In a full analysis, you would regress these dimensions back to Pathways).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc7a4bc-88e5-4903-bbad-6ffa382db26a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30288334-6f6f-48a3-96e3-4f9144215288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
