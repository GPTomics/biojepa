{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71522d3b-8805-48e6-bb36-1c9a7bd15482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "import biojepa_ac_model as model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe98e32-54b3-4da6-adf9-8b3e76e3bc0b",
   "metadata": {},
   "source": [
    "## BioJEPA Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bae5c1c-d7c4-4216-ab99-42a26b7aee75",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f67335c-63ea-4f80-9c10-96b4d3e09c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    # elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    #     device = 'mps'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ec64e1-0d7a-4dee-b478-b99f901ce9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "n_embd = 8\n",
    "n_pathways = 1024\n",
    "training_file_chunk = 25000\n",
    "pretraining_file_chunk = 50000\n",
    "n_heads = 2\n",
    "n_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025d6281-f460-46eb-89d9-842d1ca6fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_2')\n",
    "train_dir = data_dir / 'training'\n",
    "pretrain_dir = data_dir / 'pretraining'\n",
    "mask_path = data_dir / 'binary_pathway_mask.npy'\n",
    "checkpoint_dir = data_dir / 'checkpoint'\n",
    "pert_dir = data_dir / 'pert_embd'\n",
    "pert_embd_path = pert_dir / 'action_embeddings_esm2.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9671701-5cc4-4016-a354-b71238c98947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Pathway Mask...\n",
      "Mask Loaded: 5000 Genes -> 1024 Pathways\n",
      "Loading Action Embedding ...\n",
      "Bank Loaded. Shape: (1087, 320)\n"
     ]
    }
   ],
   "source": [
    "print('Loading Pathway Mask...')\n",
    "binary_mask = np.load(mask_path)\n",
    "n_genes, n_pathways = binary_mask.shape\n",
    "print(f'Mask Loaded: {n_genes} Genes -> {n_pathways} Pathways')\n",
    "\n",
    "print('Loading Action Embedding ...')\n",
    "pert_embd = np.load(pert_embd_path)\n",
    "print(f'Bank Loaded. Shape: {pert_embd.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe46b1b-aff7-4355-909f-9f71761f11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = model.BioJepaConfig(\n",
    "    mask_matrix=binary_mask, \n",
    "    num_genes=n_genes,\n",
    "    num_pathways=n_pathways,\n",
    "    embed_dim=n_embd,\n",
    "    n_layer=n_layers,\n",
    "    heads=n_heads,\n",
    "    n_pre_layer = n_layers\n",
    ")\n",
    "model = model.BioJepa(config, pert_embd=pert_embd).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609e628-943e-41c2-a4d7-a71b9075a640",
   "metadata": {},
   "source": [
    "**Load Checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aac628e-6ab7-4768-955a-3f99e79f58ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_ckpt_31769_final.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "keys = model.load_state_dict(checkpoint['model'])\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287a64f-9d0d-4fbe-8c9b-a03c463a1487",
   "metadata": {},
   "source": [
    "**Freeze Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63812672-368f-483a-be2a-8b65cc849a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c98b4a-5df8-4894-9c56-ae0dbcbc3acd",
   "metadata": {},
   "source": [
    "## Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3dec1f3-d9cc-4849-aaa8-6a7d60199432",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class BenchmarkDecoderConfig:\n",
    "    embed_dim: int = 384\n",
    "    num_pathways: int = 1024\n",
    "    num_genes: int = 4096\n",
    "    \n",
    "class BenchmarkDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        # Step 1: Collapse the embedding dimension (384 -> 1)\n",
    "        # This asks: \"How active is this pathway overall?\"\n",
    "        self.pool = nn.Linear(config.embed_dim, 1) \n",
    "        \n",
    "        # Step 2: Decode Pathway Activity -> Gene Expression\n",
    "        # This learns the specific contribution of each pathway to each gene\n",
    "        self.decode = nn.Linear(config.num_pathways, config.num_genes) \n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        \n",
    "    def _init_weights(self, module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
    "            if module.bias is not None: \n",
    "                torch.nn.init.zeros_(module.bias)\n",
    "        \n",
    "    def forward(self, latents):\n",
    "        # latents: [Batch, 1024, 384]\n",
    "        \n",
    "        # 1. Calculate Pathway Scores\n",
    "        # [B, 1024, 384] -> [B, 1024, 1] -> [B, 1024]\n",
    "        scores = self.pool(latents).squeeze(-1)\n",
    "        \n",
    "        # 2. Project to Genes\n",
    "        # [B, 1024] @ [1024, 2000] -> [B, 2000]\n",
    "        gene_preds = self.decode(scores)\n",
    "        \n",
    "        return gene_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316fe59-e4aa-4d12-9db4-2e38781f53bc",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bfad6fe-82ef-4019-b0ae-0338089f11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_shard(filename):\n",
    "    print(f'loading {filename}') # Optional: reduce noise\n",
    "    with np.load(filename) as data:\n",
    "        # Load all arrays into memory\n",
    "        # We convert to correct types immediately to save hassle later\n",
    "        control_x = data['control'].astype(np.float32)\n",
    "        control_tot = data['control_total'].astype(np.float32)\n",
    "        case_x = data['case'].astype(np.float32)\n",
    "        case_tot = data['case_total'].astype(np.float32)\n",
    "        action_ids = data['action_ids'].astype(np.int64)\n",
    "        \n",
    "    return control_x, control_tot, case_x, case_tot, action_ids\n",
    "\n",
    "class DataLoaderLite:\n",
    "    def __init__(self, B, split, device):\n",
    "        self.B = B\n",
    "        self.split = split\n",
    "        self.device = device\n",
    "        \n",
    "        # 1. Find Shards\n",
    "        data_root = train_dir / f'{split}'\n",
    "        shards = list(data_root.glob('*.npz'))\n",
    "\n",
    "        self.total_files = len(shards)\n",
    "        self.shards = sorted(shards)\n",
    "\n",
    "        assert len(shards) > 0, f'no shards found for split {split}'\n",
    "        print(f'found {len(shards)} shards for split {split}')\n",
    "        \n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        # Create a randomized queue of shards\n",
    "        self.remaining_shards = list(self.shards)\n",
    "        random.shuffle(self.remaining_shards)\n",
    "        \n",
    "        self.current_shard_idx = -1\n",
    "        self.load_next_shard()\n",
    "\n",
    "    def load_next_shard(self):\n",
    "        self.current_shard_idx += 1\n",
    "        \n",
    "        # If we ran out of shards, reset (Epoch done)\n",
    "        if self.current_shard_idx >= len(self.remaining_shards):\n",
    "            self.reset() # This resets shard_idx to -1 and reshuffles\n",
    "            return \n",
    "\n",
    "        # Load the file\n",
    "        filename = self.remaining_shards[self.current_shard_idx]\n",
    "        self.data_tuple = load_shard(filename)\n",
    "        \n",
    "        # Shuffle the items INSIDE the shard\n",
    "        # This is critical so we don't just memorize the sorted order of the shard\n",
    "        n_samples = len(self.data_tuple[0])\n",
    "        self.perm = np.random.permutation(n_samples)\n",
    "        self.current_position = 0\n",
    "        self.total_samples_in_shard = n_samples\n",
    "\n",
    "    def next_batch(self):\n",
    "        B = self.B\n",
    "        \n",
    "        # Check if we have enough data left in current shard\n",
    "        if self.current_position + B > self.total_samples_in_shard:\n",
    "            self.load_next_shard()\n",
    "            # Recursively call to get batch from the new shard\n",
    "            return self.next_batch()\n",
    "            \n",
    "        # Get indices for this batch\n",
    "        indices = self.perm[self.current_position : self.current_position + B]\n",
    "        self.current_position += B\n",
    "        \n",
    "        # Slice data using the shuffled indices\n",
    "        # data_tuple structure: (xc, xct, xt, xtt, aid)\n",
    "        batch_xc  = torch.from_numpy(self.data_tuple[0][indices]).to(self.device)\n",
    "        batch_xct = torch.from_numpy(self.data_tuple[1][indices]).to(self.device)\n",
    "        batch_xt  = torch.from_numpy(self.data_tuple[2][indices]).to(self.device)\n",
    "        batch_xtt = torch.from_numpy(self.data_tuple[3][indices]).to(self.device)\n",
    "        batch_aid = torch.from_numpy(self.data_tuple[4][indices]).to(self.device)\n",
    "        \n",
    "        return batch_xc, batch_xct, batch_xt, batch_xtt, batch_aid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f7811-5727-45e3-8194-505072bb16eb",
   "metadata": {},
   "source": [
    "**Data Loader**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e1d5000-f278-4f9b-9227-9554f31e9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_2/training/train/shard_k562e_train_0001.npz\n",
      "found 1 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_2/training/val/shard_k562e_val_0000.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = DataLoaderLite(B=BATCH_SIZE, split='train', device=DEVICE)\n",
    "val_loader = DataLoaderLite(B=BATCH_SIZE, split='val', device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9025bf-05d7-4ff8-ae9a-c1b87471c3e5",
   "metadata": {},
   "source": [
    "## Training Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484f1f2-2933-413d-80c0-f0c970656453",
   "metadata": {},
   "source": [
    "### Training Config/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad700ee3-e710-43de-be89-4003c922a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decoder = 1e-2\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494e7de-e96d-4989-b47b-9229c050a263",
   "metadata": {},
   "source": [
    "**Initialize Decoder** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74224c15-ff49-41d9-9552-b8ec9ed83dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BenchmarkDecoderConfig(\n",
    "    embed_dim= n_embd,\n",
    "    num_pathways= n_pathways,\n",
    "    num_genes= n_genes\n",
    ")\n",
    "\n",
    "decoder = BenchmarkDecoder(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da30fa-9c44-40be-921c-5184c764f0e5",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b197e689-8b98-4cf9-8382-6116bf2ce440",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f11cf-8c9f-49b9-b526-74be69d2126f",
   "metadata": {},
   "source": [
    "**Training Lenght**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "009526cc-7703-497d-87cb-4a50f9c1c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_examples = 101682\n",
    "val_total_examples = 11044\n",
    "test_total_examples = 38829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "766a254e-2fd7-4274-91c4-7ceab21d8d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3177, 15885)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = train_total_examples // BATCH_SIZE\n",
    "max_steps = epochs * steps_per_epoch\n",
    "steps_per_epoch, max_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf4803-b42e-4d1b-89db-c9b43d6e3558",
   "metadata": {},
   "source": [
    "**Scheduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c683627d-3da6-45e9-9827-06d8586a1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c5c7c-b741-486e-9ce2-99c2e253b05d",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82cb876c-e45d-43f7-94aa-2fa7f44b15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "step = 0\n",
    "total_epoch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69468a01-365b-42b9-b041-5d6969e5b4ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.9040\n",
      "Step 0 | Loss: 0.93494 | LR: 4.00e-04\n",
      "Step 25 | Loss: 0.92195 | LR: 4.25e-04\n",
      "Step 50 | Loss: 0.90335 | LR: 4.98e-04\n",
      "Step 75 | Loss: 0.92092 | LR: 6.16e-04\n",
      "test loss: 0.9156\n",
      "Step 100 | Loss: 0.88460 | LR: 7.79e-04\n",
      "Step 125 | Loss: 0.90976 | LR: 9.85e-04\n",
      "Step 150 | Loss: 0.92067 | LR: 1.23e-03\n",
      "Step 175 | Loss: 0.90909 | LR: 1.52e-03\n",
      "test loss: 0.9046\n",
      "Step 200 | Loss: 0.92686 | LR: 1.84e-03\n",
      "Step 225 | Loss: 0.90585 | LR: 2.20e-03\n",
      "Step 250 | Loss: 0.93254 | LR: 2.58e-03\n",
      "Step 275 | Loss: 0.88064 | LR: 2.99e-03\n",
      "test loss: 0.9086\n",
      "Step 300 | Loss: 0.87286 | LR: 3.43e-03\n",
      "Step 325 | Loss: 0.91142 | LR: 3.87e-03\n",
      "Step 350 | Loss: 0.90651 | LR: 4.34e-03\n",
      "Step 375 | Loss: 0.91356 | LR: 4.81e-03\n",
      "test loss: 0.8981\n",
      "Step 400 | Loss: 0.89542 | LR: 5.28e-03\n",
      "Step 425 | Loss: 0.85320 | LR: 5.76e-03\n",
      "Step 450 | Loss: 0.88244 | LR: 6.23e-03\n",
      "Step 475 | Loss: 0.84772 | LR: 6.68e-03\n",
      "test loss: 0.8774\n",
      "Step 500 | Loss: 0.89394 | LR: 7.13e-03\n",
      "Step 525 | Loss: 0.84370 | LR: 7.55e-03\n",
      "Step 550 | Loss: 0.84677 | LR: 7.96e-03\n",
      "Step 575 | Loss: 0.86985 | LR: 8.33e-03\n",
      "test loss: 0.8670\n",
      "Step 600 | Loss: 0.82859 | LR: 8.67e-03\n",
      "Step 625 | Loss: 0.84865 | LR: 8.98e-03\n",
      "Step 650 | Loss: 0.88726 | LR: 9.26e-03\n",
      "Step 675 | Loss: 0.88907 | LR: 9.49e-03\n",
      "test loss: 0.8683\n",
      "Step 700 | Loss: 0.84192 | LR: 9.68e-03\n",
      "Step 725 | Loss: 0.89034 | LR: 9.83e-03\n",
      "Step 750 | Loss: 0.82832 | LR: 9.93e-03\n",
      "Step 775 | Loss: 0.85197 | LR: 9.99e-03\n",
      "loading /Users/djemec/data/jepa/v0_2/training/train/shard_k562e_train_0000.npz\n",
      "test loss: 0.8539\n",
      "Step 800 | Loss: 0.83265 | LR: 1.00e-02\n",
      "Step 825 | Loss: 0.88569 | LR: 1.00e-02\n",
      "Step 850 | Loss: 0.85810 | LR: 1.00e-02\n",
      "Step 875 | Loss: 0.86202 | LR: 1.00e-02\n",
      "test loss: 0.8551\n",
      "Step 900 | Loss: 0.82781 | LR: 1.00e-02\n",
      "Step 925 | Loss: 0.87514 | LR: 1.00e-02\n",
      "Step 950 | Loss: 0.83064 | LR: 1.00e-02\n",
      "Step 975 | Loss: 0.89844 | LR: 1.00e-02\n",
      "test loss: 0.8492\n",
      "Step 1000 | Loss: 0.86745 | LR: 1.00e-02\n",
      "Step 1025 | Loss: 0.84469 | LR: 9.99e-03\n",
      "Step 1050 | Loss: 0.84773 | LR: 9.99e-03\n",
      "Step 1075 | Loss: 0.87138 | LR: 9.99e-03\n",
      "test loss: 0.8421\n",
      "Step 1100 | Loss: 0.81991 | LR: 9.99e-03\n",
      "Step 1125 | Loss: 0.86135 | LR: 9.99e-03\n",
      "Step 1150 | Loss: 0.83564 | LR: 9.99e-03\n",
      "Step 1175 | Loss: 0.81668 | LR: 9.98e-03\n",
      "test loss: 0.8455\n",
      "Step 1200 | Loss: 0.83716 | LR: 9.98e-03\n",
      "Step 1225 | Loss: 0.82417 | LR: 9.98e-03\n",
      "Step 1250 | Loss: 0.84276 | LR: 9.98e-03\n",
      "Step 1275 | Loss: 0.81457 | LR: 9.97e-03\n",
      "loading /Users/djemec/data/jepa/v0_2/training/val/shard_k562e_val_0000.npz\n",
      "test loss: 0.8407\n",
      "Step 1300 | Loss: 0.84680 | LR: 9.97e-03\n",
      "Step 1325 | Loss: 0.83153 | LR: 9.97e-03\n",
      "Step 1350 | Loss: 0.85100 | LR: 9.97e-03\n",
      "Step 1375 | Loss: 0.83940 | LR: 9.96e-03\n",
      "test loss: 0.8330\n",
      "Step 1400 | Loss: 0.88008 | LR: 9.96e-03\n",
      "Step 1425 | Loss: 0.85273 | LR: 9.96e-03\n",
      "Step 1450 | Loss: 0.86161 | LR: 9.95e-03\n",
      "Step 1475 | Loss: 0.79184 | LR: 9.95e-03\n"
     ]
    }
   ],
   "source": [
    "for step in range(max_steps):\n",
    "\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    # once in a while evaluate our validation set loss\n",
    "    if step % 100 == 0 or last_step:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 25\n",
    "            for i in range(val_loss_steps):\n",
    "                cont_x, cont_tot, case_x, case_tot, act_id = val_loader.next_batch()\n",
    "\n",
    "                # run BioJEPA\n",
    "                with torch.no_grad():\n",
    "                    z_context = model.student(cont_x, cont_tot)\n",
    "                    z_pred = model.predictor(z_context, act_id)\n",
    "\n",
    "                # run new decoder\n",
    "                pred_delta = decoder(z_pred) - decoder(z_context)\n",
    "                real_delta = case_x - cont_x\n",
    "\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                loss = loss / val_loss_steps\n",
    "                val_loss_accum += loss.detach()\n",
    "\n",
    "        print(f'val loss: {val_loss_accum.item():.4f}')\n",
    "\n",
    "\n",
    "    # periodically save checkpoint\n",
    "    if step > 0 and  (step+1) % steps_per_epoch ==0 and not last_step:\n",
    "        # Save Checkpoint\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'biojepa_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    # actual training\n",
    "    decoder.train\n",
    "    cont_x, cont_tot, case_x, case_tot, act_id = train_loader.next_batch()\n",
    "\n",
    "    # run frozen BioJEPA\n",
    "    with torch.no_grad():\n",
    "        z_context = model.student(cont_x, cont_tot)\n",
    "        z_pred = model.predictor(z_context, act_id)\n",
    "\n",
    "    # run decoder\n",
    "    pred_delta = decoder(z_pred) - decoder(z_context)\n",
    "    real_delta = case_x - cont_x\n",
    "    real_delta = case_x - cont_x\n",
    "\n",
    "    # loss\n",
    "    pred_delta = decoder(z_pred) - decoder(z_context)\n",
    "    real_delta = case_x - cont_x\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # loss caching\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f\"Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    if step > 0 and (step+1) % steps_per_epoch == 0:   \n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f\"=== Step {step} Done. Avg Loss: {avg_loss:.5f} ===\")\n",
    "        total_epoch_loss = 0\n",
    "    \n",
    "    if last_step:\n",
    "        # Save Checkpoint\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'biojepa_decoder_ckpt_{step}_final.pt')\n",
    "\n",
    "    step += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c924050-b2d8-4973-a3c1-f9dd0a3d1f03",
   "metadata": {},
   "source": [
    "**Training Loss Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fde37-0cac-429d-be0c-351390bac22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aaa78-e607-4bc4-8cde-49a529984c1b",
   "metadata": {},
   "source": [
    "## Trained Decoder Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974730ff-1cda-43e0-a72f-df0986bb9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.stats import ConstantInputWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd5355-31c8-47fc-a2fd-9b1fa9f91576",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.eval()\n",
    "correlations = []\n",
    "mses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a9438-c9f1-4cb0-8da2-e9fe7ec831a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps_per_epoch = val_total_examples // BATCH_SIZE\n",
    "test_steps_per_epoch = test_total_examples // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c89be7-508c-4e06-9dfc-9f4809807077",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(val_steps_per_epoch), desc=\"Evaluating\"):\n",
    "    \n",
    "    # Custom Loader Call\n",
    "    cont_x, cont_tot, case_x, case_tot, act_id = val_loader.next_batch()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z_context = model.student(cont_x, cont_tot)\n",
    "        z_pred = model.predictor(z_context, act_id)\n",
    "        \n",
    "        pred_delta = decoder(z_pred) - decoder(z_context)\n",
    "        real_delta = case_x - cont_x\n",
    "        \n",
    "    # Per-Sample Metrics\n",
    "    for i in range(len(pred_delta)):\n",
    "        p = pred_delta[i].cpu().numpy()\n",
    "        t = real_delta[i].cpu().numpy()\n",
    "        \n",
    "        # Metric: Pearson Correlation on Top 20 DEGs\n",
    "        top_20_idx = np.argsort(np.abs(t))[-20:]\n",
    "        \n",
    "        if np.std(p[top_20_idx]) > 1e-9 and np.std(t[top_20_idx]) > 1e-9:\n",
    "            \n",
    "            try:\n",
    "                corr, _ = pearsonr(p[top_20_idx], t[top_20_idx])\n",
    "                correlations.append(corr)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        mses.append(np.mean((p - t)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750afdb9-ba92-4a7a-874d-0cc221525de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mse = np.mean(mses)\n",
    "mean_corr = np.mean(correlations)\n",
    "print(f'Global MSE: {mean_mse:.4f}')\n",
    "print(f'Top-20 Pearson R: {mean_corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44680d47-980a-4b0e-b910-471b65efd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mean_corr > 0.75:\n",
    "    print('ðŸŒŸ SOTA COMPETITIVE (Matches GEARS)')\n",
    "elif mean_corr > 0.40:\n",
    "    print('âœ… FUNCTIONAL (Better than random)')\n",
    "else:\n",
    "    print('âŒ NEEDS IMPROVEMENT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b2741-9067-4cee-b37f-2ee471d3c7e6",
   "metadata": {},
   "source": [
    "## Trained Decoder Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5cb77-d9a4-43d8-ad77-b6d102d00caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_correlations = []\n",
    "eval_mses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c58931-04dc-4c75-a84d-23fbf3f7abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoaderLite(batch=batch_size, split='test', device=DEVICE, tok_dir=eval_dir)\n",
    "test_steps_per_epoch = test_total_examples // batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022a3d0-68f1-4de8-bb53-33e5bd05e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(test_steps_per_epoch), desc=\"Evaluating\"):\n",
    "    \n",
    "    # Custom Loader Call\n",
    "    cont_x, cont_tot, case_x, case_tot, act_id = test_loader.next_batch()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z_context = model.student(cont_x, cont_tot)\n",
    "        z_pred = model.predictor(z_context, act_id)\n",
    "        \n",
    "        pred_delta = decoder(z_pred) - decoder(z_context)\n",
    "        real_delta = case_x - cont_x\n",
    "        \n",
    "    # Per-Sample Metrics\n",
    "    for i in range(len(pred_delta)):\n",
    "        p = pred_delta[i].cpu().numpy()\n",
    "        t = real_delta[i].cpu().numpy()\n",
    "        \n",
    "        # Metric: Pearson Correlation on Top 20 DEGs\n",
    "        top_20_idx = np.argsort(np.abs(t))[-20:]\n",
    "        \n",
    "        if np.std(p[top_20_idx]) > 1e-9 and np.std(t[top_20_idx]) > 1e-9:\n",
    "            corr, _ = pearsonr(p[top_20_idx], t[top_20_idx])\n",
    "            eval_correlations.append(corr)\n",
    "            \n",
    "        eval_mses.append(np.mean((p - t)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee16bc-f9f8-4ab6-bc12-9e72fafe1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mean_mse = np.mean(eval_mses)\n",
    "eval_mean_corr = np.mean(eval_correlations)\n",
    "print(f'Global MSE: {eval_mean_mse:.4f}')\n",
    "print(f'Top-20 Pearson R: {eval_mean_corr:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
