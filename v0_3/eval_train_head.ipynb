{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71522d3b-8805-48e6-bb36-1c9a7bd15482",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.serialization\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import pearsonr\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "import biojepa_ac_model as model\n",
    "from biojepa_ac_model import BioJepaConfig\n",
    "from bio_dataloader import TrainingLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe98e32-54b3-4da6-adf9-8b3e76e3bc0b",
   "metadata": {},
   "source": [
    "## BioJEPA Model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f67335c-63ea-4f80-9c10-96b4d3e09c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    # elif hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():\n",
    "    #     device = 'mps'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e663c2-c9c8-4c7d-8629-f71602248487",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5ec64e1-0d7a-4dee-b478-b99f901ce9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n_embd = 8\n",
    "training_file_chunk = 25000\n",
    "n_heads = 2\n",
    "n_layers = 2\n",
    "n_genes = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "025d6281-f460-46eb-89d9-842d1ca6fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_2')\n",
    "train_dir = data_dir / 'training'\n",
    "checkpoint_dir = Path('/Users/djemec/data/jepa/v0_3') / 'checkpoints'\n",
    "pert_dir = data_dir / 'pert_embd'\n",
    "pert_embd_path = pert_dir / 'action_embeddings_esm2.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9671701-5cc4-4016-a354-b71238c98947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Action Embedding ...\n",
      "Bank Loaded. Shape: (1087, 320)\n"
     ]
    }
   ],
   "source": [
    "print('Loading Action Embedding ...')\n",
    "pert_embd = np.load(pert_embd_path)\n",
    "print(f'Bank Loaded. Shape: {pert_embd.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fe46b1b-aff7-4355-909f-9f71761f11c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.set_float32_matmul_precision('high')\n",
    "config = model.BioJepaConfig(\n",
    "    num_genes = n_genes,\n",
    "    n_layer= n_layers,\n",
    "    heads= n_heads,\n",
    "    embed_dim = n_embd,\n",
    "    n_pre_layer= n_layers\n",
    ")\n",
    "model = model.BioJepa(config, pert_embd=pert_embd).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a609e628-943e-41c2-a4d7-a71b9075a640",
   "metadata": {},
   "source": [
    "**Load Checkpoint**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4aac628e-6ab7-4768-955a-3f99e79f58ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_pt_ckpt_35109_final.pt'\n",
    "with torch.serialization.safe_globals([BioJepaConfig]):\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "\n",
    "keys = model.load_state_dict(checkpoint['model'])\n",
    "keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8287a64f-9d0d-4fbe-8c9b-a03c463a1487",
   "metadata": {},
   "source": [
    "**Freeze Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63812672-368f-483a-be2a-8b65cc849a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.freeze_encoders()\n",
    "model.eval()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c98b4a-5df8-4894-9c56-ae0dbcbc3acd",
   "metadata": {},
   "source": [
    "## Build Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3dec1f3-d9cc-4849-aaa8-6a7d60199432",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights_robust(module):\n",
    "    if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "        if isinstance(module, nn.Embedding):\n",
    "            fan_in = module.embedding_dim\n",
    "        else:\n",
    "            fan_in = module.weight.size(1)\n",
    "        std = 1.0 / math.sqrt(fan_in) if fan_in > 0 else 0.02\n",
    "        nn.init.trunc_normal_(module.weight, mean=0.0, std=std, a=-2*std, b=2*std)\n",
    "        if hasattr(module, 'bias') and module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n",
    "    elif isinstance(module, nn.LayerNorm):\n",
    "        nn.init.zeros_(module.bias)\n",
    "        nn.init.ones_(module.weight)\n",
    "\n",
    "@dataclass\n",
    "class BenchmarkDecoderConfig:\n",
    "    embed_dim: int = 256\n",
    "    \n",
    "class BenchmarkDecoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "\n",
    "        self.head = nn.Linear(config.embed_dim, 1)\n",
    "\n",
    "        self.apply(init_weights_robust)\n",
    "        \n",
    "    def forward(self, latents):\n",
    "\n",
    "        gene_preds = self.head(latents)        \n",
    "        gene_preds = gene_preds.squeeze(-1)\n",
    "        \n",
    "        return gene_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c316fe59-e4aa-4d12-9db4-2e38781f53bc",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1d5000-f278-4f9b-9227-9554f31e9a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 5 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_2/training/train/shard_k562e_train_0001.npz\n",
      "found 1 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_2/training/val/shard_k562e_val_0000.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = TrainingLoader(batch_size=batch_size, split='train', data_dir=train_dir, device=DEVICE)\n",
    "val_loader = TrainingLoader(batch_size=batch_size, split='val', data_dir=train_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9025bf-05d7-4ff8-ae9a-c1b87471c3e5",
   "metadata": {},
   "source": [
    "## Training Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f484f1f2-2933-413d-80c0-f0c970656453",
   "metadata": {},
   "source": [
    "### Training Config/Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad700ee3-e710-43de-be89-4003c922a41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decoder = 1e-3\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0494e7de-e96d-4989-b47b-9229c050a263",
   "metadata": {},
   "source": [
    "**Initialize Decoder** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "74224c15-ff49-41d9-9552-b8ec9ed83dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BenchmarkDecoderConfig(\n",
    "    embed_dim= n_embd\n",
    ")\n",
    "\n",
    "decoder = BenchmarkDecoder(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da30fa-9c44-40be-921c-5184c764f0e5",
   "metadata": {},
   "source": [
    "**Optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b197e689-8b98-4cf9-8382-6116bf2ce440",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958f11cf-8c9f-49b9-b526-74be69d2126f",
   "metadata": {},
   "source": [
    "**Training Lenght**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "009526cc-7703-497d-87cb-4a50f9c1c1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_total_examples = 101682\n",
    "val_total_examples = 11044\n",
    "test_total_examples = 38829"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "766a254e-2fd7-4274-91c4-7ceab21d8d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3177, 15885)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps_per_epoch = train_total_examples // batch_size\n",
    "max_steps = epochs * steps_per_epoch\n",
    "steps_per_epoch, max_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cf4803-b42e-4d1b-89db-c9b43d6e3558",
   "metadata": {},
   "source": [
    "**Scheduler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c683627d-3da6-45e9-9827-06d8586a1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15c5c7c-b741-486e-9ce2-99c2e253b05d",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82cb876c-e45d-43f7-94aa-2fa7f44b15c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lossi = []\n",
    "step = 0\n",
    "total_epoch_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69468a01-365b-42b9-b041-5d6969e5b4ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 3.0262\n",
      "Step 0 | Loss: 3.12702 | LR: 4.00e-05\n",
      "Step 25 | Loss: 3.03995 | LR: 4.25e-05\n",
      "Step 50 | Loss: 3.04280 | LR: 4.98e-05\n",
      "Step 75 | Loss: 2.93484 | LR: 6.16e-05\n",
      "val loss: 2.9403\n",
      "Step 100 | Loss: 2.97939 | LR: 7.79e-05\n",
      "Step 125 | Loss: 2.91448 | LR: 9.85e-05\n",
      "Step 150 | Loss: 2.88257 | LR: 1.23e-04\n",
      "Step 175 | Loss: 2.83165 | LR: 1.52e-04\n",
      "val loss: 2.7601\n",
      "Step 200 | Loss: 2.83136 | LR: 1.84e-04\n",
      "Step 225 | Loss: 2.70943 | LR: 2.20e-04\n",
      "Step 250 | Loss: 2.60817 | LR: 2.58e-04\n",
      "Step 275 | Loss: 2.59494 | LR: 2.99e-04\n",
      "val loss: 2.4845\n",
      "Step 300 | Loss: 2.43082 | LR: 3.43e-04\n",
      "Step 325 | Loss: 2.40506 | LR: 3.87e-04\n",
      "Step 350 | Loss: 2.34265 | LR: 4.34e-04\n",
      "Step 375 | Loss: 2.28795 | LR: 4.81e-04\n",
      "val loss: 2.1702\n",
      "Step 400 | Loss: 2.20529 | LR: 5.28e-04\n",
      "Step 425 | Loss: 2.10958 | LR: 5.76e-04\n"
     ]
    }
   ],
   "source": [
    "decoder.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    # once in a while evaluate our validation set loss\n",
    "    if step % 100 == 0 or last_step:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 25\n",
    "            for i in range(val_loss_steps):\n",
    "                cont_x, cont_tot, case_x, case_tot, act_id = val_loader.next_batch()\n",
    "                B, N = cont_x.shape\n",
    "\n",
    "                # run BioJEPA\n",
    "                z_context = model.student(cont_x, cont_tot, mask_idx=None)\n",
    "                target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "                z_pred_mu, _ = model.predictor(z_context, act_id, target_indices)\n",
    "\n",
    "                # run new decoder\n",
    "                pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "                real_delta = case_x - cont_x\n",
    "\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_accum / val_loss_steps\n",
    "            print(f'val loss: {avg_val_loss:.4f}')\n",
    "\n",
    "        decoder.train()\n",
    "\n",
    "    # periodically save checkpoint\n",
    "    if step > 0 and  (step+1) % steps_per_epoch ==0 and not last_step:\n",
    "        # Save Checkpoint\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'biojepa_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    # actual training\n",
    "\n",
    "    cont_x, cont_tot, case_x, case_tot, act_id = train_loader.next_batch()\n",
    "    B, N = cont_x.shape\n",
    "\n",
    "    # run frozen BioJEPA\n",
    "    with torch.no_grad():\n",
    "        z_context = model.student(cont_x, cont_tot, mask_idx=None)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = model.predictor(z_context, act_id, target_indices)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # run decoder\n",
    "    pred_case = decoder(z_pred_mu)\n",
    "    pred_control = decoder(z_context)\n",
    "\n",
    "    pred_delta = pred_case - pred_control\n",
    "    real_delta = case_x - cont_x\n",
    "\n",
    "    # loss\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    # loss caching\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f\"Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}\")\n",
    "    \n",
    "    if step > 0 and (step+1) % steps_per_epoch == 0:   \n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f\"=== Step {step} Done. Avg Loss: {avg_loss:.5f} ===\")\n",
    "        total_epoch_loss = 0\n",
    "    \n",
    "    if last_step:\n",
    "        # Save Checkpoint\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'biojepa_decoder_ckpt_{step}_final.pt')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c924050-b2d8-4973-a3c1-f9dd0a3d1f03",
   "metadata": {},
   "source": [
    "**Training Loss Plot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11fde37-0cac-429d-be0c-351390bac22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lossi)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8aaa78-e607-4bc4-8cde-49a529984c1b",
   "metadata": {},
   "source": [
    "## Trained Decoder Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974730ff-1cda-43e0-a72f-df0986bb9daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from scipy.stats import ConstantInputWarning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd5355-31c8-47fc-a2fd-9b1fa9f91576",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "decoder.eval()\n",
    "\n",
    "correlations = []\n",
    "mses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "417a9438-c9f1-4cb0-8da2-e9fe7ec831a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_steps_per_epoch = val_total_examples // batch_size\n",
    "test_steps_per_epoch = test_total_examples // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c89be7-508c-4e06-9dfc-9f4809807077",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(val_steps_per_epoch), desc=\"Benchmarking\"):\n",
    "    \n",
    "    # Custom Loader Call\n",
    "    cont_x, cont_tot, case_x, case_tot, act_id = test_loader.next_batch()\n",
    "    B, N = cont_x.shape\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z_context = model.student(cont_x, cont_tot, mask_idx=None)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = model.predictor(z_context, act_id, target_indices)\n",
    "        \n",
    "        pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "        real_delta = case_x - cont_x\n",
    "    \n",
    "    pred_np = pred_delta.cpu().numpy()\n",
    "    real_np = real_delta.cpu().numpy()\n",
    "\n",
    "    # Per-Sample Metrics\n",
    "    for i in range(B):\n",
    "        p = pred_np[i]\n",
    "        t = real_np[i]\n",
    "        mses.append(np.mean((p - t)**2))\n",
    "\n",
    "        top_20_idx = np.argsort(np.abs(t))[-20:]\n",
    "\n",
    "        p_top = p[top_20_idx]\n",
    "        t_top = t[top_20_idx]\n",
    "        \n",
    "        if np.std(p_top) > 1e-9 and np.std(t_top) > 1e-9:\n",
    "            corr, _ = pearsonr(p_top, t_top)\n",
    "            if not np.isnan(corr):\n",
    "                correlations.append(corr)\n",
    "            else:\n",
    "                correlations.append(0.0)\n",
    "        else:\n",
    "            correlations.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750afdb9-ba92-4a7a-874d-0cc221525de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_mse = np.mean(mses)\n",
    "mean_corr = np.mean(correlations) \n",
    "print(f'Global MSE: {mean_mse:.4f}')\n",
    "print(f'Top-20 Pearson R: {mean_corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44680d47-980a-4b0e-b910-471b65efd220",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mean_corr > 0.75:\n",
    "    print('üåü SOTA COMPETITIVE (Matches GEARS)')\n",
    "elif mean_corr > 0.40:\n",
    "    print('‚úÖ FUNCTIONAL (Better than random)')\n",
    "else:\n",
    "    print('‚ùå NEEDS IMPROVEMENT')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6b2741-9067-4cee-b37f-2ee471d3c7e6",
   "metadata": {},
   "source": [
    "## Trained Decoder Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd5cb77-d9a4-43d8-ad77-b6d102d00caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_correlations = []\n",
    "eval_mses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c58931-04dc-4c75-a84d-23fbf3f7abc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = TrainingLoader(batch_size=batch_size, split='test', data_dir=train_dir, device=DEVICE)\n",
    "test_steps_per_epoch = test_total_examples // batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9022a3d0-68f1-4de8-bb53-33e5bd05e212",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(test_steps_per_epoch), desc=\"Benchmarking\"):\n",
    "    \n",
    "    # Custom Loader Call\n",
    "    cont_x, cont_tot, case_x, case_tot, act_id = test_loader.next_batch()\n",
    "    B, N = cont_x.shape\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        z_context = model.student(cont_x, cont_tot, mask_idx=None)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = model.predictor(z_context, act_id, target_indices)\n",
    "        \n",
    "        pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "        real_delta = case_x - cont_x\n",
    "    \n",
    "    pred_np = pred_delta.cpu().numpy()\n",
    "    real_np = real_delta.cpu().numpy()\n",
    "\n",
    "    # Per-Sample Metrics\n",
    "    for i in range(B):\n",
    "        p = pred_np[i]\n",
    "        t = real_np[i]\n",
    "        eval_mses.append(np.mean((p - t)**2))\n",
    "\n",
    "        top_20_idx = np.argsort(np.abs(t))[-20:]\n",
    "\n",
    "        p_top = p[top_20_idx]\n",
    "        t_top = t[top_20_idx]\n",
    "        \n",
    "        if np.std(p_top) > 1e-9 and np.std(t_top) > 1e-9:\n",
    "            corr, _ = pearsonr(p_top, t_top)\n",
    "            if not np.isnan(corr):\n",
    "                eval_correlations.append(corr)\n",
    "            else:\n",
    "                eval_correlations.append(0.0)\n",
    "        else:\n",
    "            eval_correlations.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ee16bc-f9f8-4ab6-bc12-9e72fafe1b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_mean_mse = np.mean(eval_mses)\n",
    "eval_mean_corr = np.mean(eval_correlations)\n",
    "print(f'Global MSE: {eval_mean_mse:.4f}')\n",
    "print(f'Top-20 Pearson R: {eval_mean_corr:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4370f0b7-232f-4fe4-8777-3d08ab4519be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if eval_mean_corr > 0.75:\n",
    "    print('üåü SOTA COMPETITIVE (Matches GEARS)')\n",
    "elif eval_mean_corr > 0.40:\n",
    "    print('‚úÖ FUNCTIONAL (Better than random)')\n",
    "else:\n",
    "    print('‚ùå NEEDS IMPROVEMENT')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9948c0-79ac-45ac-809a-65431b4081e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
