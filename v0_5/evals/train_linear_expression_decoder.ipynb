{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Train Linear Expression Decoder\n",
    "\n",
    "Trains a linear probe decoder on frozen BioJEPA latent representations to predict expression deltas.\n",
    "\n",
    "The trained decoder is used by evaluation notebooks (eval_1, eval_2, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import biojepa_ac_v0_5 as model\n",
    "from bio_dataloader import TrainingLoader\n",
    "from linear_expression_decoder import BenchmarkDecoder, BenchmarkDecoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "n_genes = 5000\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "n_embd = 8\n",
    "pert_latent_dim = 320\n",
    "pert_mode_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_4')\n",
    "train_dir = data_dir / 'training'\n",
    "checkpoint_dir = Path('/Users/djemec/data/jepa/v0_5') / 'checkpoints'\n",
    "pert_dir = data_dir / 'pert_embd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Bank (DNA): torch.Size([1250, 1536])\n"
     ]
    }
   ],
   "source": [
    "input_bank = torch.from_numpy(np.load(pert_dir / 'input_embeddings_dna.npy')).float().to(DEVICE)\n",
    "print(f'Input Bank (DNA): {input_bank.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Load BioJEPA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "config = model.BioJepaConfig(\n",
    "    num_genes=n_genes,\n",
    "    n_layer=n_layers,\n",
    "    heads=n_heads,\n",
    "    embed_dim=n_embd,\n",
    "    n_pre_layer=n_layers,\n",
    "    pert_latent_dim=pert_latent_dim,\n",
    "    pert_mode_dim=pert_mode_dim\n",
    ")\n",
    "biojepa = model.BioJepa(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-checkpoint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_ckpt_31769_final.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "keys = biojepa.load_state_dict(checkpoint['model'])\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freeze-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "biojepa.freeze_encoders()\n",
    "biojepa.eval()\n",
    "for param in biojepa.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "data-loaders",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 11 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "found 2 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = TrainingLoader(batch_size=batch_size, split='train', data_dir=train_dir, device=DEVICE)\n",
    "val_loader = TrainingLoader(batch_size=batch_size, split='val', data_dir=train_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoder-header",
   "metadata": {},
   "source": [
    "## Initialize Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "init-decoder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder parameters: 9\n"
     ]
    }
   ],
   "source": [
    "decoder_config = BenchmarkDecoderConfig(embed_dim=n_embd)\n",
    "decoder = BenchmarkDecoder(decoder_config).to(DEVICE)\n",
    "print(f'Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 3177\n",
      "Total steps: 15885\n"
     ]
    }
   ],
   "source": [
    "lr_decoder = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "train_total_examples = 101682\n",
    "steps_per_epoch = train_total_examples // batch_size\n",
    "max_steps = epochs * steps_per_epoch\n",
    "\n",
    "print(f'Steps per epoch: {steps_per_epoch}')\n",
    "print(f'Total steps: {max_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-header",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "training-loop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1.4241\n",
      "Step 0 | Loss: 1.48166 | LR: 4.00e-05\n",
      "Step 25 | Loss: 1.41055 | LR: 4.25e-05\n",
      "Step 50 | Loss: 1.56193 | LR: 4.98e-05\n",
      "Step 75 | Loss: 1.21360 | LR: 6.16e-05\n",
      "val loss: 1.3634\n",
      "Step 100 | Loss: 1.38299 | LR: 7.79e-05\n",
      "Step 125 | Loss: 1.40190 | LR: 9.85e-05\n",
      "Step 150 | Loss: 1.41728 | LR: 1.23e-04\n",
      "Step 175 | Loss: 1.24495 | LR: 1.52e-04\n",
      "val loss: 1.3439\n",
      "Step 200 | Loss: 1.21613 | LR: 1.84e-04\n",
      "Step 225 | Loss: 1.37389 | LR: 2.20e-04\n",
      "Step 250 | Loss: 1.31199 | LR: 2.58e-04\n",
      "Step 275 | Loss: 1.13477 | LR: 2.99e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 1.1548\n",
      "Step 300 | Loss: 1.08503 | LR: 3.43e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 325 | Loss: 1.13391 | LR: 3.87e-04\n",
      "Step 350 | Loss: 1.09149 | LR: 4.34e-04\n",
      "Step 375 | Loss: 0.99985 | LR: 4.81e-04\n",
      "val loss: 1.0224\n",
      "Step 400 | Loss: 0.97912 | LR: 5.28e-04\n",
      "Step 425 | Loss: 0.89530 | LR: 5.76e-04\n",
      "Step 450 | Loss: 0.89577 | LR: 6.23e-04\n",
      "Step 475 | Loss: 0.87595 | LR: 6.68e-04\n",
      "val loss: 0.8885\n",
      "Step 500 | Loss: 0.86550 | LR: 7.13e-04\n",
      "Step 525 | Loss: 0.83029 | LR: 7.55e-04\n",
      "Step 550 | Loss: 0.79835 | LR: 7.96e-04\n",
      "Step 575 | Loss: 0.79345 | LR: 8.33e-04\n",
      "val loss: 0.7574\n",
      "Step 600 | Loss: 0.74516 | LR: 8.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 625 | Loss: 0.77130 | LR: 8.98e-04\n",
      "Step 650 | Loss: 0.74204 | LR: 9.26e-04\n",
      "Step 675 | Loss: 0.74718 | LR: 9.49e-04\n",
      "val loss: 0.6947\n",
      "Step 700 | Loss: 0.68275 | LR: 9.68e-04\n",
      "Step 725 | Loss: 0.66939 | LR: 9.83e-04\n",
      "Step 750 | Loss: 0.71605 | LR: 9.93e-04\n",
      "Step 775 | Loss: 0.67611 | LR: 9.99e-04\n",
      "val loss: 0.6634\n",
      "Step 800 | Loss: 0.73418 | LR: 1.00e-03\n",
      "Step 825 | Loss: 0.67708 | LR: 1.00e-03\n",
      "Step 850 | Loss: 0.64186 | LR: 1.00e-03\n",
      "Step 875 | Loss: 0.65687 | LR: 1.00e-03\n",
      "val loss: 0.6439\n",
      "Step 900 | Loss: 0.64578 | LR: 1.00e-03\n",
      "Step 925 | Loss: 0.58809 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 950 | Loss: 0.60741 | LR: 1.00e-03\n",
      "Step 975 | Loss: 0.64743 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "val loss: 0.6349\n",
      "Step 1000 | Loss: 0.59073 | LR: 1.00e-03\n",
      "Step 1025 | Loss: 0.61462 | LR: 9.99e-04\n",
      "Step 1050 | Loss: 0.61674 | LR: 9.99e-04\n",
      "Step 1075 | Loss: 0.61757 | LR: 9.99e-04\n",
      "val loss: 0.6112\n",
      "Step 1100 | Loss: 0.61162 | LR: 9.99e-04\n",
      "Step 1125 | Loss: 0.63385 | LR: 9.99e-04\n",
      "Step 1150 | Loss: 0.59752 | LR: 9.99e-04\n",
      "Step 1175 | Loss: 0.61002 | LR: 9.98e-04\n",
      "val loss: 0.6106\n",
      "Step 1200 | Loss: 0.60599 | LR: 9.98e-04\n",
      "Step 1225 | Loss: 0.60472 | LR: 9.98e-04\n",
      "Step 1250 | Loss: 0.57459 | LR: 9.98e-04\n",
      "Step 1275 | Loss: 0.64253 | LR: 9.97e-04\n",
      "val loss: 0.5980\n",
      "Step 1300 | Loss: 0.62030 | LR: 9.97e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 1325 | Loss: 0.62841 | LR: 9.97e-04\n",
      "Step 1350 | Loss: 0.61552 | LR: 9.97e-04\n",
      "Step 1375 | Loss: 0.59535 | LR: 9.96e-04\n",
      "val loss: 0.6135\n",
      "Step 1400 | Loss: 0.61436 | LR: 9.96e-04\n",
      "Step 1425 | Loss: 0.59338 | LR: 9.96e-04\n",
      "Step 1450 | Loss: 0.61849 | LR: 9.95e-04\n",
      "Step 1475 | Loss: 0.64993 | LR: 9.95e-04\n",
      "val loss: 0.6047\n",
      "Step 1500 | Loss: 0.59352 | LR: 9.95e-04\n",
      "Step 1525 | Loss: 0.66682 | LR: 9.94e-04\n",
      "Step 1550 | Loss: 0.59382 | LR: 9.94e-04\n",
      "Step 1575 | Loss: 0.62259 | LR: 9.93e-04\n",
      "val loss: 0.6004\n",
      "Step 1600 | Loss: 0.62726 | LR: 9.93e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 1625 | Loss: 0.57985 | LR: 9.93e-04\n",
      "Step 1650 | Loss: 0.59536 | LR: 9.92e-04\n",
      "Step 1675 | Loss: 0.62453 | LR: 9.92e-04\n",
      "val loss: 0.6096\n",
      "Step 1700 | Loss: 0.61720 | LR: 9.91e-04\n",
      "Step 1725 | Loss: 0.63148 | LR: 9.91e-04\n",
      "Step 1750 | Loss: 0.60439 | LR: 9.90e-04\n",
      "Step 1775 | Loss: 0.66546 | LR: 9.90e-04\n",
      "val loss: 0.6044\n",
      "Step 1800 | Loss: 0.63018 | LR: 9.89e-04\n",
      "Step 1825 | Loss: 0.56826 | LR: 9.88e-04\n",
      "Step 1850 | Loss: 0.61554 | LR: 9.88e-04\n",
      "Step 1875 | Loss: 0.62161 | LR: 9.87e-04\n",
      "val loss: 0.5961\n",
      "Step 1900 | Loss: 0.56333 | LR: 9.87e-04\n",
      "Step 1925 | Loss: 0.61973 | LR: 9.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 1950 | Loss: 0.60864 | LR: 9.86e-04\n",
      "Step 1975 | Loss: 0.61626 | LR: 9.85e-04\n",
      "val loss: 0.5897\n",
      "Step 2000 | Loss: 0.58566 | LR: 9.84e-04\n",
      "Step 2025 | Loss: 0.60244 | LR: 9.84e-04\n",
      "Step 2050 | Loss: 0.59216 | LR: 9.83e-04\n",
      "Step 2075 | Loss: 0.60162 | LR: 9.82e-04\n",
      "val loss: 0.5937\n",
      "Step 2100 | Loss: 0.54900 | LR: 9.82e-04\n",
      "Step 2125 | Loss: 0.60637 | LR: 9.81e-04\n",
      "Step 2150 | Loss: 0.59926 | LR: 9.80e-04\n",
      "Step 2175 | Loss: 0.63576 | LR: 9.79e-04\n",
      "val loss: 0.6000\n",
      "Step 2200 | Loss: 0.54627 | LR: 9.79e-04\n",
      "Step 2225 | Loss: 0.58883 | LR: 9.78e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 2250 | Loss: 0.60014 | LR: 9.77e-04\n",
      "Step 2275 | Loss: 0.60198 | LR: 9.76e-04\n",
      "val loss: 0.5948\n",
      "Step 2300 | Loss: 0.58398 | LR: 9.76e-04\n",
      "Step 2325 | Loss: 0.59119 | LR: 9.75e-04\n",
      "Step 2350 | Loss: 0.63360 | LR: 9.74e-04\n",
      "Step 2375 | Loss: 0.61196 | LR: 9.73e-04\n",
      "val loss: 0.6036\n",
      "Step 2400 | Loss: 0.61379 | LR: 9.72e-04\n",
      "Step 2425 | Loss: 0.61814 | LR: 9.71e-04\n",
      "Step 2450 | Loss: 0.58115 | LR: 9.71e-04\n",
      "Step 2475 | Loss: 0.60785 | LR: 9.70e-04\n",
      "val loss: 0.6022\n",
      "Step 2500 | Loss: 0.60833 | LR: 9.69e-04\n",
      "Step 2525 | Loss: 0.59494 | LR: 9.68e-04\n",
      "Step 2550 | Loss: 0.58968 | LR: 9.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 2575 | Loss: 0.61404 | LR: 9.66e-04\n",
      "val loss: 0.5967\n",
      "Step 2600 | Loss: 0.60813 | LR: 9.65e-04\n",
      "Step 2625 | Loss: 0.59339 | LR: 9.64e-04\n",
      "Step 2650 | Loss: 0.60973 | LR: 9.63e-04\n",
      "Step 2675 | Loss: 0.61339 | LR: 9.62e-04\n",
      "val loss: 0.5939\n",
      "Step 2700 | Loss: 0.60866 | LR: 9.61e-04\n",
      "Step 2725 | Loss: 0.60700 | LR: 9.60e-04\n",
      "Step 2750 | Loss: 0.59883 | LR: 9.59e-04\n",
      "Step 2775 | Loss: 0.57634 | LR: 9.58e-04\n",
      "val loss: 0.5989\n",
      "Step 2800 | Loss: 0.58400 | LR: 9.57e-04\n",
      "Step 2825 | Loss: 0.60072 | LR: 9.56e-04\n",
      "Step 2850 | Loss: 0.62597 | LR: 9.55e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 2875 | Loss: 0.59047 | LR: 9.54e-04\n",
      "val loss: 0.6031\n",
      "Step 2900 | Loss: 0.64504 | LR: 9.53e-04\n",
      "Step 2925 | Loss: 0.58231 | LR: 9.52e-04\n",
      "Step 2950 | Loss: 0.61123 | LR: 9.50e-04\n",
      "Step 2975 | Loss: 0.59086 | LR: 9.49e-04\n",
      "val loss: 0.5903\n",
      "Step 3000 | Loss: 0.63258 | LR: 9.48e-04\n",
      "Step 3025 | Loss: 0.59817 | LR: 9.47e-04\n",
      "Step 3050 | Loss: 0.62493 | LR: 9.46e-04\n",
      "Step 3075 | Loss: 0.60906 | LR: 9.45e-04\n",
      "val loss: 0.5944\n",
      "Step 3100 | Loss: 0.60088 | LR: 9.43e-04\n",
      "Step 3125 | Loss: 0.64908 | LR: 9.42e-04\n",
      "Step 3150 | Loss: 0.59903 | LR: 9.41e-04\n",
      "Step 3175 | Loss: 0.63173 | LR: 9.40e-04\n",
      "=== Epoch 1 Done. Avg Loss: 0.71766 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5989\n",
      "Step 3200 | Loss: 0.63467 | LR: 9.38e-04\n",
      "Step 3225 | Loss: 0.59448 | LR: 9.37e-04\n",
      "Step 3250 | Loss: 0.60139 | LR: 9.36e-04\n",
      "Step 3275 | Loss: 0.59643 | LR: 9.35e-04\n",
      "val loss: 0.6038\n",
      "Step 3300 | Loss: 0.58866 | LR: 9.33e-04\n",
      "Step 3325 | Loss: 0.59973 | LR: 9.32e-04\n",
      "Step 3350 | Loss: 0.59087 | LR: 9.31e-04\n",
      "Step 3375 | Loss: 0.60578 | LR: 9.29e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5966\n",
      "Step 3400 | Loss: 0.64871 | LR: 9.28e-04\n",
      "Step 3425 | Loss: 0.58446 | LR: 9.27e-04\n",
      "Step 3450 | Loss: 0.65419 | LR: 9.25e-04\n",
      "Step 3475 | Loss: 0.60771 | LR: 9.24e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5912\n",
      "Step 3500 | Loss: 0.60049 | LR: 9.23e-04\n",
      "Step 3525 | Loss: 0.61435 | LR: 9.21e-04\n",
      "Step 3550 | Loss: 0.59190 | LR: 9.20e-04\n",
      "Step 3575 | Loss: 0.59926 | LR: 9.18e-04\n",
      "val loss: 0.5935\n",
      "Step 3600 | Loss: 0.62636 | LR: 9.17e-04\n",
      "Step 3625 | Loss: 0.61105 | LR: 9.16e-04\n",
      "Step 3650 | Loss: 0.58330 | LR: 9.14e-04\n",
      "Step 3675 | Loss: 0.57559 | LR: 9.13e-04\n",
      "val loss: 0.5884\n",
      "Step 3700 | Loss: 0.59713 | LR: 9.11e-04\n",
      "Step 3725 | Loss: 0.59229 | LR: 9.10e-04\n",
      "Step 3750 | Loss: 0.61270 | LR: 9.08e-04\n",
      "Step 3775 | Loss: 0.58184 | LR: 9.07e-04\n",
      "val loss: 0.5911\n",
      "Step 3800 | Loss: 0.60818 | LR: 9.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 3825 | Loss: 0.61272 | LR: 9.04e-04\n",
      "Step 3850 | Loss: 0.59981 | LR: 9.02e-04\n",
      "Step 3875 | Loss: 0.56931 | LR: 9.01e-04\n",
      "val loss: 0.5967\n",
      "Step 3900 | Loss: 0.59719 | LR: 8.99e-04\n",
      "Step 3925 | Loss: 0.60225 | LR: 8.97e-04\n",
      "Step 3950 | Loss: 0.61605 | LR: 8.96e-04\n",
      "Step 3975 | Loss: 0.57443 | LR: 8.94e-04\n",
      "val loss: 0.5953\n",
      "Step 4000 | Loss: 0.59902 | LR: 8.93e-04\n",
      "Step 4025 | Loss: 0.60318 | LR: 8.91e-04\n",
      "Step 4050 | Loss: 0.57521 | LR: 8.89e-04\n",
      "Step 4075 | Loss: 0.59644 | LR: 8.88e-04\n",
      "val loss: 0.5884\n",
      "Step 4100 | Loss: 0.58751 | LR: 8.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 4125 | Loss: 0.59368 | LR: 8.84e-04\n",
      "Step 4150 | Loss: 0.60199 | LR: 8.83e-04\n",
      "Step 4175 | Loss: 0.58407 | LR: 8.81e-04\n",
      "val loss: 0.5899\n",
      "Step 4200 | Loss: 0.59790 | LR: 8.79e-04\n",
      "Step 4225 | Loss: 0.63261 | LR: 8.78e-04\n",
      "Step 4250 | Loss: 0.59689 | LR: 8.76e-04\n",
      "Step 4275 | Loss: 0.59734 | LR: 8.74e-04\n",
      "val loss: 0.5888\n",
      "Step 4300 | Loss: 0.57901 | LR: 8.73e-04\n",
      "Step 4325 | Loss: 0.60332 | LR: 8.71e-04\n",
      "Step 4350 | Loss: 0.64141 | LR: 8.69e-04\n",
      "Step 4375 | Loss: 0.60170 | LR: 8.67e-04\n",
      "val loss: 0.6003\n",
      "Step 4400 | Loss: 0.62274 | LR: 8.65e-04\n",
      "Step 4425 | Loss: 0.63079 | LR: 8.64e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 4450 | Loss: 0.61347 | LR: 8.62e-04\n",
      "Step 4475 | Loss: 0.59619 | LR: 8.60e-04\n",
      "val loss: 0.6072\n",
      "Step 4500 | Loss: 0.63723 | LR: 8.58e-04\n",
      "Step 4525 | Loss: 0.57829 | LR: 8.56e-04\n",
      "Step 4550 | Loss: 0.58912 | LR: 8.55e-04\n",
      "Step 4575 | Loss: 0.62951 | LR: 8.53e-04\n",
      "val loss: 0.5902\n",
      "Step 4600 | Loss: 0.58137 | LR: 8.51e-04\n",
      "Step 4625 | Loss: 0.58117 | LR: 8.49e-04\n",
      "Step 4650 | Loss: 0.59055 | LR: 8.47e-04\n",
      "Step 4675 | Loss: 0.61670 | LR: 8.45e-04\n",
      "val loss: 0.5978\n",
      "Step 4700 | Loss: 0.58454 | LR: 8.43e-04\n",
      "Step 4725 | Loss: 0.59085 | LR: 8.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 4750 | Loss: 0.59289 | LR: 8.40e-04\n",
      "Step 4775 | Loss: 0.58273 | LR: 8.38e-04\n",
      "val loss: 0.5941\n",
      "Step 4800 | Loss: 0.59085 | LR: 8.36e-04\n",
      "Step 4825 | Loss: 0.59860 | LR: 8.34e-04\n",
      "Step 4850 | Loss: 0.58347 | LR: 8.32e-04\n",
      "Step 4875 | Loss: 0.60836 | LR: 8.30e-04\n",
      "val loss: 0.5903\n",
      "Step 4900 | Loss: 0.63331 | LR: 8.28e-04\n",
      "Step 4925 | Loss: 0.61862 | LR: 8.26e-04\n",
      "Step 4950 | Loss: 0.61409 | LR: 8.24e-04\n",
      "Step 4975 | Loss: 0.60805 | LR: 8.22e-04\n",
      "val loss: 0.5885\n",
      "Step 5000 | Loss: 0.57573 | LR: 8.20e-04\n",
      "Step 5025 | Loss: 0.63211 | LR: 8.18e-04\n",
      "Step 5050 | Loss: 0.59374 | LR: 8.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 5075 | Loss: 0.56266 | LR: 8.14e-04\n",
      "val loss: 0.5989\n",
      "Step 5100 | Loss: 0.59766 | LR: 8.12e-04\n",
      "Step 5125 | Loss: 0.57732 | LR: 8.10e-04\n",
      "Step 5150 | Loss: 0.58649 | LR: 8.08e-04\n",
      "Step 5175 | Loss: 0.60979 | LR: 8.06e-04\n",
      "val loss: 0.5951\n",
      "Step 5200 | Loss: 0.61577 | LR: 8.04e-04\n",
      "Step 5225 | Loss: 0.62397 | LR: 8.02e-04\n",
      "Step 5250 | Loss: 0.61635 | LR: 8.00e-04\n",
      "Step 5275 | Loss: 0.54697 | LR: 7.98e-04\n",
      "val loss: 0.5889\n",
      "Step 5300 | Loss: 0.62086 | LR: 7.96e-04\n",
      "Step 5325 | Loss: 0.59830 | LR: 7.93e-04\n",
      "Step 5350 | Loss: 0.62247 | LR: 7.91e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 5375 | Loss: 0.58651 | LR: 7.89e-04\n",
      "val loss: 0.5997\n",
      "Step 5400 | Loss: 0.55974 | LR: 7.87e-04\n",
      "Step 5425 | Loss: 0.58804 | LR: 7.85e-04\n",
      "Step 5450 | Loss: 0.60113 | LR: 7.83e-04\n",
      "Step 5475 | Loss: 0.62072 | LR: 7.81e-04\n",
      "val loss: 0.6022\n",
      "Step 5500 | Loss: 0.64139 | LR: 7.78e-04\n",
      "Step 5525 | Loss: 0.63297 | LR: 7.76e-04\n",
      "Step 5550 | Loss: 0.59578 | LR: 7.74e-04\n",
      "Step 5575 | Loss: 0.60321 | LR: 7.72e-04\n",
      "val loss: 0.5867\n",
      "Step 5600 | Loss: 0.61737 | LR: 7.70e-04\n",
      "Step 5625 | Loss: 0.59002 | LR: 7.68e-04\n",
      "Step 5650 | Loss: 0.54492 | LR: 7.65e-04\n",
      "Step 5675 | Loss: 0.61902 | LR: 7.63e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "val loss: 0.5985\n",
      "Step 5700 | Loss: 0.61254 | LR: 7.61e-04\n",
      "Step 5725 | Loss: 0.62081 | LR: 7.59e-04\n",
      "Step 5750 | Loss: 0.57676 | LR: 7.57e-04\n",
      "Step 5775 | Loss: 0.64848 | LR: 7.54e-04\n",
      "val loss: 0.5973\n",
      "Step 5800 | Loss: 0.61250 | LR: 7.52e-04\n",
      "Step 5825 | Loss: 0.64014 | LR: 7.50e-04\n",
      "Step 5850 | Loss: 0.59586 | LR: 7.48e-04\n",
      "Step 5875 | Loss: 0.60109 | LR: 7.45e-04\n",
      "val loss: 0.5836\n",
      "Step 5900 | Loss: 0.59933 | LR: 7.43e-04\n",
      "Step 5925 | Loss: 0.57487 | LR: 7.41e-04\n",
      "Step 5950 | Loss: 0.58347 | LR: 7.38e-04\n",
      "Step 5975 | Loss: 0.62487 | LR: 7.36e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.6008\n",
      "Step 6000 | Loss: 0.54524 | LR: 7.34e-04\n",
      "Step 6025 | Loss: 0.61533 | LR: 7.32e-04\n",
      "Step 6050 | Loss: 0.59932 | LR: 7.29e-04\n",
      "Step 6075 | Loss: 0.57535 | LR: 7.27e-04\n",
      "val loss: 0.6095\n",
      "Step 6100 | Loss: 0.61556 | LR: 7.25e-04\n",
      "Step 6125 | Loss: 0.58744 | LR: 7.22e-04\n",
      "Step 6150 | Loss: 0.61506 | LR: 7.20e-04\n",
      "Step 6175 | Loss: 0.62627 | LR: 7.18e-04\n",
      "val loss: 0.5893\n",
      "Step 6200 | Loss: 0.62015 | LR: 7.15e-04\n",
      "Step 6225 | Loss: 0.59428 | LR: 7.13e-04\n",
      "Step 6250 | Loss: 0.60525 | LR: 7.11e-04\n",
      "Step 6275 | Loss: 0.61448 | LR: 7.08e-04\n",
      "val loss: 0.5896\n",
      "Step 6300 | Loss: 0.59098 | LR: 7.06e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6325 | Loss: 0.61101 | LR: 7.03e-04\n",
      "Step 6350 | Loss: 0.64228 | LR: 7.01e-04\n",
      "=== Epoch 2 Done. Avg Loss: 0.60070 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 6375 | Loss: 0.59661 | LR: 6.99e-04\n",
      "val loss: 0.6064\n",
      "Step 6400 | Loss: 0.62946 | LR: 6.96e-04\n",
      "Step 6425 | Loss: 0.59191 | LR: 6.94e-04\n",
      "Step 6450 | Loss: 0.59050 | LR: 6.91e-04\n",
      "Step 6475 | Loss: 0.59412 | LR: 6.89e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5940\n",
      "Step 6500 | Loss: 0.63267 | LR: 6.87e-04\n",
      "Step 6525 | Loss: 0.58559 | LR: 6.84e-04\n",
      "Step 6550 | Loss: 0.56836 | LR: 6.82e-04\n",
      "Step 6575 | Loss: 0.61890 | LR: 6.79e-04\n",
      "val loss: 0.6007\n",
      "Step 6600 | Loss: 0.63593 | LR: 6.77e-04\n",
      "Step 6625 | Loss: 0.65814 | LR: 6.75e-04\n",
      "Step 6650 | Loss: 0.59596 | LR: 6.72e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6675 | Loss: 0.56260 | LR: 6.70e-04\n",
      "val loss: 0.6065\n",
      "Step 6700 | Loss: 0.57758 | LR: 6.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 6725 | Loss: 0.58691 | LR: 6.65e-04\n",
      "Step 6750 | Loss: 0.61793 | LR: 6.62e-04\n",
      "Step 6775 | Loss: 0.61143 | LR: 6.60e-04\n",
      "val loss: 0.6006\n",
      "Step 6800 | Loss: 0.59528 | LR: 6.57e-04\n",
      "Step 6825 | Loss: 0.60878 | LR: 6.55e-04\n",
      "Step 6850 | Loss: 0.64207 | LR: 6.52e-04\n",
      "Step 6875 | Loss: 0.59049 | LR: 6.50e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6047\n",
      "Step 6900 | Loss: 0.61688 | LR: 6.47e-04\n",
      "Step 6925 | Loss: 0.55396 | LR: 6.45e-04\n",
      "Step 6950 | Loss: 0.60785 | LR: 6.42e-04\n",
      "Step 6975 | Loss: 0.62827 | LR: 6.40e-04\n",
      "val loss: 0.5874\n",
      "Step 7000 | Loss: 0.59271 | LR: 6.37e-04\n",
      "Step 7025 | Loss: 0.57656 | LR: 6.35e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 7050 | Loss: 0.57362 | LR: 6.32e-04\n",
      "Step 7075 | Loss: 0.54985 | LR: 6.30e-04\n",
      "val loss: 0.5876\n",
      "Step 7100 | Loss: 0.61846 | LR: 6.27e-04\n",
      "Step 7125 | Loss: 0.61771 | LR: 6.25e-04\n",
      "Step 7150 | Loss: 0.59856 | LR: 6.22e-04\n",
      "Step 7175 | Loss: 0.58942 | LR: 6.20e-04\n",
      "val loss: 0.5898\n",
      "Step 7200 | Loss: 0.60261 | LR: 6.17e-04\n",
      "Step 7225 | Loss: 0.66589 | LR: 6.15e-04\n",
      "Step 7250 | Loss: 0.58052 | LR: 6.12e-04\n",
      "Step 7275 | Loss: 0.57903 | LR: 6.10e-04\n",
      "val loss: 0.5985\n",
      "Step 7300 | Loss: 0.59822 | LR: 6.07e-04\n",
      "Step 7325 | Loss: 0.60237 | LR: 6.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 7350 | Loss: 0.57177 | LR: 6.02e-04\n",
      "Step 7375 | Loss: 0.58025 | LR: 6.00e-04\n",
      "val loss: 0.6015\n",
      "Step 7400 | Loss: 0.58497 | LR: 5.97e-04\n",
      "Step 7425 | Loss: 0.61722 | LR: 5.94e-04\n",
      "Step 7450 | Loss: 0.62575 | LR: 5.92e-04\n",
      "Step 7475 | Loss: 0.62090 | LR: 5.89e-04\n",
      "val loss: 0.5976\n",
      "Step 7500 | Loss: 0.56160 | LR: 5.87e-04\n",
      "Step 7525 | Loss: 0.58364 | LR: 5.84e-04\n",
      "Step 7550 | Loss: 0.60139 | LR: 5.82e-04\n",
      "Step 7575 | Loss: 0.60946 | LR: 5.79e-04\n",
      "val loss: 0.5969\n",
      "Step 7600 | Loss: 0.62994 | LR: 5.76e-04\n",
      "Step 7625 | Loss: 0.61857 | LR: 5.74e-04\n",
      "Step 7650 | Loss: 0.57010 | LR: 5.71e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 7675 | Loss: 0.61630 | LR: 5.69e-04\n",
      "val loss: 0.5938\n",
      "Step 7700 | Loss: 0.60820 | LR: 5.66e-04\n",
      "Step 7725 | Loss: 0.61268 | LR: 5.64e-04\n",
      "Step 7750 | Loss: 0.58531 | LR: 5.61e-04\n",
      "Step 7775 | Loss: 0.57242 | LR: 5.58e-04\n",
      "val loss: 0.5985\n",
      "Step 7800 | Loss: 0.60731 | LR: 5.56e-04\n",
      "Step 7825 | Loss: 0.57922 | LR: 5.53e-04\n",
      "Step 7850 | Loss: 0.58684 | LR: 5.51e-04\n",
      "Step 7875 | Loss: 0.58207 | LR: 5.48e-04\n",
      "val loss: 0.5961\n",
      "Step 7900 | Loss: 0.58076 | LR: 5.45e-04\n",
      "Step 7925 | Loss: 0.59752 | LR: 5.43e-04\n",
      "Step 7950 | Loss: 0.57715 | LR: 5.40e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 7975 | Loss: 0.57815 | LR: 5.38e-04\n",
      "val loss: 0.5987\n",
      "Step 8000 | Loss: 0.60178 | LR: 5.35e-04\n",
      "Step 8025 | Loss: 0.59064 | LR: 5.33e-04\n",
      "Step 8050 | Loss: 0.56768 | LR: 5.30e-04\n",
      "Step 8075 | Loss: 0.62928 | LR: 5.27e-04\n",
      "val loss: 0.5961\n",
      "Step 8100 | Loss: 0.61903 | LR: 5.25e-04\n",
      "Step 8125 | Loss: 0.58175 | LR: 5.22e-04\n",
      "Step 8150 | Loss: 0.60463 | LR: 5.20e-04\n",
      "Step 8175 | Loss: 0.59763 | LR: 5.17e-04\n",
      "val loss: 0.5913\n",
      "Step 8200 | Loss: 0.60747 | LR: 5.14e-04\n",
      "Step 8225 | Loss: 0.61879 | LR: 5.12e-04\n",
      "Step 8250 | Loss: 0.63413 | LR: 5.09e-04\n",
      "Step 8275 | Loss: 0.62336 | LR: 5.07e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.6002\n",
      "Step 8300 | Loss: 0.61256 | LR: 5.04e-04\n",
      "Step 8325 | Loss: 0.58331 | LR: 5.01e-04\n",
      "Step 8350 | Loss: 0.64844 | LR: 4.99e-04\n",
      "Step 8375 | Loss: 0.61563 | LR: 4.96e-04\n",
      "val loss: 0.5960\n",
      "Step 8400 | Loss: 0.62032 | LR: 4.94e-04\n",
      "Step 8425 | Loss: 0.60019 | LR: 4.91e-04\n",
      "Step 8450 | Loss: 0.62950 | LR: 4.88e-04\n",
      "Step 8475 | Loss: 0.60314 | LR: 4.86e-04\n",
      "val loss: 0.5946\n",
      "Step 8500 | Loss: 0.61188 | LR: 4.83e-04\n",
      "Step 8525 | Loss: 0.57260 | LR: 4.81e-04\n",
      "Step 8550 | Loss: 0.59049 | LR: 4.78e-04\n",
      "Step 8575 | Loss: 0.59640 | LR: 4.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "val loss: 0.5901\n",
      "Step 8600 | Loss: 0.62278 | LR: 4.73e-04\n",
      "Step 8625 | Loss: 0.57297 | LR: 4.70e-04\n",
      "Step 8650 | Loss: 0.57383 | LR: 4.68e-04\n",
      "Step 8675 | Loss: 0.63066 | LR: 4.65e-04\n",
      "val loss: 0.5965\n",
      "Step 8700 | Loss: 0.58797 | LR: 4.62e-04\n",
      "Step 8725 | Loss: 0.57479 | LR: 4.60e-04\n",
      "Step 8750 | Loss: 0.61715 | LR: 4.57e-04\n",
      "Step 8775 | Loss: 0.59974 | LR: 4.55e-04\n",
      "val loss: 0.5929\n",
      "Step 8800 | Loss: 0.56949 | LR: 4.52e-04\n",
      "Step 8825 | Loss: 0.58645 | LR: 4.49e-04\n",
      "Step 8850 | Loss: 0.61085 | LR: 4.47e-04\n",
      "Step 8875 | Loss: 0.58102 | LR: 4.44e-04\n",
      "val loss: 0.5926\n",
      "Step 8900 | Loss: 0.61580 | LR: 4.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 8925 | Loss: 0.57929 | LR: 4.39e-04\n",
      "Step 8950 | Loss: 0.60923 | LR: 4.36e-04\n",
      "Step 8975 | Loss: 0.62127 | LR: 4.34e-04\n",
      "val loss: 0.6110\n",
      "Step 9000 | Loss: 0.55161 | LR: 4.31e-04\n",
      "Step 9025 | Loss: 0.60437 | LR: 4.29e-04\n",
      "Step 9050 | Loss: 0.61380 | LR: 4.26e-04\n",
      "Step 9075 | Loss: 0.57036 | LR: 4.24e-04\n",
      "val loss: 0.5932\n",
      "Step 9100 | Loss: 0.60525 | LR: 4.21e-04\n",
      "Step 9125 | Loss: 0.60217 | LR: 4.18e-04\n",
      "Step 9150 | Loss: 0.57831 | LR: 4.16e-04\n",
      "Step 9175 | Loss: 0.59804 | LR: 4.13e-04\n",
      "val loss: 0.6048\n",
      "Step 9200 | Loss: 0.60779 | LR: 4.11e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 9225 | Loss: 0.60444 | LR: 4.08e-04\n",
      "Step 9250 | Loss: 0.57179 | LR: 4.06e-04\n",
      "Step 9275 | Loss: 0.57219 | LR: 4.03e-04\n",
      "val loss: 0.5970\n",
      "Step 9300 | Loss: 0.60032 | LR: 4.00e-04\n",
      "Step 9325 | Loss: 0.60946 | LR: 3.98e-04\n",
      "Step 9350 | Loss: 0.59924 | LR: 3.95e-04\n",
      "Step 9375 | Loss: 0.58888 | LR: 3.93e-04\n",
      "val loss: 0.5957\n",
      "Step 9400 | Loss: 0.58419 | LR: 3.90e-04\n",
      "Step 9425 | Loss: 0.61271 | LR: 3.88e-04\n",
      "Step 9450 | Loss: 0.61602 | LR: 3.85e-04\n",
      "Step 9475 | Loss: 0.61571 | LR: 3.83e-04\n",
      "val loss: 0.5801\n",
      "Step 9500 | Loss: 0.56177 | LR: 3.80e-04\n",
      "Step 9525 | Loss: 0.62552 | LR: 3.78e-04\n",
      "=== Epoch 3 Done. Avg Loss: 0.60067 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 9550 | Loss: 0.62278 | LR: 3.75e-04\n",
      "Step 9575 | Loss: 0.60725 | LR: 3.73e-04\n",
      "val loss: 0.5941\n",
      "Step 9600 | Loss: 0.57545 | LR: 3.70e-04\n",
      "Step 9625 | Loss: 0.58917 | LR: 3.68e-04\n",
      "Step 9650 | Loss: 0.59652 | LR: 3.65e-04\n",
      "Step 9675 | Loss: 0.62514 | LR: 3.63e-04\n",
      "val loss: 0.5794\n",
      "Step 9700 | Loss: 0.58621 | LR: 3.60e-04\n",
      "Step 9725 | Loss: 0.62217 | LR: 3.58e-04\n",
      "Step 9750 | Loss: 0.61366 | LR: 3.55e-04\n",
      "Step 9775 | Loss: 0.61150 | LR: 3.53e-04\n",
      "val loss: 0.5885\n",
      "Step 9800 | Loss: 0.58718 | LR: 3.50e-04\n",
      "Step 9825 | Loss: 0.57850 | LR: 3.48e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 9850 | Loss: 0.59208 | LR: 3.45e-04\n",
      "Step 9875 | Loss: 0.59204 | LR: 3.43e-04\n",
      "val loss: 0.5910\n",
      "Step 9900 | Loss: 0.61315 | LR: 3.40e-04\n",
      "Step 9925 | Loss: 0.59641 | LR: 3.38e-04\n",
      "Step 9950 | Loss: 0.59693 | LR: 3.35e-04\n",
      "Step 9975 | Loss: 0.58821 | LR: 3.33e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5920\n",
      "Step 10000 | Loss: 0.61416 | LR: 3.30e-04\n",
      "Step 10025 | Loss: 0.59419 | LR: 3.28e-04\n",
      "Step 10050 | Loss: 0.56859 | LR: 3.26e-04\n",
      "Step 10075 | Loss: 0.60679 | LR: 3.23e-04\n",
      "val loss: 0.6071\n",
      "Step 10100 | Loss: 0.62625 | LR: 3.21e-04\n",
      "Step 10125 | Loss: 0.63756 | LR: 3.18e-04\n",
      "Step 10150 | Loss: 0.57077 | LR: 3.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 10175 | Loss: 0.58275 | LR: 3.13e-04\n",
      "val loss: 0.5968\n",
      "Step 10200 | Loss: 0.58790 | LR: 3.11e-04\n",
      "Step 10225 | Loss: 0.57385 | LR: 3.09e-04\n",
      "Step 10250 | Loss: 0.62451 | LR: 3.06e-04\n",
      "Step 10275 | Loss: 0.59086 | LR: 3.04e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.6054\n",
      "Step 10300 | Loss: 0.61623 | LR: 3.01e-04\n",
      "Step 10325 | Loss: 0.58439 | LR: 2.99e-04\n",
      "Step 10350 | Loss: 0.60021 | LR: 2.97e-04\n",
      "Step 10375 | Loss: 0.58388 | LR: 2.94e-04\n",
      "val loss: 0.6013\n",
      "Step 10400 | Loss: 0.56986 | LR: 2.92e-04\n",
      "Step 10425 | Loss: 0.59630 | LR: 2.90e-04\n",
      "Step 10450 | Loss: 0.59559 | LR: 2.87e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 10475 | Loss: 0.62846 | LR: 2.85e-04\n",
      "val loss: 0.5973\n",
      "Step 10500 | Loss: 0.60120 | LR: 2.82e-04\n",
      "Step 10525 | Loss: 0.60863 | LR: 2.80e-04\n",
      "Step 10550 | Loss: 0.55491 | LR: 2.78e-04\n",
      "Step 10575 | Loss: 0.63718 | LR: 2.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6068\n",
      "Step 10600 | Loss: 0.59916 | LR: 2.73e-04\n",
      "Step 10625 | Loss: 0.57009 | LR: 2.71e-04\n",
      "Step 10650 | Loss: 0.60927 | LR: 2.68e-04\n",
      "Step 10675 | Loss: 0.60325 | LR: 2.66e-04\n",
      "val loss: 0.5941\n",
      "Step 10700 | Loss: 0.60938 | LR: 2.64e-04\n",
      "Step 10725 | Loss: 0.58816 | LR: 2.62e-04\n",
      "Step 10750 | Loss: 0.62579 | LR: 2.59e-04\n",
      "Step 10775 | Loss: 0.58960 | LR: 2.57e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "val loss: 0.5912\n",
      "Step 10800 | Loss: 0.60014 | LR: 2.55e-04\n",
      "Step 10825 | Loss: 0.55998 | LR: 2.53e-04\n",
      "Step 10850 | Loss: 0.58248 | LR: 2.50e-04\n",
      "Step 10875 | Loss: 0.56010 | LR: 2.48e-04\n",
      "val loss: 0.5998\n",
      "Step 10900 | Loss: 0.59268 | LR: 2.46e-04\n",
      "Step 10925 | Loss: 0.58775 | LR: 2.44e-04\n",
      "Step 10950 | Loss: 0.57693 | LR: 2.41e-04\n",
      "Step 10975 | Loss: 0.60214 | LR: 2.39e-04\n",
      "val loss: 0.5962\n",
      "Step 11000 | Loss: 0.62090 | LR: 2.37e-04\n",
      "Step 11025 | Loss: 0.61972 | LR: 2.35e-04\n",
      "Step 11050 | Loss: 0.60251 | LR: 2.32e-04\n",
      "Step 11075 | Loss: 0.61631 | LR: 2.30e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "val loss: 0.5937\n",
      "Step 11100 | Loss: 0.59468 | LR: 2.28e-04\n",
      "Step 11125 | Loss: 0.58675 | LR: 2.26e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 11150 | Loss: 0.61332 | LR: 2.24e-04\n",
      "Step 11175 | Loss: 0.60182 | LR: 2.22e-04\n",
      "val loss: 0.6121\n",
      "Step 11200 | Loss: 0.58673 | LR: 2.19e-04\n",
      "Step 11225 | Loss: 0.58277 | LR: 2.17e-04\n",
      "Step 11250 | Loss: 0.57987 | LR: 2.15e-04\n",
      "Step 11275 | Loss: 0.56460 | LR: 2.13e-04\n",
      "val loss: 0.6083\n",
      "Step 11300 | Loss: 0.58697 | LR: 2.11e-04\n",
      "Step 11325 | Loss: 0.59477 | LR: 2.09e-04\n",
      "Step 11350 | Loss: 0.63806 | LR: 2.07e-04\n",
      "Step 11375 | Loss: 0.59425 | LR: 2.04e-04\n",
      "val loss: 0.6014\n",
      "Step 11400 | Loss: 0.60310 | LR: 2.02e-04\n",
      "Step 11425 | Loss: 0.61404 | LR: 2.00e-04\n",
      "Step 11450 | Loss: 0.59442 | LR: 1.98e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 11475 | Loss: 0.57455 | LR: 1.96e-04\n",
      "val loss: 0.5884\n",
      "Step 11500 | Loss: 0.60644 | LR: 1.94e-04\n",
      "Step 11525 | Loss: 0.61245 | LR: 1.92e-04\n",
      "Step 11550 | Loss: 0.61198 | LR: 1.90e-04\n",
      "Step 11575 | Loss: 0.58166 | LR: 1.88e-04\n",
      "val loss: 0.5824\n",
      "Step 11600 | Loss: 0.60694 | LR: 1.86e-04\n",
      "Step 11625 | Loss: 0.57554 | LR: 1.84e-04\n",
      "Step 11650 | Loss: 0.63144 | LR: 1.82e-04\n",
      "Step 11675 | Loss: 0.60407 | LR: 1.80e-04\n",
      "val loss: 0.5903\n",
      "Step 11700 | Loss: 0.65152 | LR: 1.78e-04\n",
      "Step 11725 | Loss: 0.57778 | LR: 1.76e-04\n",
      "Step 11750 | Loss: 0.63088 | LR: 1.74e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 11775 | Loss: 0.58127 | LR: 1.72e-04\n",
      "val loss: 0.5915\n",
      "Step 11800 | Loss: 0.59464 | LR: 1.70e-04\n",
      "Step 11825 | Loss: 0.57315 | LR: 1.68e-04\n",
      "Step 11850 | Loss: 0.61697 | LR: 1.66e-04\n",
      "Step 11875 | Loss: 0.56563 | LR: 1.64e-04\n",
      "val loss: 0.5846\n",
      "Step 11900 | Loss: 0.59355 | LR: 1.62e-04\n",
      "Step 11925 | Loss: 0.60743 | LR: 1.60e-04\n",
      "Step 11950 | Loss: 0.58848 | LR: 1.58e-04\n",
      "Step 11975 | Loss: 0.62183 | LR: 1.57e-04\n",
      "val loss: 0.5947\n",
      "Step 12000 | Loss: 0.57275 | LR: 1.55e-04\n",
      "Step 12025 | Loss: 0.58449 | LR: 1.53e-04\n",
      "Step 12050 | Loss: 0.59667 | LR: 1.51e-04\n",
      "Step 12075 | Loss: 0.61957 | LR: 1.49e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5865\n",
      "Step 12100 | Loss: 0.60608 | LR: 1.47e-04\n",
      "Step 12125 | Loss: 0.59045 | LR: 1.45e-04\n",
      "Step 12150 | Loss: 0.62806 | LR: 1.44e-04\n",
      "Step 12175 | Loss: 0.60559 | LR: 1.42e-04\n",
      "val loss: 0.6052\n",
      "Step 12200 | Loss: 0.56707 | LR: 1.40e-04\n",
      "Step 12225 | Loss: 0.61903 | LR: 1.38e-04\n",
      "Step 12250 | Loss: 0.61775 | LR: 1.36e-04\n",
      "Step 12275 | Loss: 0.62386 | LR: 1.35e-04\n",
      "val loss: 0.5782\n",
      "Step 12300 | Loss: 0.62971 | LR: 1.33e-04\n",
      "Step 12325 | Loss: 0.58419 | LR: 1.31e-04\n",
      "Step 12350 | Loss: 0.61873 | LR: 1.29e-04\n",
      "Step 12375 | Loss: 0.59317 | LR: 1.28e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5872\n",
      "Step 12400 | Loss: 0.61964 | LR: 1.26e-04\n",
      "Step 12425 | Loss: 0.58714 | LR: 1.24e-04\n",
      "Step 12450 | Loss: 0.61911 | LR: 1.22e-04\n",
      "Step 12475 | Loss: 0.55520 | LR: 1.21e-04\n",
      "val loss: 0.5959\n",
      "Step 12500 | Loss: 0.59090 | LR: 1.19e-04\n",
      "Step 12525 | Loss: 0.61829 | LR: 1.17e-04\n",
      "Step 12550 | Loss: 0.58663 | LR: 1.16e-04\n",
      "Step 12575 | Loss: 0.62921 | LR: 1.14e-04\n",
      "val loss: 0.6006\n",
      "Step 12600 | Loss: 0.59644 | LR: 1.12e-04\n",
      "Step 12625 | Loss: 0.57720 | LR: 1.11e-04\n",
      "Step 12650 | Loss: 0.59907 | LR: 1.09e-04\n",
      "Step 12675 | Loss: 0.63261 | LR: 1.07e-04\n",
      "val loss: 0.6111\n",
      "Step 12700 | Loss: 0.62990 | LR: 1.06e-04\n",
      "=== Epoch 4 Done. Avg Loss: 0.60068 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 12725 | Loss: 0.53470 | LR: 1.04e-04\n",
      "Step 12750 | Loss: 0.62536 | LR: 1.03e-04\n",
      "Step 12775 | Loss: 0.60284 | LR: 1.01e-04\n",
      "val loss: 0.5975\n",
      "Step 12800 | Loss: 0.61449 | LR: 9.95e-05\n",
      "Step 12825 | Loss: 0.58968 | LR: 9.79e-05\n",
      "Step 12850 | Loss: 0.58660 | LR: 9.64e-05\n",
      "Step 12875 | Loss: 0.59522 | LR: 9.49e-05\n",
      "val loss: 0.5892\n",
      "Step 12900 | Loss: 0.58218 | LR: 9.34e-05\n",
      "Step 12925 | Loss: 0.57990 | LR: 9.18e-05\n",
      "Step 12950 | Loss: 0.59970 | LR: 9.03e-05\n",
      "Step 12975 | Loss: 0.59656 | LR: 8.89e-05\n",
      "val loss: 0.5916\n",
      "Step 13000 | Loss: 0.56004 | LR: 8.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 13025 | Loss: 0.58147 | LR: 8.59e-05\n",
      "Step 13050 | Loss: 0.57388 | LR: 8.45e-05\n",
      "Step 13075 | Loss: 0.58503 | LR: 8.30e-05\n",
      "val loss: 0.5904\n",
      "Step 13100 | Loss: 0.56374 | LR: 8.16e-05\n",
      "Step 13125 | Loss: 0.57299 | LR: 8.02e-05\n",
      "Step 13150 | Loss: 0.61398 | LR: 7.88e-05\n",
      "Step 13175 | Loss: 0.57062 | LR: 7.74e-05\n",
      "val loss: 0.5968\n",
      "Step 13200 | Loss: 0.59810 | LR: 7.60e-05\n",
      "Step 13225 | Loss: 0.63077 | LR: 7.46e-05\n",
      "Step 13250 | Loss: 0.60786 | LR: 7.33e-05\n",
      "Step 13275 | Loss: 0.59280 | LR: 7.19e-05\n",
      "val loss: 0.5941\n",
      "Step 13300 | Loss: 0.64702 | LR: 7.06e-05\n",
      "Step 13325 | Loss: 0.56726 | LR: 6.92e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 13350 | Loss: 0.59102 | LR: 6.79e-05\n",
      "Step 13375 | Loss: 0.60416 | LR: 6.66e-05\n",
      "val loss: 0.6003\n",
      "Step 13400 | Loss: 0.59620 | LR: 6.53e-05\n",
      "Step 13425 | Loss: 0.60310 | LR: 6.40e-05\n",
      "Step 13450 | Loss: 0.58293 | LR: 6.28e-05\n",
      "Step 13475 | Loss: 0.59270 | LR: 6.15e-05\n",
      "val loss: 0.5933\n",
      "Step 13500 | Loss: 0.60819 | LR: 6.03e-05\n",
      "Step 13525 | Loss: 0.63018 | LR: 5.90e-05\n",
      "Step 13550 | Loss: 0.62868 | LR: 5.78e-05\n",
      "Step 13575 | Loss: 0.58689 | LR: 5.66e-05\n",
      "val loss: 0.5880\n",
      "Step 13600 | Loss: 0.61012 | LR: 5.54e-05\n",
      "Step 13625 | Loss: 0.61321 | LR: 5.42e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 13650 | Loss: 0.57533 | LR: 5.31e-05\n",
      "Step 13675 | Loss: 0.60994 | LR: 5.19e-05\n",
      "val loss: 0.5986\n",
      "Step 13700 | Loss: 0.59048 | LR: 5.08e-05\n",
      "Step 13725 | Loss: 0.58553 | LR: 4.96e-05\n",
      "Step 13750 | Loss: 0.59436 | LR: 4.85e-05\n",
      "Step 13775 | Loss: 0.57047 | LR: 4.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.6019\n",
      "Step 13800 | Loss: 0.60569 | LR: 4.63e-05\n",
      "Step 13825 | Loss: 0.60041 | LR: 4.52e-05\n",
      "Step 13850 | Loss: 0.61610 | LR: 4.41e-05\n",
      "Step 13875 | Loss: 0.61920 | LR: 4.31e-05\n",
      "val loss: 0.5936\n",
      "Step 13900 | Loss: 0.59429 | LR: 4.20e-05\n",
      "Step 13925 | Loss: 0.54090 | LR: 4.10e-05\n",
      "Step 13950 | Loss: 0.59202 | LR: 3.99e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 13975 | Loss: 0.60127 | LR: 3.89e-05\n",
      "val loss: 0.6060\n",
      "Step 14000 | Loss: 0.60135 | LR: 3.79e-05\n",
      "Step 14025 | Loss: 0.60579 | LR: 3.69e-05\n",
      "Step 14050 | Loss: 0.57612 | LR: 3.60e-05\n",
      "Step 14075 | Loss: 0.55624 | LR: 3.50e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6049\n",
      "Step 14100 | Loss: 0.59615 | LR: 3.41e-05\n",
      "Step 14125 | Loss: 0.63436 | LR: 3.31e-05\n",
      "Step 14150 | Loss: 0.59791 | LR: 3.22e-05\n",
      "Step 14175 | Loss: 0.60791 | LR: 3.13e-05\n",
      "val loss: 0.5943\n",
      "Step 14200 | Loss: 0.59647 | LR: 3.04e-05\n",
      "Step 14225 | Loss: 0.57332 | LR: 2.95e-05\n",
      "Step 14250 | Loss: 0.53324 | LR: 2.86e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 14275 | Loss: 0.58654 | LR: 2.78e-05\n",
      "val loss: 0.6011\n",
      "Step 14300 | Loss: 0.61052 | LR: 2.69e-05\n",
      "Step 14325 | Loss: 0.59005 | LR: 2.61e-05\n",
      "Step 14350 | Loss: 0.57529 | LR: 2.53e-05\n",
      "Step 14375 | Loss: 0.57305 | LR: 2.44e-05\n",
      "val loss: 0.6044\n",
      "Step 14400 | Loss: 0.60892 | LR: 2.36e-05\n",
      "Step 14425 | Loss: 0.55297 | LR: 2.29e-05\n",
      "Step 14450 | Loss: 0.57431 | LR: 2.21e-05\n",
      "Step 14475 | Loss: 0.58622 | LR: 2.13e-05\n",
      "val loss: 0.5896\n",
      "Step 14500 | Loss: 0.58762 | LR: 2.06e-05\n",
      "Step 14525 | Loss: 0.56586 | LR: 1.99e-05\n",
      "Step 14550 | Loss: 0.62901 | LR: 1.91e-05\n",
      "Step 14575 | Loss: 0.59679 | LR: 1.84e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5935\n",
      "Step 14600 | Loss: 0.57396 | LR: 1.77e-05\n",
      "Step 14625 | Loss: 0.61614 | LR: 1.71e-05\n",
      "Step 14650 | Loss: 0.58677 | LR: 1.64e-05\n",
      "Step 14675 | Loss: 0.56974 | LR: 1.57e-05\n",
      "val loss: 0.5925\n",
      "Step 14700 | Loss: 0.60110 | LR: 1.51e-05\n",
      "Step 14725 | Loss: 0.58913 | LR: 1.45e-05\n",
      "Step 14750 | Loss: 0.62273 | LR: 1.38e-05\n",
      "Step 14775 | Loss: 0.63137 | LR: 1.32e-05\n",
      "val loss: 0.5952\n",
      "Step 14800 | Loss: 0.59471 | LR: 1.27e-05\n",
      "Step 14825 | Loss: 0.59785 | LR: 1.21e-05\n",
      "Step 14850 | Loss: 0.56764 | LR: 1.15e-05\n",
      "Step 14875 | Loss: 0.59176 | LR: 1.10e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5975\n",
      "Step 14900 | Loss: 0.60577 | LR: 1.04e-05\n",
      "Step 14925 | Loss: 0.62594 | LR: 9.91e-06\n",
      "Step 14950 | Loss: 0.61536 | LR: 9.41e-06\n",
      "Step 14975 | Loss: 0.56691 | LR: 8.91e-06\n",
      "val loss: 0.5940\n",
      "Step 15000 | Loss: 0.62608 | LR: 8.43e-06\n",
      "Step 15025 | Loss: 0.61061 | LR: 7.96e-06\n",
      "Step 15050 | Loss: 0.61178 | LR: 7.50e-06\n",
      "Step 15075 | Loss: 0.55776 | LR: 7.06e-06\n",
      "val loss: 0.5937\n",
      "Step 15100 | Loss: 0.61049 | LR: 6.63e-06\n",
      "Step 15125 | Loss: 0.61824 | LR: 6.22e-06\n",
      "Step 15150 | Loss: 0.59351 | LR: 5.81e-06\n",
      "Step 15175 | Loss: 0.57944 | LR: 5.43e-06\n",
      "val loss: 0.5969\n",
      "Step 15200 | Loss: 0.60809 | LR: 5.05e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 15225 | Loss: 0.58918 | LR: 4.69e-06\n",
      "Step 15250 | Loss: 0.58718 | LR: 4.34e-06\n",
      "Step 15275 | Loss: 0.55661 | LR: 4.00e-06\n",
      "val loss: 0.5975\n",
      "Step 15300 | Loss: 0.56148 | LR: 3.68e-06\n",
      "Step 15325 | Loss: 0.62030 | LR: 3.37e-06\n",
      "Step 15350 | Loss: 0.57660 | LR: 3.08e-06\n",
      "Step 15375 | Loss: 0.57640 | LR: 2.80e-06\n",
      "val loss: 0.5848\n",
      "Step 15400 | Loss: 0.63461 | LR: 2.53e-06\n",
      "Step 15425 | Loss: 0.59866 | LR: 2.28e-06\n",
      "Step 15450 | Loss: 0.59987 | LR: 2.03e-06\n",
      "Step 15475 | Loss: 0.58278 | LR: 1.81e-06\n",
      "val loss: 0.5881\n",
      "Step 15500 | Loss: 0.61824 | LR: 1.59e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 15525 | Loss: 0.60949 | LR: 1.39e-06\n",
      "Step 15550 | Loss: 0.59685 | LR: 1.20e-06\n",
      "Step 15575 | Loss: 0.58588 | LR: 1.03e-06\n",
      "val loss: 0.5974\n",
      "Step 15600 | Loss: 0.60320 | LR: 8.71e-07\n",
      "Step 15625 | Loss: 0.61980 | LR: 7.25e-07\n",
      "Step 15650 | Loss: 0.63836 | LR: 5.92e-07\n",
      "Step 15675 | Loss: 0.56696 | LR: 4.73e-07\n",
      "val loss: 0.5864\n",
      "Step 15700 | Loss: 0.58214 | LR: 3.67e-07\n",
      "Step 15725 | Loss: 0.61141 | LR: 2.74e-07\n",
      "Step 15750 | Loss: 0.58575 | LR: 1.96e-07\n",
      "Step 15775 | Loss: 0.56649 | LR: 1.30e-07\n",
      "val loss: 0.5905\n",
      "Step 15800 | Loss: 0.55787 | LR: 7.86e-08\n",
      "Step 15825 | Loss: 0.61243 | LR: 4.04e-08\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 15850 | Loss: 0.64750 | LR: 1.58e-08\n",
      "Step 15875 | Loss: 0.61295 | LR: 4.69e-09\n",
      "val loss: 0.5978\n",
      "=== Epoch 5 Done. Avg Loss: 0.60064 ===\n",
      "Saved final checkpoint: linear_decoder_ckpt_15884_final.pt\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "val_lossi = []\n",
    "total_epoch_loss = 0\n",
    "\n",
    "decoder.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    if step % 100 == 0 or last_step:\n",
    "        biojepa.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 10\n",
    "            for i in range(val_loss_steps):\n",
    "                xc, xct, xt, xtt, p_idx, p_mod, p_mode = val_loader.next_batch()\n",
    "                p_feats = input_bank[p_idx]\n",
    "                B, N = xc.shape\n",
    "\n",
    "                action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "                z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "                target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "                z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "                pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "                real_delta = xt - xc\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_accum / val_loss_steps\n",
    "            val_lossi.append(avg_val_loss)\n",
    "            print(f'val loss: {avg_val_loss:.4f}')\n",
    "        decoder.train()\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0 and not last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    xc, xct, xt, xtt, p_idx, p_mod, p_mode = train_loader.next_batch()\n",
    "    p_feats = input_bank[p_idx]\n",
    "    B, N = xc.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "        action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "    real_delta = xt - xc\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f'Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0:\n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f'=== Epoch {(step + 1) // steps_per_epoch} Done. Avg Loss: {avg_loss:.5f} ===')\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "    if last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}_final.pt')\n",
    "        print(f'Saved final checkpoint: linear_decoder_ckpt_{step}_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-header",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loss-plot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(lossi, alpha=0.7)\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].set_ylabel('Train Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].plot(val_lossi, 'o-', color='orange')\n",
    "axes[1].set_xlabel('Validation Check (every 100 steps)')\n",
    "axes[1].set_ylabel('Val Loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Final train loss: 0.6335\n",
      "Final val loss: 0.5978\n",
      "Checkpoint saved: /Users/djemec/data/jepa/v0_5/checkpoints/linear_decoder_ckpt_15884_final.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*60)\n",
    "print(f'Final train loss: {lossi[-1]:.4f}')\n",
    "print(f'Final val loss: {val_lossi[-1]:.4f}')\n",
    "print(f'Checkpoint saved: {checkpoint_dir / f\"linear_decoder_ckpt_{max_steps-1}_final.pt\"}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c7d10-570d-4fa2-8aa2-89f9e60a3d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
