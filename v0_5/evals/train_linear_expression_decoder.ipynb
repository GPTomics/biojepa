{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Train Linear Expression Decoder\n",
    "\n",
    "Trains a linear probe decoder on frozen BioJEPA latent representations to predict expression deltas.\n",
    "\n",
    "The trained decoder is used by evaluation notebooks (eval_1, eval_2, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import biojepa_ac_v0_5 as model\n",
    "from bio_dataloader import TrainingLoader\n",
    "from linear_expression_decoder import BenchmarkDecoder, BenchmarkDecoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "n_genes = 5000\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "n_embd = 8\n",
    "pert_latent_dim = 320\n",
    "pert_mode_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_4')\n",
    "train_dir = data_dir / 'training'\n",
    "checkpoint_dir = Path('/Users/djemec/data/jepa/v0_5') / 'checkpoints'\n",
    "pert_dir = data_dir / 'pert_embd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Bank (DNA): torch.Size([1250, 1536])\n"
     ]
    }
   ],
   "source": [
    "input_bank = torch.from_numpy(np.load(pert_dir / 'input_embeddings_dna.npy')).float().to(DEVICE)\n",
    "print(f'Input Bank (DNA): {input_bank.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Load BioJEPA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "config = model.BioJepaConfig(\n",
    "    num_genes=n_genes,\n",
    "    n_layer=n_layers,\n",
    "    heads=n_heads,\n",
    "    embed_dim=n_embd,\n",
    "    n_pre_layer=n_layers,\n",
    "    pert_latent_dim=pert_latent_dim,\n",
    "    pert_mode_dim=pert_mode_dim\n",
    ")\n",
    "biojepa = model.BioJepa(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-checkpoint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_ckpt_31769_final.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "keys = biojepa.load_state_dict(checkpoint['model'])\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freeze-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "biojepa.freeze_encoders()\n",
    "biojepa.eval()\n",
    "for param in biojepa.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "data-loaders",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 11 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "found 2 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = TrainingLoader(batch_size=batch_size, split='train', data_dir=train_dir, device=DEVICE)\n",
    "val_loader = TrainingLoader(batch_size=batch_size, split='val', data_dir=train_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoder-header",
   "metadata": {},
   "source": [
    "## Initialize Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "init-decoder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder parameters: 9\n"
     ]
    }
   ],
   "source": [
    "decoder_config = BenchmarkDecoderConfig(embed_dim=n_embd)\n",
    "decoder = BenchmarkDecoder(decoder_config).to(DEVICE)\n",
    "print(f'Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 3177\n",
      "Total steps: 15885\n"
     ]
    }
   ],
   "source": [
    "lr_decoder = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "train_total_examples = 101682\n",
    "steps_per_epoch = train_total_examples // batch_size\n",
    "max_steps = epochs * steps_per_epoch\n",
    "\n",
    "print(f'Steps per epoch: {steps_per_epoch}')\n",
    "print(f'Total steps: {max_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-header",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "training-loop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 2.8340\n",
      "Step 0 | Loss: 2.76603 | LR: 4.00e-05\n",
      "Step 25 | Loss: 2.72534 | LR: 4.25e-05\n",
      "Step 50 | Loss: 2.82748 | LR: 4.98e-05\n",
      "Step 75 | Loss: 2.78194 | LR: 6.16e-05\n",
      "val loss: 2.8221\n",
      "Step 100 | Loss: 2.75629 | LR: 7.79e-05\n",
      "Step 125 | Loss: 2.70778 | LR: 9.85e-05\n",
      "Step 150 | Loss: 2.84229 | LR: 1.23e-04\n",
      "Step 175 | Loss: 2.56005 | LR: 1.52e-04\n",
      "val loss: 2.6116\n",
      "Step 200 | Loss: 2.67643 | LR: 1.84e-04\n",
      "Step 225 | Loss: 2.44690 | LR: 2.20e-04\n",
      "Step 250 | Loss: 2.39885 | LR: 2.58e-04\n",
      "Step 275 | Loss: 2.37594 | LR: 2.99e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 2.3351\n",
      "Step 300 | Loss: 2.41970 | LR: 3.43e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 325 | Loss: 2.36239 | LR: 3.87e-04\n",
      "Step 350 | Loss: 2.21244 | LR: 4.34e-04\n",
      "Step 375 | Loss: 2.03955 | LR: 4.81e-04\n",
      "val loss: 2.0205\n",
      "Step 400 | Loss: 2.15426 | LR: 5.28e-04\n",
      "Step 425 | Loss: 1.89188 | LR: 5.76e-04\n",
      "Step 450 | Loss: 1.83986 | LR: 6.23e-04\n",
      "Step 475 | Loss: 1.71826 | LR: 6.68e-04\n",
      "val loss: 1.6214\n",
      "Step 500 | Loss: 1.52144 | LR: 7.13e-04\n",
      "Step 525 | Loss: 1.51510 | LR: 7.55e-04\n",
      "Step 550 | Loss: 1.47173 | LR: 7.96e-04\n",
      "Step 575 | Loss: 1.45303 | LR: 8.33e-04\n",
      "val loss: 1.2644\n",
      "Step 600 | Loss: 1.29238 | LR: 8.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 625 | Loss: 1.20527 | LR: 8.98e-04\n",
      "Step 650 | Loss: 1.10900 | LR: 9.26e-04\n",
      "Step 675 | Loss: 1.03298 | LR: 9.49e-04\n",
      "val loss: 0.9839\n",
      "Step 700 | Loss: 1.00182 | LR: 9.68e-04\n",
      "Step 725 | Loss: 0.95374 | LR: 9.83e-04\n",
      "Step 750 | Loss: 0.94626 | LR: 9.93e-04\n",
      "Step 775 | Loss: 0.83955 | LR: 9.99e-04\n",
      "val loss: 0.8224\n",
      "Step 800 | Loss: 0.87767 | LR: 1.00e-03\n",
      "Step 825 | Loss: 0.78521 | LR: 1.00e-03\n",
      "Step 850 | Loss: 0.73988 | LR: 1.00e-03\n",
      "Step 875 | Loss: 0.69564 | LR: 1.00e-03\n",
      "val loss: 0.7251\n",
      "Step 900 | Loss: 0.71815 | LR: 1.00e-03\n",
      "Step 925 | Loss: 0.70221 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 950 | Loss: 0.74583 | LR: 1.00e-03\n",
      "Step 975 | Loss: 0.72957 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "val loss: 0.6706\n",
      "Step 1000 | Loss: 0.65771 | LR: 1.00e-03\n",
      "Step 1025 | Loss: 0.68300 | LR: 9.99e-04\n",
      "Step 1050 | Loss: 0.66720 | LR: 9.99e-04\n",
      "Step 1075 | Loss: 0.63325 | LR: 9.99e-04\n",
      "val loss: 0.6421\n",
      "Step 1100 | Loss: 0.64561 | LR: 9.99e-04\n",
      "Step 1125 | Loss: 0.63444 | LR: 9.99e-04\n",
      "Step 1150 | Loss: 0.66419 | LR: 9.99e-04\n",
      "Step 1175 | Loss: 0.62406 | LR: 9.98e-04\n",
      "val loss: 0.6243\n",
      "Step 1200 | Loss: 0.60698 | LR: 9.98e-04\n",
      "Step 1225 | Loss: 0.63435 | LR: 9.98e-04\n",
      "Step 1250 | Loss: 0.63569 | LR: 9.98e-04\n",
      "Step 1275 | Loss: 0.65327 | LR: 9.97e-04\n",
      "val loss: 0.6139\n",
      "Step 1300 | Loss: 0.62839 | LR: 9.97e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 1325 | Loss: 0.60395 | LR: 9.97e-04\n",
      "Step 1350 | Loss: 0.65228 | LR: 9.97e-04\n",
      "Step 1375 | Loss: 0.62837 | LR: 9.96e-04\n",
      "val loss: 0.5985\n",
      "Step 1400 | Loss: 0.58477 | LR: 9.96e-04\n",
      "Step 1425 | Loss: 0.65428 | LR: 9.96e-04\n",
      "Step 1450 | Loss: 0.59533 | LR: 9.95e-04\n",
      "Step 1475 | Loss: 0.65463 | LR: 9.95e-04\n",
      "val loss: 0.6060\n",
      "Step 1500 | Loss: 0.63353 | LR: 9.95e-04\n",
      "Step 1525 | Loss: 0.61837 | LR: 9.94e-04\n",
      "Step 1550 | Loss: 0.62983 | LR: 9.94e-04\n",
      "Step 1575 | Loss: 0.65790 | LR: 9.93e-04\n",
      "val loss: 0.6165\n",
      "Step 1600 | Loss: 0.59728 | LR: 9.93e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 1625 | Loss: 0.62834 | LR: 9.93e-04\n",
      "Step 1650 | Loss: 0.59713 | LR: 9.92e-04\n",
      "Step 1675 | Loss: 0.60919 | LR: 9.92e-04\n",
      "val loss: 0.6018\n",
      "Step 1700 | Loss: 0.63998 | LR: 9.91e-04\n",
      "Step 1725 | Loss: 0.65076 | LR: 9.91e-04\n",
      "Step 1750 | Loss: 0.56840 | LR: 9.90e-04\n",
      "Step 1775 | Loss: 0.59563 | LR: 9.90e-04\n",
      "val loss: 0.6080\n",
      "Step 1800 | Loss: 0.61957 | LR: 9.89e-04\n",
      "Step 1825 | Loss: 0.61854 | LR: 9.88e-04\n",
      "Step 1850 | Loss: 0.63639 | LR: 9.88e-04\n",
      "Step 1875 | Loss: 0.60453 | LR: 9.87e-04\n",
      "val loss: 0.6124\n",
      "Step 1900 | Loss: 0.62494 | LR: 9.87e-04\n",
      "Step 1925 | Loss: 0.61223 | LR: 9.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 1950 | Loss: 0.60969 | LR: 9.86e-04\n",
      "Step 1975 | Loss: 0.63023 | LR: 9.85e-04\n",
      "val loss: 0.6134\n",
      "Step 2000 | Loss: 0.63226 | LR: 9.84e-04\n",
      "Step 2025 | Loss: 0.65305 | LR: 9.84e-04\n",
      "Step 2050 | Loss: 0.65136 | LR: 9.83e-04\n",
      "Step 2075 | Loss: 0.62636 | LR: 9.82e-04\n",
      "val loss: 0.6024\n",
      "Step 2100 | Loss: 0.61349 | LR: 9.82e-04\n",
      "Step 2125 | Loss: 0.59231 | LR: 9.81e-04\n",
      "Step 2150 | Loss: 0.63273 | LR: 9.80e-04\n",
      "Step 2175 | Loss: 0.60043 | LR: 9.79e-04\n",
      "val loss: 0.6030\n",
      "Step 2200 | Loss: 0.62447 | LR: 9.79e-04\n",
      "Step 2225 | Loss: 0.61459 | LR: 9.78e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 2250 | Loss: 0.56754 | LR: 9.77e-04\n",
      "Step 2275 | Loss: 0.62470 | LR: 9.76e-04\n",
      "val loss: 0.6017\n",
      "Step 2300 | Loss: 0.57777 | LR: 9.76e-04\n",
      "Step 2325 | Loss: 0.62219 | LR: 9.75e-04\n",
      "Step 2350 | Loss: 0.61206 | LR: 9.74e-04\n",
      "Step 2375 | Loss: 0.63604 | LR: 9.73e-04\n",
      "val loss: 0.6039\n",
      "Step 2400 | Loss: 0.62211 | LR: 9.72e-04\n",
      "Step 2425 | Loss: 0.57644 | LR: 9.71e-04\n",
      "Step 2450 | Loss: 0.57332 | LR: 9.71e-04\n",
      "Step 2475 | Loss: 0.64114 | LR: 9.70e-04\n",
      "val loss: 0.5996\n",
      "Step 2500 | Loss: 0.60197 | LR: 9.69e-04\n",
      "Step 2525 | Loss: 0.61728 | LR: 9.68e-04\n",
      "Step 2550 | Loss: 0.60960 | LR: 9.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 2575 | Loss: 0.61708 | LR: 9.66e-04\n",
      "val loss: 0.6113\n",
      "Step 2600 | Loss: 0.63298 | LR: 9.65e-04\n",
      "Step 2625 | Loss: 0.59398 | LR: 9.64e-04\n",
      "Step 2650 | Loss: 0.61532 | LR: 9.63e-04\n",
      "Step 2675 | Loss: 0.58324 | LR: 9.62e-04\n",
      "val loss: 0.6007\n",
      "Step 2700 | Loss: 0.63101 | LR: 9.61e-04\n",
      "Step 2725 | Loss: 0.62416 | LR: 9.60e-04\n",
      "Step 2750 | Loss: 0.61823 | LR: 9.59e-04\n",
      "Step 2775 | Loss: 0.56927 | LR: 9.58e-04\n",
      "val loss: 0.6144\n",
      "Step 2800 | Loss: 0.64548 | LR: 9.57e-04\n",
      "Step 2825 | Loss: 0.62108 | LR: 9.56e-04\n",
      "Step 2850 | Loss: 0.60835 | LR: 9.55e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 2875 | Loss: 0.58681 | LR: 9.54e-04\n",
      "val loss: 0.5952\n",
      "Step 2900 | Loss: 0.59928 | LR: 9.53e-04\n",
      "Step 2925 | Loss: 0.62801 | LR: 9.52e-04\n",
      "Step 2950 | Loss: 0.63148 | LR: 9.50e-04\n",
      "Step 2975 | Loss: 0.60226 | LR: 9.49e-04\n",
      "val loss: 0.6156\n",
      "Step 3000 | Loss: 0.58273 | LR: 9.48e-04\n",
      "Step 3025 | Loss: 0.60663 | LR: 9.47e-04\n",
      "Step 3050 | Loss: 0.61685 | LR: 9.46e-04\n",
      "Step 3075 | Loss: 0.60833 | LR: 9.45e-04\n",
      "val loss: 0.5912\n",
      "Step 3100 | Loss: 0.58249 | LR: 9.43e-04\n",
      "Step 3125 | Loss: 0.59402 | LR: 9.42e-04\n",
      "Step 3150 | Loss: 0.61100 | LR: 9.41e-04\n",
      "Step 3175 | Loss: 0.60287 | LR: 9.40e-04\n",
      "=== Epoch 1 Done. Avg Loss: 0.95814 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.6128\n",
      "Step 3200 | Loss: 0.58620 | LR: 9.38e-04\n",
      "Step 3225 | Loss: 0.62811 | LR: 9.37e-04\n",
      "Step 3250 | Loss: 0.60130 | LR: 9.36e-04\n",
      "Step 3275 | Loss: 0.61909 | LR: 9.35e-04\n",
      "val loss: 0.5893\n",
      "Step 3300 | Loss: 0.62558 | LR: 9.33e-04\n",
      "Step 3325 | Loss: 0.60875 | LR: 9.32e-04\n",
      "Step 3350 | Loss: 0.60457 | LR: 9.31e-04\n",
      "Step 3375 | Loss: 0.61465 | LR: 9.29e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6048\n",
      "Step 3400 | Loss: 0.58733 | LR: 9.28e-04\n",
      "Step 3425 | Loss: 0.62493 | LR: 9.27e-04\n",
      "Step 3450 | Loss: 0.60687 | LR: 9.25e-04\n",
      "Step 3475 | Loss: 0.60502 | LR: 9.24e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.6158\n",
      "Step 3500 | Loss: 0.59255 | LR: 9.23e-04\n",
      "Step 3525 | Loss: 0.63441 | LR: 9.21e-04\n",
      "Step 3550 | Loss: 0.59147 | LR: 9.20e-04\n",
      "Step 3575 | Loss: 0.59780 | LR: 9.18e-04\n",
      "val loss: 0.5977\n",
      "Step 3600 | Loss: 0.60676 | LR: 9.17e-04\n",
      "Step 3625 | Loss: 0.59238 | LR: 9.16e-04\n",
      "Step 3650 | Loss: 0.59408 | LR: 9.14e-04\n",
      "Step 3675 | Loss: 0.58991 | LR: 9.13e-04\n",
      "val loss: 0.6202\n",
      "Step 3700 | Loss: 0.63069 | LR: 9.11e-04\n",
      "Step 3725 | Loss: 0.60554 | LR: 9.10e-04\n",
      "Step 3750 | Loss: 0.59405 | LR: 9.08e-04\n",
      "Step 3775 | Loss: 0.59495 | LR: 9.07e-04\n",
      "val loss: 0.6089\n",
      "Step 3800 | Loss: 0.60245 | LR: 9.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 3825 | Loss: 0.59753 | LR: 9.04e-04\n",
      "Step 3850 | Loss: 0.58507 | LR: 9.02e-04\n",
      "Step 3875 | Loss: 0.60895 | LR: 9.01e-04\n",
      "val loss: 0.6118\n",
      "Step 3900 | Loss: 0.57711 | LR: 8.99e-04\n",
      "Step 3925 | Loss: 0.60616 | LR: 8.97e-04\n",
      "Step 3950 | Loss: 0.66531 | LR: 8.96e-04\n",
      "Step 3975 | Loss: 0.62195 | LR: 8.94e-04\n",
      "val loss: 0.6060\n",
      "Step 4000 | Loss: 0.59977 | LR: 8.93e-04\n",
      "Step 4025 | Loss: 0.58546 | LR: 8.91e-04\n",
      "Step 4050 | Loss: 0.62162 | LR: 8.89e-04\n",
      "Step 4075 | Loss: 0.63928 | LR: 8.88e-04\n",
      "val loss: 0.5859\n",
      "Step 4100 | Loss: 0.62067 | LR: 8.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 4125 | Loss: 0.59625 | LR: 8.84e-04\n",
      "Step 4150 | Loss: 0.55096 | LR: 8.83e-04\n",
      "Step 4175 | Loss: 0.57873 | LR: 8.81e-04\n",
      "val loss: 0.5976\n",
      "Step 4200 | Loss: 0.59188 | LR: 8.79e-04\n",
      "Step 4225 | Loss: 0.62814 | LR: 8.78e-04\n",
      "Step 4250 | Loss: 0.57778 | LR: 8.76e-04\n",
      "Step 4275 | Loss: 0.62314 | LR: 8.74e-04\n",
      "val loss: 0.6108\n",
      "Step 4300 | Loss: 0.61750 | LR: 8.73e-04\n",
      "Step 4325 | Loss: 0.61806 | LR: 8.71e-04\n",
      "Step 4350 | Loss: 0.60390 | LR: 8.69e-04\n",
      "Step 4375 | Loss: 0.62686 | LR: 8.67e-04\n",
      "val loss: 0.6114\n",
      "Step 4400 | Loss: 0.61562 | LR: 8.65e-04\n",
      "Step 4425 | Loss: 0.59262 | LR: 8.64e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 4450 | Loss: 0.62091 | LR: 8.62e-04\n",
      "Step 4475 | Loss: 0.60119 | LR: 8.60e-04\n",
      "val loss: 0.6047\n",
      "Step 4500 | Loss: 0.64364 | LR: 8.58e-04\n",
      "Step 4525 | Loss: 0.56774 | LR: 8.56e-04\n",
      "Step 4550 | Loss: 0.56336 | LR: 8.55e-04\n",
      "Step 4575 | Loss: 0.59491 | LR: 8.53e-04\n",
      "val loss: 0.6066\n",
      "Step 4600 | Loss: 0.59728 | LR: 8.51e-04\n",
      "Step 4625 | Loss: 0.61016 | LR: 8.49e-04\n",
      "Step 4650 | Loss: 0.62585 | LR: 8.47e-04\n",
      "Step 4675 | Loss: 0.58231 | LR: 8.45e-04\n",
      "val loss: 0.5973\n",
      "Step 4700 | Loss: 0.62570 | LR: 8.43e-04\n",
      "Step 4725 | Loss: 0.63743 | LR: 8.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 4750 | Loss: 0.61153 | LR: 8.40e-04\n",
      "Step 4775 | Loss: 0.63589 | LR: 8.38e-04\n",
      "val loss: 0.6083\n",
      "Step 4800 | Loss: 0.58623 | LR: 8.36e-04\n",
      "Step 4825 | Loss: 0.62730 | LR: 8.34e-04\n",
      "Step 4850 | Loss: 0.62058 | LR: 8.32e-04\n",
      "Step 4875 | Loss: 0.61997 | LR: 8.30e-04\n",
      "val loss: 0.6007\n",
      "Step 4900 | Loss: 0.59859 | LR: 8.28e-04\n",
      "Step 4925 | Loss: 0.62675 | LR: 8.26e-04\n",
      "Step 4950 | Loss: 0.60146 | LR: 8.24e-04\n",
      "Step 4975 | Loss: 0.60730 | LR: 8.22e-04\n",
      "val loss: 0.5929\n",
      "Step 5000 | Loss: 0.61738 | LR: 8.20e-04\n",
      "Step 5025 | Loss: 0.60106 | LR: 8.18e-04\n",
      "Step 5050 | Loss: 0.60209 | LR: 8.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 5075 | Loss: 0.62532 | LR: 8.14e-04\n",
      "val loss: 0.6073\n",
      "Step 5100 | Loss: 0.57892 | LR: 8.12e-04\n",
      "Step 5125 | Loss: 0.59868 | LR: 8.10e-04\n",
      "Step 5150 | Loss: 0.59617 | LR: 8.08e-04\n",
      "Step 5175 | Loss: 0.60730 | LR: 8.06e-04\n",
      "val loss: 0.6120\n",
      "Step 5200 | Loss: 0.60917 | LR: 8.04e-04\n",
      "Step 5225 | Loss: 0.61101 | LR: 8.02e-04\n",
      "Step 5250 | Loss: 0.60868 | LR: 8.00e-04\n",
      "Step 5275 | Loss: 0.60566 | LR: 7.98e-04\n",
      "val loss: 0.5906\n",
      "Step 5300 | Loss: 0.62915 | LR: 7.96e-04\n",
      "Step 5325 | Loss: 0.56798 | LR: 7.93e-04\n",
      "Step 5350 | Loss: 0.67590 | LR: 7.91e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 5375 | Loss: 0.60608 | LR: 7.89e-04\n",
      "val loss: 0.6181\n",
      "Step 5400 | Loss: 0.60206 | LR: 7.87e-04\n",
      "Step 5425 | Loss: 0.60894 | LR: 7.85e-04\n",
      "Step 5450 | Loss: 0.62576 | LR: 7.83e-04\n",
      "Step 5475 | Loss: 0.58816 | LR: 7.81e-04\n",
      "val loss: 0.6074\n",
      "Step 5500 | Loss: 0.60962 | LR: 7.78e-04\n",
      "Step 5525 | Loss: 0.61582 | LR: 7.76e-04\n",
      "Step 5550 | Loss: 0.58867 | LR: 7.74e-04\n",
      "Step 5575 | Loss: 0.65214 | LR: 7.72e-04\n",
      "val loss: 0.6120\n",
      "Step 5600 | Loss: 0.62216 | LR: 7.70e-04\n",
      "Step 5625 | Loss: 0.62574 | LR: 7.68e-04\n",
      "Step 5650 | Loss: 0.61504 | LR: 7.65e-04\n",
      "Step 5675 | Loss: 0.64659 | LR: 7.63e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "val loss: 0.5989\n",
      "Step 5700 | Loss: 0.62937 | LR: 7.61e-04\n",
      "Step 5725 | Loss: 0.59129 | LR: 7.59e-04\n",
      "Step 5750 | Loss: 0.59535 | LR: 7.57e-04\n",
      "Step 5775 | Loss: 0.64653 | LR: 7.54e-04\n",
      "val loss: 0.6014\n",
      "Step 5800 | Loss: 0.61600 | LR: 7.52e-04\n",
      "Step 5825 | Loss: 0.58937 | LR: 7.50e-04\n",
      "Step 5850 | Loss: 0.62970 | LR: 7.48e-04\n",
      "Step 5875 | Loss: 0.59598 | LR: 7.45e-04\n",
      "val loss: 0.6054\n",
      "Step 5900 | Loss: 0.57855 | LR: 7.43e-04\n",
      "Step 5925 | Loss: 0.55070 | LR: 7.41e-04\n",
      "Step 5950 | Loss: 0.62869 | LR: 7.38e-04\n",
      "Step 5975 | Loss: 0.59615 | LR: 7.36e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.6151\n",
      "Step 6000 | Loss: 0.61347 | LR: 7.34e-04\n",
      "Step 6025 | Loss: 0.61091 | LR: 7.32e-04\n",
      "Step 6050 | Loss: 0.56437 | LR: 7.29e-04\n",
      "Step 6075 | Loss: 0.59169 | LR: 7.27e-04\n",
      "val loss: 0.6038\n",
      "Step 6100 | Loss: 0.61675 | LR: 7.25e-04\n",
      "Step 6125 | Loss: 0.64337 | LR: 7.22e-04\n",
      "Step 6150 | Loss: 0.61808 | LR: 7.20e-04\n",
      "Step 6175 | Loss: 0.61430 | LR: 7.18e-04\n",
      "val loss: 0.6019\n",
      "Step 6200 | Loss: 0.56890 | LR: 7.15e-04\n",
      "Step 6225 | Loss: 0.64362 | LR: 7.13e-04\n",
      "Step 6250 | Loss: 0.61075 | LR: 7.11e-04\n",
      "Step 6275 | Loss: 0.59103 | LR: 7.08e-04\n",
      "val loss: 0.6046\n",
      "Step 6300 | Loss: 0.59562 | LR: 7.06e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6325 | Loss: 0.57717 | LR: 7.03e-04\n",
      "Step 6350 | Loss: 0.58083 | LR: 7.01e-04\n",
      "=== Epoch 2 Done. Avg Loss: 0.60931 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 6375 | Loss: 0.60097 | LR: 6.99e-04\n",
      "val loss: 0.6009\n",
      "Step 6400 | Loss: 0.60390 | LR: 6.96e-04\n",
      "Step 6425 | Loss: 0.59844 | LR: 6.94e-04\n",
      "Step 6450 | Loss: 0.60608 | LR: 6.91e-04\n",
      "Step 6475 | Loss: 0.60372 | LR: 6.89e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.6006\n",
      "Step 6500 | Loss: 0.60832 | LR: 6.87e-04\n",
      "Step 6525 | Loss: 0.61736 | LR: 6.84e-04\n",
      "Step 6550 | Loss: 0.60112 | LR: 6.82e-04\n",
      "Step 6575 | Loss: 0.61971 | LR: 6.79e-04\n",
      "val loss: 0.6024\n",
      "Step 6600 | Loss: 0.61605 | LR: 6.77e-04\n",
      "Step 6625 | Loss: 0.59378 | LR: 6.75e-04\n",
      "Step 6650 | Loss: 0.62989 | LR: 6.72e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6675 | Loss: 0.61366 | LR: 6.70e-04\n",
      "val loss: 0.6025\n",
      "Step 6700 | Loss: 0.62148 | LR: 6.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 6725 | Loss: 0.61213 | LR: 6.65e-04\n",
      "Step 6750 | Loss: 0.60662 | LR: 6.62e-04\n",
      "Step 6775 | Loss: 0.61322 | LR: 6.60e-04\n",
      "val loss: 0.6049\n",
      "Step 6800 | Loss: 0.61227 | LR: 6.57e-04\n",
      "Step 6825 | Loss: 0.61425 | LR: 6.55e-04\n",
      "Step 6850 | Loss: 0.58683 | LR: 6.52e-04\n",
      "Step 6875 | Loss: 0.58268 | LR: 6.50e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6008\n",
      "Step 6900 | Loss: 0.60266 | LR: 6.47e-04\n",
      "Step 6925 | Loss: 0.59315 | LR: 6.45e-04\n",
      "Step 6950 | Loss: 0.63868 | LR: 6.42e-04\n",
      "Step 6975 | Loss: 0.58475 | LR: 6.40e-04\n",
      "val loss: 0.6107\n",
      "Step 7000 | Loss: 0.62007 | LR: 6.37e-04\n",
      "Step 7025 | Loss: 0.60944 | LR: 6.35e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 7050 | Loss: 0.59678 | LR: 6.32e-04\n",
      "Step 7075 | Loss: 0.62502 | LR: 6.30e-04\n",
      "val loss: 0.5953\n",
      "Step 7100 | Loss: 0.64910 | LR: 6.27e-04\n",
      "Step 7125 | Loss: 0.60151 | LR: 6.25e-04\n",
      "Step 7150 | Loss: 0.62300 | LR: 6.22e-04\n",
      "Step 7175 | Loss: 0.62495 | LR: 6.20e-04\n",
      "val loss: 0.6146\n",
      "Step 7200 | Loss: 0.62648 | LR: 6.17e-04\n",
      "Step 7225 | Loss: 0.65083 | LR: 6.15e-04\n",
      "Step 7250 | Loss: 0.63921 | LR: 6.12e-04\n",
      "Step 7275 | Loss: 0.60149 | LR: 6.10e-04\n",
      "val loss: 0.5966\n",
      "Step 7300 | Loss: 0.59078 | LR: 6.07e-04\n",
      "Step 7325 | Loss: 0.60699 | LR: 6.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 7350 | Loss: 0.60684 | LR: 6.02e-04\n",
      "Step 7375 | Loss: 0.62825 | LR: 6.00e-04\n",
      "val loss: 0.5947\n",
      "Step 7400 | Loss: 0.61270 | LR: 5.97e-04\n",
      "Step 7425 | Loss: 0.59824 | LR: 5.94e-04\n",
      "Step 7450 | Loss: 0.58489 | LR: 5.92e-04\n",
      "Step 7475 | Loss: 0.60399 | LR: 5.89e-04\n",
      "val loss: 0.6058\n",
      "Step 7500 | Loss: 0.62315 | LR: 5.87e-04\n",
      "Step 7525 | Loss: 0.60082 | LR: 5.84e-04\n",
      "Step 7550 | Loss: 0.61839 | LR: 5.82e-04\n",
      "Step 7575 | Loss: 0.61023 | LR: 5.79e-04\n",
      "val loss: 0.5981\n",
      "Step 7600 | Loss: 0.59702 | LR: 5.76e-04\n",
      "Step 7625 | Loss: 0.63845 | LR: 5.74e-04\n",
      "Step 7650 | Loss: 0.60531 | LR: 5.71e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 7675 | Loss: 0.60607 | LR: 5.69e-04\n",
      "val loss: 0.6066\n",
      "Step 7700 | Loss: 0.61285 | LR: 5.66e-04\n",
      "Step 7725 | Loss: 0.62117 | LR: 5.64e-04\n",
      "Step 7750 | Loss: 0.58688 | LR: 5.61e-04\n",
      "Step 7775 | Loss: 0.63062 | LR: 5.58e-04\n",
      "val loss: 0.6123\n",
      "Step 7800 | Loss: 0.58059 | LR: 5.56e-04\n",
      "Step 7825 | Loss: 0.59261 | LR: 5.53e-04\n",
      "Step 7850 | Loss: 0.61812 | LR: 5.51e-04\n",
      "Step 7875 | Loss: 0.59829 | LR: 5.48e-04\n",
      "val loss: 0.6066\n",
      "Step 7900 | Loss: 0.65688 | LR: 5.45e-04\n",
      "Step 7925 | Loss: 0.60562 | LR: 5.43e-04\n",
      "Step 7950 | Loss: 0.61829 | LR: 5.40e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 7975 | Loss: 0.61981 | LR: 5.38e-04\n",
      "val loss: 0.5916\n",
      "Step 8000 | Loss: 0.62031 | LR: 5.35e-04\n",
      "Step 8025 | Loss: 0.62193 | LR: 5.33e-04\n",
      "Step 8050 | Loss: 0.62630 | LR: 5.30e-04\n",
      "Step 8075 | Loss: 0.58947 | LR: 5.27e-04\n",
      "val loss: 0.6056\n",
      "Step 8100 | Loss: 0.59921 | LR: 5.25e-04\n",
      "Step 8125 | Loss: 0.61212 | LR: 5.22e-04\n",
      "Step 8150 | Loss: 0.61233 | LR: 5.20e-04\n",
      "Step 8175 | Loss: 0.59448 | LR: 5.17e-04\n",
      "val loss: 0.5995\n",
      "Step 8200 | Loss: 0.62129 | LR: 5.14e-04\n",
      "Step 8225 | Loss: 0.63056 | LR: 5.12e-04\n",
      "Step 8250 | Loss: 0.60455 | LR: 5.09e-04\n",
      "Step 8275 | Loss: 0.60478 | LR: 5.07e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.6116\n",
      "Step 8300 | Loss: 0.60845 | LR: 5.04e-04\n",
      "Step 8325 | Loss: 0.60328 | LR: 5.01e-04\n",
      "Step 8350 | Loss: 0.64371 | LR: 4.99e-04\n",
      "Step 8375 | Loss: 0.60151 | LR: 4.96e-04\n",
      "val loss: 0.6124\n",
      "Step 8400 | Loss: 0.62915 | LR: 4.94e-04\n",
      "Step 8425 | Loss: 0.57839 | LR: 4.91e-04\n",
      "Step 8450 | Loss: 0.60127 | LR: 4.88e-04\n",
      "Step 8475 | Loss: 0.57676 | LR: 4.86e-04\n",
      "val loss: 0.6028\n",
      "Step 8500 | Loss: 0.59841 | LR: 4.83e-04\n",
      "Step 8525 | Loss: 0.57029 | LR: 4.81e-04\n",
      "Step 8550 | Loss: 0.59578 | LR: 4.78e-04\n",
      "Step 8575 | Loss: 0.62463 | LR: 4.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "val loss: 0.6020\n",
      "Step 8600 | Loss: 0.60734 | LR: 4.73e-04\n",
      "Step 8625 | Loss: 0.57758 | LR: 4.70e-04\n",
      "Step 8650 | Loss: 0.63826 | LR: 4.68e-04\n",
      "Step 8675 | Loss: 0.62042 | LR: 4.65e-04\n",
      "val loss: 0.6057\n",
      "Step 8700 | Loss: 0.60489 | LR: 4.62e-04\n",
      "Step 8725 | Loss: 0.60479 | LR: 4.60e-04\n",
      "Step 8750 | Loss: 0.62631 | LR: 4.57e-04\n",
      "Step 8775 | Loss: 0.59658 | LR: 4.55e-04\n",
      "val loss: 0.6092\n",
      "Step 8800 | Loss: 0.62083 | LR: 4.52e-04\n",
      "Step 8825 | Loss: 0.62678 | LR: 4.49e-04\n",
      "Step 8850 | Loss: 0.62339 | LR: 4.47e-04\n",
      "Step 8875 | Loss: 0.63300 | LR: 4.44e-04\n",
      "val loss: 0.6106\n",
      "Step 8900 | Loss: 0.60520 | LR: 4.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 8925 | Loss: 0.61010 | LR: 4.39e-04\n",
      "Step 8950 | Loss: 0.62075 | LR: 4.36e-04\n",
      "Step 8975 | Loss: 0.61805 | LR: 4.34e-04\n",
      "val loss: 0.6097\n",
      "Step 9000 | Loss: 0.62949 | LR: 4.31e-04\n",
      "Step 9025 | Loss: 0.60823 | LR: 4.29e-04\n",
      "Step 9050 | Loss: 0.61654 | LR: 4.26e-04\n",
      "Step 9075 | Loss: 0.65838 | LR: 4.24e-04\n",
      "val loss: 0.5935\n",
      "Step 9100 | Loss: 0.62163 | LR: 4.21e-04\n",
      "Step 9125 | Loss: 0.59866 | LR: 4.18e-04\n",
      "Step 9150 | Loss: 0.61095 | LR: 4.16e-04\n",
      "Step 9175 | Loss: 0.58241 | LR: 4.13e-04\n",
      "val loss: 0.6069\n",
      "Step 9200 | Loss: 0.63960 | LR: 4.11e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 9225 | Loss: 0.61802 | LR: 4.08e-04\n",
      "Step 9250 | Loss: 0.62112 | LR: 4.06e-04\n",
      "Step 9275 | Loss: 0.61464 | LR: 4.03e-04\n",
      "val loss: 0.6107\n",
      "Step 9300 | Loss: 0.57815 | LR: 4.00e-04\n",
      "Step 9325 | Loss: 0.59190 | LR: 3.98e-04\n",
      "Step 9350 | Loss: 0.64272 | LR: 3.95e-04\n",
      "Step 9375 | Loss: 0.61255 | LR: 3.93e-04\n",
      "val loss: 0.5974\n",
      "Step 9400 | Loss: 0.59621 | LR: 3.90e-04\n",
      "Step 9425 | Loss: 0.61080 | LR: 3.88e-04\n",
      "Step 9450 | Loss: 0.63277 | LR: 3.85e-04\n",
      "Step 9475 | Loss: 0.62228 | LR: 3.83e-04\n",
      "val loss: 0.6139\n",
      "Step 9500 | Loss: 0.62227 | LR: 3.80e-04\n",
      "Step 9525 | Loss: 0.59512 | LR: 3.78e-04\n",
      "=== Epoch 3 Done. Avg Loss: 0.60933 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 9550 | Loss: 0.59467 | LR: 3.75e-04\n",
      "Step 9575 | Loss: 0.62094 | LR: 3.73e-04\n",
      "val loss: 0.6221\n",
      "Step 9600 | Loss: 0.60139 | LR: 3.70e-04\n",
      "Step 9625 | Loss: 0.58723 | LR: 3.68e-04\n",
      "Step 9650 | Loss: 0.58833 | LR: 3.65e-04\n",
      "Step 9675 | Loss: 0.62156 | LR: 3.63e-04\n",
      "val loss: 0.6047\n",
      "Step 9700 | Loss: 0.60902 | LR: 3.60e-04\n",
      "Step 9725 | Loss: 0.62615 | LR: 3.58e-04\n",
      "Step 9750 | Loss: 0.60742 | LR: 3.55e-04\n",
      "Step 9775 | Loss: 0.62989 | LR: 3.53e-04\n",
      "val loss: 0.5998\n",
      "Step 9800 | Loss: 0.58171 | LR: 3.50e-04\n",
      "Step 9825 | Loss: 0.60375 | LR: 3.48e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 9850 | Loss: 0.59273 | LR: 3.45e-04\n",
      "Step 9875 | Loss: 0.59686 | LR: 3.43e-04\n",
      "val loss: 0.5981\n",
      "Step 9900 | Loss: 0.62859 | LR: 3.40e-04\n",
      "Step 9925 | Loss: 0.60317 | LR: 3.38e-04\n",
      "Step 9950 | Loss: 0.60055 | LR: 3.35e-04\n",
      "Step 9975 | Loss: 0.59851 | LR: 3.33e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.6053\n",
      "Step 10000 | Loss: 0.63808 | LR: 3.30e-04\n",
      "Step 10025 | Loss: 0.61148 | LR: 3.28e-04\n",
      "Step 10050 | Loss: 0.57838 | LR: 3.26e-04\n",
      "Step 10075 | Loss: 0.63831 | LR: 3.23e-04\n",
      "val loss: 0.6068\n",
      "Step 10100 | Loss: 0.63652 | LR: 3.21e-04\n",
      "Step 10125 | Loss: 0.62937 | LR: 3.18e-04\n",
      "Step 10150 | Loss: 0.59628 | LR: 3.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 10175 | Loss: 0.61524 | LR: 3.13e-04\n",
      "val loss: 0.6040\n",
      "Step 10200 | Loss: 0.58193 | LR: 3.11e-04\n",
      "Step 10225 | Loss: 0.60100 | LR: 3.09e-04\n",
      "Step 10250 | Loss: 0.62584 | LR: 3.06e-04\n",
      "Step 10275 | Loss: 0.58678 | LR: 3.04e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5909\n",
      "Step 10300 | Loss: 0.63617 | LR: 3.01e-04\n",
      "Step 10325 | Loss: 0.58017 | LR: 2.99e-04\n",
      "Step 10350 | Loss: 0.63919 | LR: 2.97e-04\n",
      "Step 10375 | Loss: 0.64721 | LR: 2.94e-04\n",
      "val loss: 0.6113\n",
      "Step 10400 | Loss: 0.62447 | LR: 2.92e-04\n",
      "Step 10425 | Loss: 0.60665 | LR: 2.90e-04\n",
      "Step 10450 | Loss: 0.63319 | LR: 2.87e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 10475 | Loss: 0.57203 | LR: 2.85e-04\n",
      "val loss: 0.6035\n",
      "Step 10500 | Loss: 0.61624 | LR: 2.82e-04\n",
      "Step 10525 | Loss: 0.59078 | LR: 2.80e-04\n",
      "Step 10550 | Loss: 0.64159 | LR: 2.78e-04\n",
      "Step 10575 | Loss: 0.61586 | LR: 2.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6098\n",
      "Step 10600 | Loss: 0.62832 | LR: 2.73e-04\n",
      "Step 10625 | Loss: 0.63955 | LR: 2.71e-04\n",
      "Step 10650 | Loss: 0.59127 | LR: 2.68e-04\n",
      "Step 10675 | Loss: 0.60543 | LR: 2.66e-04\n",
      "val loss: 0.6028\n",
      "Step 10700 | Loss: 0.64639 | LR: 2.64e-04\n",
      "Step 10725 | Loss: 0.58300 | LR: 2.62e-04\n",
      "Step 10750 | Loss: 0.60556 | LR: 2.59e-04\n",
      "Step 10775 | Loss: 0.63452 | LR: 2.57e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "val loss: 0.5950\n",
      "Step 10800 | Loss: 0.64600 | LR: 2.55e-04\n",
      "Step 10825 | Loss: 0.65017 | LR: 2.53e-04\n",
      "Step 10850 | Loss: 0.58656 | LR: 2.50e-04\n",
      "Step 10875 | Loss: 0.59753 | LR: 2.48e-04\n",
      "val loss: 0.6045\n",
      "Step 10900 | Loss: 0.58568 | LR: 2.46e-04\n",
      "Step 10925 | Loss: 0.62534 | LR: 2.44e-04\n",
      "Step 10950 | Loss: 0.60189 | LR: 2.41e-04\n",
      "Step 10975 | Loss: 0.60065 | LR: 2.39e-04\n",
      "val loss: 0.5972\n",
      "Step 11000 | Loss: 0.60114 | LR: 2.37e-04\n",
      "Step 11025 | Loss: 0.59295 | LR: 2.35e-04\n",
      "Step 11050 | Loss: 0.58824 | LR: 2.32e-04\n",
      "Step 11075 | Loss: 0.59956 | LR: 2.30e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "val loss: 0.6123\n",
      "Step 11100 | Loss: 0.58527 | LR: 2.28e-04\n",
      "Step 11125 | Loss: 0.60092 | LR: 2.26e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 11150 | Loss: 0.59784 | LR: 2.24e-04\n",
      "Step 11175 | Loss: 0.58989 | LR: 2.22e-04\n",
      "val loss: 0.6062\n",
      "Step 11200 | Loss: 0.61313 | LR: 2.19e-04\n",
      "Step 11225 | Loss: 0.59484 | LR: 2.17e-04\n",
      "Step 11250 | Loss: 0.62830 | LR: 2.15e-04\n",
      "Step 11275 | Loss: 0.60917 | LR: 2.13e-04\n",
      "val loss: 0.6062\n",
      "Step 11300 | Loss: 0.61207 | LR: 2.11e-04\n",
      "Step 11325 | Loss: 0.59566 | LR: 2.09e-04\n",
      "Step 11350 | Loss: 0.62513 | LR: 2.07e-04\n",
      "Step 11375 | Loss: 0.61535 | LR: 2.04e-04\n",
      "val loss: 0.6123\n",
      "Step 11400 | Loss: 0.58521 | LR: 2.02e-04\n",
      "Step 11425 | Loss: 0.59888 | LR: 2.00e-04\n",
      "Step 11450 | Loss: 0.60743 | LR: 1.98e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 11475 | Loss: 0.60583 | LR: 1.96e-04\n",
      "val loss: 0.6065\n",
      "Step 11500 | Loss: 0.59822 | LR: 1.94e-04\n",
      "Step 11525 | Loss: 0.62410 | LR: 1.92e-04\n",
      "Step 11550 | Loss: 0.63037 | LR: 1.90e-04\n",
      "Step 11575 | Loss: 0.60651 | LR: 1.88e-04\n",
      "val loss: 0.6083\n",
      "Step 11600 | Loss: 0.58579 | LR: 1.86e-04\n",
      "Step 11625 | Loss: 0.59378 | LR: 1.84e-04\n",
      "Step 11650 | Loss: 0.60228 | LR: 1.82e-04\n",
      "Step 11675 | Loss: 0.61901 | LR: 1.80e-04\n",
      "val loss: 0.5968\n",
      "Step 11700 | Loss: 0.62837 | LR: 1.78e-04\n",
      "Step 11725 | Loss: 0.62171 | LR: 1.76e-04\n",
      "Step 11750 | Loss: 0.62555 | LR: 1.74e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 11775 | Loss: 0.63370 | LR: 1.72e-04\n",
      "val loss: 0.6003\n",
      "Step 11800 | Loss: 0.60821 | LR: 1.70e-04\n",
      "Step 11825 | Loss: 0.60526 | LR: 1.68e-04\n",
      "Step 11850 | Loss: 0.60323 | LR: 1.66e-04\n",
      "Step 11875 | Loss: 0.60229 | LR: 1.64e-04\n",
      "val loss: 0.5965\n",
      "Step 11900 | Loss: 0.59702 | LR: 1.62e-04\n",
      "Step 11925 | Loss: 0.59355 | LR: 1.60e-04\n",
      "Step 11950 | Loss: 0.58285 | LR: 1.58e-04\n",
      "Step 11975 | Loss: 0.62253 | LR: 1.57e-04\n",
      "val loss: 0.6115\n",
      "Step 12000 | Loss: 0.60641 | LR: 1.55e-04\n",
      "Step 12025 | Loss: 0.59780 | LR: 1.53e-04\n",
      "Step 12050 | Loss: 0.61328 | LR: 1.51e-04\n",
      "Step 12075 | Loss: 0.60340 | LR: 1.49e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5971\n",
      "Step 12100 | Loss: 0.60483 | LR: 1.47e-04\n",
      "Step 12125 | Loss: 0.57940 | LR: 1.45e-04\n",
      "Step 12150 | Loss: 0.61724 | LR: 1.44e-04\n",
      "Step 12175 | Loss: 0.60471 | LR: 1.42e-04\n",
      "val loss: 0.5909\n",
      "Step 12200 | Loss: 0.59214 | LR: 1.40e-04\n",
      "Step 12225 | Loss: 0.61821 | LR: 1.38e-04\n",
      "Step 12250 | Loss: 0.63194 | LR: 1.36e-04\n",
      "Step 12275 | Loss: 0.57694 | LR: 1.35e-04\n",
      "val loss: 0.6013\n",
      "Step 12300 | Loss: 0.60350 | LR: 1.33e-04\n",
      "Step 12325 | Loss: 0.64530 | LR: 1.31e-04\n",
      "Step 12350 | Loss: 0.60986 | LR: 1.29e-04\n",
      "Step 12375 | Loss: 0.61544 | LR: 1.28e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5999\n",
      "Step 12400 | Loss: 0.62047 | LR: 1.26e-04\n",
      "Step 12425 | Loss: 0.62342 | LR: 1.24e-04\n",
      "Step 12450 | Loss: 0.61539 | LR: 1.22e-04\n",
      "Step 12475 | Loss: 0.60269 | LR: 1.21e-04\n",
      "val loss: 0.6133\n",
      "Step 12500 | Loss: 0.62435 | LR: 1.19e-04\n",
      "Step 12525 | Loss: 0.64246 | LR: 1.17e-04\n",
      "Step 12550 | Loss: 0.58656 | LR: 1.16e-04\n",
      "Step 12575 | Loss: 0.59678 | LR: 1.14e-04\n",
      "val loss: 0.6118\n",
      "Step 12600 | Loss: 0.61122 | LR: 1.12e-04\n",
      "Step 12625 | Loss: 0.60650 | LR: 1.11e-04\n",
      "Step 12650 | Loss: 0.60533 | LR: 1.09e-04\n",
      "Step 12675 | Loss: 0.61077 | LR: 1.07e-04\n",
      "val loss: 0.5976\n",
      "Step 12700 | Loss: 0.59515 | LR: 1.06e-04\n",
      "=== Epoch 4 Done. Avg Loss: 0.60930 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 12725 | Loss: 0.60945 | LR: 1.04e-04\n",
      "Step 12750 | Loss: 0.61683 | LR: 1.03e-04\n",
      "Step 12775 | Loss: 0.61555 | LR: 1.01e-04\n",
      "val loss: 0.6097\n",
      "Step 12800 | Loss: 0.61610 | LR: 9.95e-05\n",
      "Step 12825 | Loss: 0.58503 | LR: 9.79e-05\n",
      "Step 12850 | Loss: 0.60641 | LR: 9.64e-05\n",
      "Step 12875 | Loss: 0.59898 | LR: 9.49e-05\n",
      "val loss: 0.6127\n",
      "Step 12900 | Loss: 0.57048 | LR: 9.34e-05\n",
      "Step 12925 | Loss: 0.58113 | LR: 9.18e-05\n",
      "Step 12950 | Loss: 0.62156 | LR: 9.03e-05\n",
      "Step 12975 | Loss: 0.60969 | LR: 8.89e-05\n",
      "val loss: 0.6004\n",
      "Step 13000 | Loss: 0.61884 | LR: 8.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 13025 | Loss: 0.57482 | LR: 8.59e-05\n",
      "Step 13050 | Loss: 0.60566 | LR: 8.45e-05\n",
      "Step 13075 | Loss: 0.60970 | LR: 8.30e-05\n",
      "val loss: 0.6029\n",
      "Step 13100 | Loss: 0.60091 | LR: 8.16e-05\n",
      "Step 13125 | Loss: 0.58148 | LR: 8.02e-05\n",
      "Step 13150 | Loss: 0.59894 | LR: 7.88e-05\n",
      "Step 13175 | Loss: 0.58508 | LR: 7.74e-05\n",
      "val loss: 0.6064\n",
      "Step 13200 | Loss: 0.58656 | LR: 7.60e-05\n",
      "Step 13225 | Loss: 0.61368 | LR: 7.46e-05\n",
      "Step 13250 | Loss: 0.63289 | LR: 7.33e-05\n",
      "Step 13275 | Loss: 0.64447 | LR: 7.19e-05\n",
      "val loss: 0.6108\n",
      "Step 13300 | Loss: 0.57747 | LR: 7.06e-05\n",
      "Step 13325 | Loss: 0.59137 | LR: 6.92e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 13350 | Loss: 0.61818 | LR: 6.79e-05\n",
      "Step 13375 | Loss: 0.62507 | LR: 6.66e-05\n",
      "val loss: 0.6178\n",
      "Step 13400 | Loss: 0.60297 | LR: 6.53e-05\n",
      "Step 13425 | Loss: 0.60498 | LR: 6.40e-05\n",
      "Step 13450 | Loss: 0.62496 | LR: 6.28e-05\n",
      "Step 13475 | Loss: 0.59900 | LR: 6.15e-05\n",
      "val loss: 0.5974\n",
      "Step 13500 | Loss: 0.62408 | LR: 6.03e-05\n",
      "Step 13525 | Loss: 0.59655 | LR: 5.90e-05\n",
      "Step 13550 | Loss: 0.60862 | LR: 5.78e-05\n",
      "Step 13575 | Loss: 0.62703 | LR: 5.66e-05\n",
      "val loss: 0.6123\n",
      "Step 13600 | Loss: 0.62342 | LR: 5.54e-05\n",
      "Step 13625 | Loss: 0.60194 | LR: 5.42e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 13650 | Loss: 0.62033 | LR: 5.31e-05\n",
      "Step 13675 | Loss: 0.61032 | LR: 5.19e-05\n",
      "val loss: 0.6115\n",
      "Step 13700 | Loss: 0.56643 | LR: 5.08e-05\n",
      "Step 13725 | Loss: 0.60293 | LR: 4.96e-05\n",
      "Step 13750 | Loss: 0.61789 | LR: 4.85e-05\n",
      "Step 13775 | Loss: 0.58923 | LR: 4.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.6010\n",
      "Step 13800 | Loss: 0.61552 | LR: 4.63e-05\n",
      "Step 13825 | Loss: 0.64444 | LR: 4.52e-05\n",
      "Step 13850 | Loss: 0.60000 | LR: 4.41e-05\n",
      "Step 13875 | Loss: 0.63296 | LR: 4.31e-05\n",
      "val loss: 0.6043\n",
      "Step 13900 | Loss: 0.61218 | LR: 4.20e-05\n",
      "Step 13925 | Loss: 0.59157 | LR: 4.10e-05\n",
      "Step 13950 | Loss: 0.61184 | LR: 3.99e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 13975 | Loss: 0.60587 | LR: 3.89e-05\n",
      "val loss: 0.6039\n",
      "Step 14000 | Loss: 0.57739 | LR: 3.79e-05\n",
      "Step 14025 | Loss: 0.60241 | LR: 3.69e-05\n",
      "Step 14050 | Loss: 0.58644 | LR: 3.60e-05\n",
      "Step 14075 | Loss: 0.61656 | LR: 3.50e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.6108\n",
      "Step 14100 | Loss: 0.61309 | LR: 3.41e-05\n",
      "Step 14125 | Loss: 0.57969 | LR: 3.31e-05\n",
      "Step 14150 | Loss: 0.63114 | LR: 3.22e-05\n",
      "Step 14175 | Loss: 0.63044 | LR: 3.13e-05\n",
      "val loss: 0.6035\n",
      "Step 14200 | Loss: 0.61698 | LR: 3.04e-05\n",
      "Step 14225 | Loss: 0.58058 | LR: 2.95e-05\n",
      "Step 14250 | Loss: 0.57938 | LR: 2.86e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 14275 | Loss: 0.59074 | LR: 2.78e-05\n",
      "val loss: 0.6125\n",
      "Step 14300 | Loss: 0.62561 | LR: 2.69e-05\n",
      "Step 14325 | Loss: 0.60810 | LR: 2.61e-05\n",
      "Step 14350 | Loss: 0.58937 | LR: 2.53e-05\n",
      "Step 14375 | Loss: 0.63122 | LR: 2.44e-05\n",
      "val loss: 0.6202\n",
      "Step 14400 | Loss: 0.61183 | LR: 2.36e-05\n",
      "Step 14425 | Loss: 0.62414 | LR: 2.29e-05\n",
      "Step 14450 | Loss: 0.62391 | LR: 2.21e-05\n",
      "Step 14475 | Loss: 0.61524 | LR: 2.13e-05\n",
      "val loss: 0.6031\n",
      "Step 14500 | Loss: 0.60692 | LR: 2.06e-05\n",
      "Step 14525 | Loss: 0.62949 | LR: 1.99e-05\n",
      "Step 14550 | Loss: 0.61638 | LR: 1.91e-05\n",
      "Step 14575 | Loss: 0.61187 | LR: 1.84e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.6152\n",
      "Step 14600 | Loss: 0.60384 | LR: 1.77e-05\n",
      "Step 14625 | Loss: 0.61559 | LR: 1.71e-05\n",
      "Step 14650 | Loss: 0.59458 | LR: 1.64e-05\n",
      "Step 14675 | Loss: 0.63004 | LR: 1.57e-05\n",
      "val loss: 0.6051\n",
      "Step 14700 | Loss: 0.57588 | LR: 1.51e-05\n",
      "Step 14725 | Loss: 0.59360 | LR: 1.45e-05\n",
      "Step 14750 | Loss: 0.60768 | LR: 1.38e-05\n",
      "Step 14775 | Loss: 0.59843 | LR: 1.32e-05\n",
      "val loss: 0.6071\n",
      "Step 14800 | Loss: 0.62065 | LR: 1.27e-05\n",
      "Step 14825 | Loss: 0.56295 | LR: 1.21e-05\n",
      "Step 14850 | Loss: 0.56717 | LR: 1.15e-05\n",
      "Step 14875 | Loss: 0.60739 | LR: 1.10e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5985\n",
      "Step 14900 | Loss: 0.62090 | LR: 1.04e-05\n",
      "Step 14925 | Loss: 0.58379 | LR: 9.91e-06\n",
      "Step 14950 | Loss: 0.57736 | LR: 9.41e-06\n",
      "Step 14975 | Loss: 0.58759 | LR: 8.91e-06\n",
      "val loss: 0.6053\n",
      "Step 15000 | Loss: 0.61136 | LR: 8.43e-06\n",
      "Step 15025 | Loss: 0.60242 | LR: 7.96e-06\n",
      "Step 15050 | Loss: 0.59724 | LR: 7.50e-06\n",
      "Step 15075 | Loss: 0.59993 | LR: 7.06e-06\n",
      "val loss: 0.6035\n",
      "Step 15100 | Loss: 0.63800 | LR: 6.63e-06\n",
      "Step 15125 | Loss: 0.60246 | LR: 6.22e-06\n",
      "Step 15150 | Loss: 0.59588 | LR: 5.81e-06\n",
      "Step 15175 | Loss: 0.62244 | LR: 5.43e-06\n",
      "val loss: 0.6088\n",
      "Step 15200 | Loss: 0.61223 | LR: 5.05e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 15225 | Loss: 0.60146 | LR: 4.69e-06\n",
      "Step 15250 | Loss: 0.62344 | LR: 4.34e-06\n",
      "Step 15275 | Loss: 0.62370 | LR: 4.00e-06\n",
      "val loss: 0.6150\n",
      "Step 15300 | Loss: 0.61026 | LR: 3.68e-06\n",
      "Step 15325 | Loss: 0.64290 | LR: 3.37e-06\n",
      "Step 15350 | Loss: 0.61108 | LR: 3.08e-06\n",
      "Step 15375 | Loss: 0.62606 | LR: 2.80e-06\n",
      "val loss: 0.6031\n",
      "Step 15400 | Loss: 0.62874 | LR: 2.53e-06\n",
      "Step 15425 | Loss: 0.58749 | LR: 2.28e-06\n",
      "Step 15450 | Loss: 0.61256 | LR: 2.03e-06\n",
      "Step 15475 | Loss: 0.63014 | LR: 1.81e-06\n",
      "val loss: 0.6063\n",
      "Step 15500 | Loss: 0.65091 | LR: 1.59e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 15525 | Loss: 0.58389 | LR: 1.39e-06\n",
      "Step 15550 | Loss: 0.61142 | LR: 1.20e-06\n",
      "Step 15575 | Loss: 0.63486 | LR: 1.03e-06\n",
      "val loss: 0.5955\n",
      "Step 15600 | Loss: 0.62112 | LR: 8.71e-07\n",
      "Step 15625 | Loss: 0.59515 | LR: 7.25e-07\n",
      "Step 15650 | Loss: 0.65722 | LR: 5.92e-07\n",
      "Step 15675 | Loss: 0.62527 | LR: 4.73e-07\n",
      "val loss: 0.6105\n",
      "Step 15700 | Loss: 0.61140 | LR: 3.67e-07\n",
      "Step 15725 | Loss: 0.64319 | LR: 2.74e-07\n",
      "Step 15750 | Loss: 0.59934 | LR: 1.96e-07\n",
      "Step 15775 | Loss: 0.60340 | LR: 1.30e-07\n",
      "val loss: 0.5938\n",
      "Step 15800 | Loss: 0.58614 | LR: 7.86e-08\n",
      "Step 15825 | Loss: 0.59778 | LR: 4.04e-08\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 15850 | Loss: 0.58794 | LR: 1.58e-08\n",
      "Step 15875 | Loss: 0.61552 | LR: 4.69e-09\n",
      "val loss: 0.6122\n",
      "=== Epoch 5 Done. Avg Loss: 0.60926 ===\n",
      "Saved final checkpoint: linear_decoder_ckpt_15884_final.pt\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "val_lossi = []\n",
    "total_epoch_loss = 0\n",
    "\n",
    "decoder.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    if step % 100 == 0 or last_step:\n",
    "        biojepa.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 10\n",
    "            for i in range(val_loss_steps):\n",
    "                xc, xct, xt, xtt, p_idx, p_mod, p_mode = val_loader.next_batch()\n",
    "                p_feats = input_bank[p_idx]\n",
    "                B, N = xc.shape\n",
    "\n",
    "                action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "                z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "                target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "                z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "                pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "                real_delta = xt - xc\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_accum / val_loss_steps\n",
    "            val_lossi.append(avg_val_loss)\n",
    "            print(f'val loss: {avg_val_loss:.4f}')\n",
    "        decoder.train()\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0 and not last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    xc, xct, xt, xtt, p_idx, p_mod, p_mode = train_loader.next_batch()\n",
    "    p_feats = input_bank[p_idx]\n",
    "    B, N = xc.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "        action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "    real_delta = xt - xc\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f'Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0:\n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f'=== Epoch {(step + 1) // steps_per_epoch} Done. Avg Loss: {avg_loss:.5f} ===')\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "    if last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}_final.pt')\n",
    "        print(f'Saved final checkpoint: linear_decoder_ckpt_{step}_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-header",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loss-plot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(lossi, alpha=0.7)\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].set_ylabel('Train Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].plot(val_lossi, 'o-', color='orange')\n",
    "axes[1].set_xlabel('Validation Check (every 100 steps)')\n",
    "axes[1].set_ylabel('Val Loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Final train loss: 0.5749\n",
      "Final val loss: 0.6122\n",
      "Checkpoint saved: /Users/djemec/data/jepa/v0_5/checkpoints/linear_decoder_ckpt_15884_final.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*60)\n",
    "print(f'Final train loss: {lossi[-1]:.4f}')\n",
    "print(f'Final val loss: {val_lossi[-1]:.4f}')\n",
    "print(f'Checkpoint saved: {checkpoint_dir / f\"linear_decoder_ckpt_{max_steps-1}_final.pt\"}')\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920c7d10-570d-4fa2-8aa2-89f9e60a3d9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
