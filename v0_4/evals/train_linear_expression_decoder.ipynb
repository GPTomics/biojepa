{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Train Linear Expression Decoder\n",
    "\n",
    "Trains a linear probe decoder on frozen BioJEPA latent representations to predict expression deltas.\n",
    "\n",
    "The trained decoder is used by evaluation notebooks (eval_1, eval_2, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import biojepa_ac_v0_4 as model\n",
    "from bio_dataloader import TrainingLoader\n",
    "from linear_expression_decoder import BenchmarkDecoder, BenchmarkDecoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "n_genes = 5000\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "n_embd = 8\n",
    "pert_latent_dim = 320\n",
    "pert_mode_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_4')\n",
    "train_dir = data_dir / 'training'\n",
    "checkpoint_dir = data_dir / 'checkpoints'\n",
    "pert_dir = data_dir / 'pert_embd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Bank (DNA): torch.Size([1250, 1536])\n"
     ]
    }
   ],
   "source": [
    "input_bank = torch.from_numpy(np.load(pert_dir / 'input_embeddings_dna.npy')).float().to(DEVICE)\n",
    "print(f'Input Bank (DNA): {input_bank.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Load BioJEPA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "config = model.BioJepaConfig(\n",
    "    num_genes=n_genes,\n",
    "    n_layer=n_layers,\n",
    "    heads=n_heads,\n",
    "    embed_dim=n_embd,\n",
    "    n_pre_layer=n_layers,\n",
    "    pert_latent_dim=pert_latent_dim,\n",
    "    pert_mode_dim=pert_mode_dim\n",
    ")\n",
    "biojepa = model.BioJepa(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-checkpoint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_ckpt_31769_final.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "keys = biojepa.load_state_dict(checkpoint['model'])\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freeze-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "biojepa.freeze_encoders()\n",
    "biojepa.eval()\n",
    "for param in biojepa.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "data-loaders",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 11 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "found 2 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = TrainingLoader(batch_size=batch_size, split='train', data_dir=train_dir, device=DEVICE)\n",
    "val_loader = TrainingLoader(batch_size=batch_size, split='val', data_dir=train_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoder-header",
   "metadata": {},
   "source": [
    "## Initialize Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "init-decoder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder parameters: 9\n"
     ]
    }
   ],
   "source": [
    "decoder_config = BenchmarkDecoderConfig(embed_dim=n_embd)\n",
    "decoder = BenchmarkDecoder(decoder_config).to(DEVICE)\n",
    "print(f'Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 3177\n",
      "Total steps: 15885\n"
     ]
    }
   ],
   "source": [
    "lr_decoder = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "train_total_examples = 101682\n",
    "steps_per_epoch = train_total_examples // batch_size\n",
    "max_steps = epochs * steps_per_epoch\n",
    "\n",
    "print(f'Steps per epoch: {steps_per_epoch}')\n",
    "print(f'Total steps: {max_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-header",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "training-loop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1.8479\n",
      "Step 0 | Loss: 1.88126 | LR: 4.00e-05\n",
      "Step 25 | Loss: 1.92110 | LR: 4.25e-05\n",
      "Step 50 | Loss: 1.81810 | LR: 4.98e-05\n",
      "Step 75 | Loss: 1.83593 | LR: 6.16e-05\n",
      "val loss: 1.8015\n",
      "Step 100 | Loss: 1.82286 | LR: 7.79e-05\n",
      "Step 125 | Loss: 1.78325 | LR: 9.85e-05\n",
      "Step 150 | Loss: 1.85472 | LR: 1.23e-04\n",
      "Step 175 | Loss: 1.68756 | LR: 1.52e-04\n",
      "val loss: 1.7550\n",
      "Step 200 | Loss: 1.71301 | LR: 1.84e-04\n",
      "Step 225 | Loss: 1.65168 | LR: 2.20e-04\n",
      "Step 250 | Loss: 1.58125 | LR: 2.58e-04\n",
      "Step 275 | Loss: 1.64760 | LR: 2.99e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 1.5856\n",
      "Step 300 | Loss: 1.65168 | LR: 3.43e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 325 | Loss: 1.51634 | LR: 3.87e-04\n",
      "Step 350 | Loss: 1.50714 | LR: 4.34e-04\n",
      "Step 375 | Loss: 1.44486 | LR: 4.81e-04\n",
      "val loss: 1.4022\n",
      "Step 400 | Loss: 1.34753 | LR: 5.28e-04\n",
      "Step 425 | Loss: 1.41416 | LR: 5.76e-04\n",
      "Step 450 | Loss: 1.23077 | LR: 6.23e-04\n",
      "Step 475 | Loss: 1.29137 | LR: 6.68e-04\n",
      "val loss: 1.1845\n",
      "Step 500 | Loss: 1.23802 | LR: 7.13e-04\n",
      "Step 525 | Loss: 1.09357 | LR: 7.55e-04\n",
      "Step 550 | Loss: 1.08085 | LR: 7.96e-04\n",
      "Step 575 | Loss: 1.01227 | LR: 8.33e-04\n",
      "val loss: 0.9422\n",
      "Step 600 | Loss: 0.98839 | LR: 8.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 625 | Loss: 0.92242 | LR: 8.98e-04\n",
      "Step 650 | Loss: 0.83560 | LR: 9.26e-04\n",
      "Step 675 | Loss: 0.79993 | LR: 9.49e-04\n",
      "val loss: 0.7837\n",
      "Step 700 | Loss: 0.79780 | LR: 9.68e-04\n",
      "Step 725 | Loss: 0.77188 | LR: 9.83e-04\n",
      "Step 750 | Loss: 0.80257 | LR: 9.93e-04\n",
      "Step 775 | Loss: 0.75945 | LR: 9.99e-04\n",
      "val loss: 0.6848\n",
      "Step 800 | Loss: 0.67917 | LR: 1.00e-03\n",
      "Step 825 | Loss: 0.65181 | LR: 1.00e-03\n",
      "Step 850 | Loss: 0.64110 | LR: 1.00e-03\n",
      "Step 875 | Loss: 0.66717 | LR: 1.00e-03\n",
      "val loss: 0.6276\n",
      "Step 900 | Loss: 0.68428 | LR: 1.00e-03\n",
      "Step 925 | Loss: 0.65329 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 950 | Loss: 0.60166 | LR: 1.00e-03\n",
      "Step 975 | Loss: 0.59225 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "val loss: 0.5854\n",
      "Step 1000 | Loss: 0.58636 | LR: 1.00e-03\n",
      "Step 1025 | Loss: 0.57071 | LR: 9.99e-04\n",
      "Step 1050 | Loss: 0.60506 | LR: 9.99e-04\n",
      "Step 1075 | Loss: 0.56090 | LR: 9.99e-04\n",
      "val loss: 0.5586\n",
      "Step 1100 | Loss: 0.58875 | LR: 9.99e-04\n",
      "Step 1125 | Loss: 0.57037 | LR: 9.99e-04\n",
      "Step 1150 | Loss: 0.61235 | LR: 9.99e-04\n",
      "Step 1175 | Loss: 0.58668 | LR: 9.98e-04\n",
      "val loss: 0.5560\n",
      "Step 1200 | Loss: 0.56367 | LR: 9.98e-04\n",
      "Step 1225 | Loss: 0.56745 | LR: 9.98e-04\n",
      "Step 1250 | Loss: 0.56221 | LR: 9.98e-04\n",
      "Step 1275 | Loss: 0.51789 | LR: 9.97e-04\n",
      "val loss: 0.5394\n",
      "Step 1300 | Loss: 0.51908 | LR: 9.97e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 1325 | Loss: 0.51085 | LR: 9.97e-04\n",
      "Step 1350 | Loss: 0.51766 | LR: 9.97e-04\n",
      "Step 1375 | Loss: 0.51813 | LR: 9.96e-04\n",
      "val loss: 0.5399\n",
      "Step 1400 | Loss: 0.51056 | LR: 9.96e-04\n",
      "Step 1425 | Loss: 0.51561 | LR: 9.96e-04\n",
      "Step 1450 | Loss: 0.52424 | LR: 9.95e-04\n",
      "Step 1475 | Loss: 0.49577 | LR: 9.95e-04\n",
      "val loss: 0.5192\n",
      "Step 1500 | Loss: 0.53588 | LR: 9.95e-04\n",
      "Step 1525 | Loss: 0.53879 | LR: 9.94e-04\n",
      "Step 1550 | Loss: 0.53514 | LR: 9.94e-04\n",
      "Step 1575 | Loss: 0.53216 | LR: 9.93e-04\n",
      "val loss: 0.5180\n",
      "Step 1600 | Loss: 0.51382 | LR: 9.93e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 1625 | Loss: 0.54056 | LR: 9.93e-04\n",
      "Step 1650 | Loss: 0.52620 | LR: 9.92e-04\n",
      "Step 1675 | Loss: 0.54820 | LR: 9.92e-04\n",
      "val loss: 0.5157\n",
      "Step 1700 | Loss: 0.51332 | LR: 9.91e-04\n",
      "Step 1725 | Loss: 0.56138 | LR: 9.91e-04\n",
      "Step 1750 | Loss: 0.50702 | LR: 9.90e-04\n",
      "Step 1775 | Loss: 0.53245 | LR: 9.90e-04\n",
      "val loss: 0.5347\n",
      "Step 1800 | Loss: 0.52592 | LR: 9.89e-04\n",
      "Step 1825 | Loss: 0.51024 | LR: 9.88e-04\n",
      "Step 1850 | Loss: 0.52937 | LR: 9.88e-04\n",
      "Step 1875 | Loss: 0.53346 | LR: 9.87e-04\n",
      "val loss: 0.5133\n",
      "Step 1900 | Loss: 0.49016 | LR: 9.87e-04\n",
      "Step 1925 | Loss: 0.53402 | LR: 9.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 1950 | Loss: 0.51415 | LR: 9.86e-04\n",
      "Step 1975 | Loss: 0.51980 | LR: 9.85e-04\n",
      "val loss: 0.5126\n",
      "Step 2000 | Loss: 0.54769 | LR: 9.84e-04\n",
      "Step 2025 | Loss: 0.54018 | LR: 9.84e-04\n",
      "Step 2050 | Loss: 0.53338 | LR: 9.83e-04\n",
      "Step 2075 | Loss: 0.50002 | LR: 9.82e-04\n",
      "val loss: 0.5106\n",
      "Step 2100 | Loss: 0.55327 | LR: 9.82e-04\n",
      "Step 2125 | Loss: 0.53634 | LR: 9.81e-04\n",
      "Step 2150 | Loss: 0.49640 | LR: 9.80e-04\n",
      "Step 2175 | Loss: 0.53005 | LR: 9.79e-04\n",
      "val loss: 0.5200\n",
      "Step 2200 | Loss: 0.50786 | LR: 9.79e-04\n",
      "Step 2225 | Loss: 0.50284 | LR: 9.78e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 2250 | Loss: 0.55307 | LR: 9.77e-04\n",
      "Step 2275 | Loss: 0.52795 | LR: 9.76e-04\n",
      "val loss: 0.5230\n",
      "Step 2300 | Loss: 0.53066 | LR: 9.76e-04\n",
      "Step 2325 | Loss: 0.52138 | LR: 9.75e-04\n",
      "Step 2350 | Loss: 0.53169 | LR: 9.74e-04\n",
      "Step 2375 | Loss: 0.51578 | LR: 9.73e-04\n",
      "val loss: 0.5081\n",
      "Step 2400 | Loss: 0.55224 | LR: 9.72e-04\n",
      "Step 2425 | Loss: 0.54339 | LR: 9.71e-04\n",
      "Step 2450 | Loss: 0.50958 | LR: 9.71e-04\n",
      "Step 2475 | Loss: 0.52685 | LR: 9.70e-04\n",
      "val loss: 0.5137\n",
      "Step 2500 | Loss: 0.55480 | LR: 9.69e-04\n",
      "Step 2525 | Loss: 0.52483 | LR: 9.68e-04\n",
      "Step 2550 | Loss: 0.52638 | LR: 9.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 2575 | Loss: 0.52243 | LR: 9.66e-04\n",
      "val loss: 0.5262\n",
      "Step 2600 | Loss: 0.52421 | LR: 9.65e-04\n",
      "Step 2625 | Loss: 0.54621 | LR: 9.64e-04\n",
      "Step 2650 | Loss: 0.53791 | LR: 9.63e-04\n",
      "Step 2675 | Loss: 0.53741 | LR: 9.62e-04\n",
      "val loss: 0.5140\n",
      "Step 2700 | Loss: 0.54350 | LR: 9.61e-04\n",
      "Step 2725 | Loss: 0.53313 | LR: 9.60e-04\n",
      "Step 2750 | Loss: 0.52147 | LR: 9.59e-04\n",
      "Step 2775 | Loss: 0.52813 | LR: 9.58e-04\n",
      "val loss: 0.5109\n",
      "Step 2800 | Loss: 0.53501 | LR: 9.57e-04\n",
      "Step 2825 | Loss: 0.53988 | LR: 9.56e-04\n",
      "Step 2850 | Loss: 0.53599 | LR: 9.55e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 2875 | Loss: 0.49860 | LR: 9.54e-04\n",
      "val loss: 0.5107\n",
      "Step 2900 | Loss: 0.51522 | LR: 9.53e-04\n",
      "Step 2925 | Loss: 0.55590 | LR: 9.52e-04\n",
      "Step 2950 | Loss: 0.50452 | LR: 9.50e-04\n",
      "Step 2975 | Loss: 0.53902 | LR: 9.49e-04\n",
      "val loss: 0.5107\n",
      "Step 3000 | Loss: 0.47588 | LR: 9.48e-04\n",
      "Step 3025 | Loss: 0.53061 | LR: 9.47e-04\n",
      "Step 3050 | Loss: 0.52051 | LR: 9.46e-04\n",
      "Step 3075 | Loss: 0.50241 | LR: 9.45e-04\n",
      "val loss: 0.5126\n",
      "Step 3100 | Loss: 0.54026 | LR: 9.43e-04\n",
      "Step 3125 | Loss: 0.49354 | LR: 9.42e-04\n",
      "Step 3150 | Loss: 0.50848 | LR: 9.41e-04\n",
      "Step 3175 | Loss: 0.50393 | LR: 9.40e-04\n",
      "=== Epoch 1 Done. Avg Loss: 0.74135 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5102\n",
      "Step 3200 | Loss: 0.53143 | LR: 9.38e-04\n",
      "Step 3225 | Loss: 0.54015 | LR: 9.37e-04\n",
      "Step 3250 | Loss: 0.50592 | LR: 9.36e-04\n",
      "Step 3275 | Loss: 0.52469 | LR: 9.35e-04\n",
      "val loss: 0.5289\n",
      "Step 3300 | Loss: 0.54688 | LR: 9.33e-04\n",
      "Step 3325 | Loss: 0.50339 | LR: 9.32e-04\n",
      "Step 3350 | Loss: 0.53495 | LR: 9.31e-04\n",
      "Step 3375 | Loss: 0.52371 | LR: 9.29e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5146\n",
      "Step 3400 | Loss: 0.48030 | LR: 9.28e-04\n",
      "Step 3425 | Loss: 0.55385 | LR: 9.27e-04\n",
      "Step 3450 | Loss: 0.53071 | LR: 9.25e-04\n",
      "Step 3475 | Loss: 0.52544 | LR: 9.24e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5197\n",
      "Step 3500 | Loss: 0.52456 | LR: 9.23e-04\n",
      "Step 3525 | Loss: 0.50638 | LR: 9.21e-04\n",
      "Step 3550 | Loss: 0.52069 | LR: 9.20e-04\n",
      "Step 3575 | Loss: 0.52686 | LR: 9.18e-04\n",
      "val loss: 0.5170\n",
      "Step 3600 | Loss: 0.53484 | LR: 9.17e-04\n",
      "Step 3625 | Loss: 0.52601 | LR: 9.16e-04\n",
      "Step 3650 | Loss: 0.50939 | LR: 9.14e-04\n",
      "Step 3675 | Loss: 0.54589 | LR: 9.13e-04\n",
      "val loss: 0.5124\n",
      "Step 3700 | Loss: 0.50576 | LR: 9.11e-04\n",
      "Step 3725 | Loss: 0.50365 | LR: 9.10e-04\n",
      "Step 3750 | Loss: 0.54483 | LR: 9.08e-04\n",
      "Step 3775 | Loss: 0.51283 | LR: 9.07e-04\n",
      "val loss: 0.5176\n",
      "Step 3800 | Loss: 0.54446 | LR: 9.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 3825 | Loss: 0.52897 | LR: 9.04e-04\n",
      "Step 3850 | Loss: 0.52627 | LR: 9.02e-04\n",
      "Step 3875 | Loss: 0.52806 | LR: 9.01e-04\n",
      "val loss: 0.5161\n",
      "Step 3900 | Loss: 0.52961 | LR: 8.99e-04\n",
      "Step 3925 | Loss: 0.54197 | LR: 8.97e-04\n",
      "Step 3950 | Loss: 0.52530 | LR: 8.96e-04\n",
      "Step 3975 | Loss: 0.50833 | LR: 8.94e-04\n",
      "val loss: 0.5182\n",
      "Step 4000 | Loss: 0.50182 | LR: 8.93e-04\n",
      "Step 4025 | Loss: 0.48274 | LR: 8.91e-04\n",
      "Step 4050 | Loss: 0.51890 | LR: 8.89e-04\n",
      "Step 4075 | Loss: 0.52820 | LR: 8.88e-04\n",
      "val loss: 0.5190\n",
      "Step 4100 | Loss: 0.49003 | LR: 8.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 4125 | Loss: 0.49586 | LR: 8.84e-04\n",
      "Step 4150 | Loss: 0.50996 | LR: 8.83e-04\n",
      "Step 4175 | Loss: 0.52347 | LR: 8.81e-04\n",
      "val loss: 0.5162\n",
      "Step 4200 | Loss: 0.51788 | LR: 8.79e-04\n",
      "Step 4225 | Loss: 0.51460 | LR: 8.78e-04\n",
      "Step 4250 | Loss: 0.48082 | LR: 8.76e-04\n",
      "Step 4275 | Loss: 0.52791 | LR: 8.74e-04\n",
      "val loss: 0.5164\n",
      "Step 4300 | Loss: 0.54872 | LR: 8.73e-04\n",
      "Step 4325 | Loss: 0.50833 | LR: 8.71e-04\n",
      "Step 4350 | Loss: 0.50635 | LR: 8.69e-04\n",
      "Step 4375 | Loss: 0.53403 | LR: 8.67e-04\n",
      "val loss: 0.5148\n",
      "Step 4400 | Loss: 0.53862 | LR: 8.65e-04\n",
      "Step 4425 | Loss: 0.52156 | LR: 8.64e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 4450 | Loss: 0.48647 | LR: 8.62e-04\n",
      "Step 4475 | Loss: 0.53610 | LR: 8.60e-04\n",
      "val loss: 0.5189\n",
      "Step 4500 | Loss: 0.54240 | LR: 8.58e-04\n",
      "Step 4525 | Loss: 0.50389 | LR: 8.56e-04\n",
      "Step 4550 | Loss: 0.50191 | LR: 8.55e-04\n",
      "Step 4575 | Loss: 0.50956 | LR: 8.53e-04\n",
      "val loss: 0.5179\n",
      "Step 4600 | Loss: 0.51758 | LR: 8.51e-04\n",
      "Step 4625 | Loss: 0.50746 | LR: 8.49e-04\n",
      "Step 4650 | Loss: 0.51107 | LR: 8.47e-04\n",
      "Step 4675 | Loss: 0.52272 | LR: 8.45e-04\n",
      "val loss: 0.5059\n",
      "Step 4700 | Loss: 0.51819 | LR: 8.43e-04\n",
      "Step 4725 | Loss: 0.54074 | LR: 8.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 4750 | Loss: 0.51285 | LR: 8.40e-04\n",
      "Step 4775 | Loss: 0.50038 | LR: 8.38e-04\n",
      "val loss: 0.5060\n",
      "Step 4800 | Loss: 0.51612 | LR: 8.36e-04\n",
      "Step 4825 | Loss: 0.53326 | LR: 8.34e-04\n",
      "Step 4850 | Loss: 0.51900 | LR: 8.32e-04\n",
      "Step 4875 | Loss: 0.51154 | LR: 8.30e-04\n",
      "val loss: 0.5224\n",
      "Step 4900 | Loss: 0.49310 | LR: 8.28e-04\n",
      "Step 4925 | Loss: 0.50500 | LR: 8.26e-04\n",
      "Step 4950 | Loss: 0.52135 | LR: 8.24e-04\n",
      "Step 4975 | Loss: 0.54979 | LR: 8.22e-04\n",
      "val loss: 0.5131\n",
      "Step 5000 | Loss: 0.52320 | LR: 8.20e-04\n",
      "Step 5025 | Loss: 0.50067 | LR: 8.18e-04\n",
      "Step 5050 | Loss: 0.50176 | LR: 8.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 5075 | Loss: 0.50203 | LR: 8.14e-04\n",
      "val loss: 0.5173\n",
      "Step 5100 | Loss: 0.52831 | LR: 8.12e-04\n",
      "Step 5125 | Loss: 0.51123 | LR: 8.10e-04\n",
      "Step 5150 | Loss: 0.52283 | LR: 8.08e-04\n",
      "Step 5175 | Loss: 0.49684 | LR: 8.06e-04\n",
      "val loss: 0.5154\n",
      "Step 5200 | Loss: 0.50638 | LR: 8.04e-04\n",
      "Step 5225 | Loss: 0.51052 | LR: 8.02e-04\n",
      "Step 5250 | Loss: 0.51858 | LR: 8.00e-04\n",
      "Step 5275 | Loss: 0.49436 | LR: 7.98e-04\n",
      "val loss: 0.5189\n",
      "Step 5300 | Loss: 0.50139 | LR: 7.96e-04\n",
      "Step 5325 | Loss: 0.53390 | LR: 7.93e-04\n",
      "Step 5350 | Loss: 0.52617 | LR: 7.91e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 5375 | Loss: 0.52901 | LR: 7.89e-04\n",
      "val loss: 0.5084\n",
      "Step 5400 | Loss: 0.49521 | LR: 7.87e-04\n",
      "Step 5425 | Loss: 0.53065 | LR: 7.85e-04\n",
      "Step 5450 | Loss: 0.47702 | LR: 7.83e-04\n",
      "Step 5475 | Loss: 0.48566 | LR: 7.81e-04\n",
      "val loss: 0.5207\n",
      "Step 5500 | Loss: 0.52943 | LR: 7.78e-04\n",
      "Step 5525 | Loss: 0.52355 | LR: 7.76e-04\n",
      "Step 5550 | Loss: 0.50817 | LR: 7.74e-04\n",
      "Step 5575 | Loss: 0.50822 | LR: 7.72e-04\n",
      "val loss: 0.5195\n",
      "Step 5600 | Loss: 0.50724 | LR: 7.70e-04\n",
      "Step 5625 | Loss: 0.52434 | LR: 7.68e-04\n",
      "Step 5650 | Loss: 0.51782 | LR: 7.65e-04\n",
      "Step 5675 | Loss: 0.50981 | LR: 7.63e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "val loss: 0.5145\n",
      "Step 5700 | Loss: 0.52491 | LR: 7.61e-04\n",
      "Step 5725 | Loss: 0.51730 | LR: 7.59e-04\n",
      "Step 5750 | Loss: 0.50805 | LR: 7.57e-04\n",
      "Step 5775 | Loss: 0.51751 | LR: 7.54e-04\n",
      "val loss: 0.5163\n",
      "Step 5800 | Loss: 0.50899 | LR: 7.52e-04\n",
      "Step 5825 | Loss: 0.53759 | LR: 7.50e-04\n",
      "Step 5850 | Loss: 0.54136 | LR: 7.48e-04\n",
      "Step 5875 | Loss: 0.48698 | LR: 7.45e-04\n",
      "val loss: 0.5187\n",
      "Step 5900 | Loss: 0.51551 | LR: 7.43e-04\n",
      "Step 5925 | Loss: 0.52278 | LR: 7.41e-04\n",
      "Step 5950 | Loss: 0.52955 | LR: 7.38e-04\n",
      "Step 5975 | Loss: 0.52094 | LR: 7.36e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.5244\n",
      "Step 6000 | Loss: 0.52110 | LR: 7.34e-04\n",
      "Step 6025 | Loss: 0.50751 | LR: 7.32e-04\n",
      "Step 6050 | Loss: 0.52275 | LR: 7.29e-04\n",
      "Step 6075 | Loss: 0.52267 | LR: 7.27e-04\n",
      "val loss: 0.5247\n",
      "Step 6100 | Loss: 0.51890 | LR: 7.25e-04\n",
      "Step 6125 | Loss: 0.52135 | LR: 7.22e-04\n",
      "Step 6150 | Loss: 0.53170 | LR: 7.20e-04\n",
      "Step 6175 | Loss: 0.52439 | LR: 7.18e-04\n",
      "val loss: 0.5123\n",
      "Step 6200 | Loss: 0.51882 | LR: 7.15e-04\n",
      "Step 6225 | Loss: 0.54001 | LR: 7.13e-04\n",
      "Step 6250 | Loss: 0.49747 | LR: 7.11e-04\n",
      "Step 6275 | Loss: 0.50586 | LR: 7.08e-04\n",
      "val loss: 0.5166\n",
      "Step 6300 | Loss: 0.51044 | LR: 7.06e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6325 | Loss: 0.53831 | LR: 7.03e-04\n",
      "Step 6350 | Loss: 0.50331 | LR: 7.01e-04\n",
      "=== Epoch 2 Done. Avg Loss: 0.52034 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 6375 | Loss: 0.55139 | LR: 6.99e-04\n",
      "val loss: 0.5159\n",
      "Step 6400 | Loss: 0.49856 | LR: 6.96e-04\n",
      "Step 6425 | Loss: 0.52258 | LR: 6.94e-04\n",
      "Step 6450 | Loss: 0.51282 | LR: 6.91e-04\n",
      "Step 6475 | Loss: 0.53282 | LR: 6.89e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5075\n",
      "Step 6500 | Loss: 0.52578 | LR: 6.87e-04\n",
      "Step 6525 | Loss: 0.54373 | LR: 6.84e-04\n",
      "Step 6550 | Loss: 0.51723 | LR: 6.82e-04\n",
      "Step 6575 | Loss: 0.52370 | LR: 6.79e-04\n",
      "val loss: 0.5181\n",
      "Step 6600 | Loss: 0.49068 | LR: 6.77e-04\n",
      "Step 6625 | Loss: 0.53502 | LR: 6.75e-04\n",
      "Step 6650 | Loss: 0.53031 | LR: 6.72e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6675 | Loss: 0.50539 | LR: 6.70e-04\n",
      "val loss: 0.5157\n",
      "Step 6700 | Loss: 0.52110 | LR: 6.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 6725 | Loss: 0.50591 | LR: 6.65e-04\n",
      "Step 6750 | Loss: 0.53446 | LR: 6.62e-04\n",
      "Step 6775 | Loss: 0.54698 | LR: 6.60e-04\n",
      "val loss: 0.5197\n",
      "Step 6800 | Loss: 0.51746 | LR: 6.57e-04\n",
      "Step 6825 | Loss: 0.51790 | LR: 6.55e-04\n",
      "Step 6850 | Loss: 0.53619 | LR: 6.52e-04\n",
      "Step 6875 | Loss: 0.52651 | LR: 6.50e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5171\n",
      "Step 6900 | Loss: 0.51073 | LR: 6.47e-04\n",
      "Step 6925 | Loss: 0.52411 | LR: 6.45e-04\n",
      "Step 6950 | Loss: 0.54907 | LR: 6.42e-04\n",
      "Step 6975 | Loss: 0.50659 | LR: 6.40e-04\n",
      "val loss: 0.5158\n",
      "Step 7000 | Loss: 0.52927 | LR: 6.37e-04\n",
      "Step 7025 | Loss: 0.51306 | LR: 6.35e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 7050 | Loss: 0.52184 | LR: 6.32e-04\n",
      "Step 7075 | Loss: 0.53164 | LR: 6.30e-04\n",
      "val loss: 0.5151\n",
      "Step 7100 | Loss: 0.51196 | LR: 6.27e-04\n",
      "Step 7125 | Loss: 0.51390 | LR: 6.25e-04\n",
      "Step 7150 | Loss: 0.54600 | LR: 6.22e-04\n",
      "Step 7175 | Loss: 0.53002 | LR: 6.20e-04\n",
      "val loss: 0.5180\n",
      "Step 7200 | Loss: 0.53905 | LR: 6.17e-04\n",
      "Step 7225 | Loss: 0.56466 | LR: 6.15e-04\n",
      "Step 7250 | Loss: 0.52219 | LR: 6.12e-04\n",
      "Step 7275 | Loss: 0.54918 | LR: 6.10e-04\n",
      "val loss: 0.5109\n",
      "Step 7300 | Loss: 0.51160 | LR: 6.07e-04\n",
      "Step 7325 | Loss: 0.50621 | LR: 6.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 7350 | Loss: 0.50475 | LR: 6.02e-04\n",
      "Step 7375 | Loss: 0.50545 | LR: 6.00e-04\n",
      "val loss: 0.5198\n",
      "Step 7400 | Loss: 0.51997 | LR: 5.97e-04\n",
      "Step 7425 | Loss: 0.52188 | LR: 5.94e-04\n",
      "Step 7450 | Loss: 0.49633 | LR: 5.92e-04\n",
      "Step 7475 | Loss: 0.49464 | LR: 5.89e-04\n",
      "val loss: 0.5155\n",
      "Step 7500 | Loss: 0.52900 | LR: 5.87e-04\n",
      "Step 7525 | Loss: 0.48908 | LR: 5.84e-04\n",
      "Step 7550 | Loss: 0.49546 | LR: 5.82e-04\n",
      "Step 7575 | Loss: 0.49243 | LR: 5.79e-04\n",
      "val loss: 0.5172\n",
      "Step 7600 | Loss: 0.52744 | LR: 5.76e-04\n",
      "Step 7625 | Loss: 0.53537 | LR: 5.74e-04\n",
      "Step 7650 | Loss: 0.53019 | LR: 5.71e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 7675 | Loss: 0.50478 | LR: 5.69e-04\n",
      "val loss: 0.5139\n",
      "Step 7700 | Loss: 0.50139 | LR: 5.66e-04\n",
      "Step 7725 | Loss: 0.53536 | LR: 5.64e-04\n",
      "Step 7750 | Loss: 0.52231 | LR: 5.61e-04\n",
      "Step 7775 | Loss: 0.54044 | LR: 5.58e-04\n",
      "val loss: 0.5138\n",
      "Step 7800 | Loss: 0.54157 | LR: 5.56e-04\n",
      "Step 7825 | Loss: 0.53164 | LR: 5.53e-04\n",
      "Step 7850 | Loss: 0.51298 | LR: 5.51e-04\n",
      "Step 7875 | Loss: 0.52116 | LR: 5.48e-04\n",
      "val loss: 0.5144\n",
      "Step 7900 | Loss: 0.52589 | LR: 5.45e-04\n",
      "Step 7925 | Loss: 0.53533 | LR: 5.43e-04\n",
      "Step 7950 | Loss: 0.55146 | LR: 5.40e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 7975 | Loss: 0.51373 | LR: 5.38e-04\n",
      "val loss: 0.5201\n",
      "Step 8000 | Loss: 0.50437 | LR: 5.35e-04\n",
      "Step 8025 | Loss: 0.53721 | LR: 5.33e-04\n",
      "Step 8050 | Loss: 0.50734 | LR: 5.30e-04\n",
      "Step 8075 | Loss: 0.54156 | LR: 5.27e-04\n",
      "val loss: 0.5229\n",
      "Step 8100 | Loss: 0.51174 | LR: 5.25e-04\n",
      "Step 8125 | Loss: 0.52151 | LR: 5.22e-04\n",
      "Step 8150 | Loss: 0.49072 | LR: 5.20e-04\n",
      "Step 8175 | Loss: 0.51836 | LR: 5.17e-04\n",
      "val loss: 0.5144\n",
      "Step 8200 | Loss: 0.54254 | LR: 5.14e-04\n",
      "Step 8225 | Loss: 0.56823 | LR: 5.12e-04\n",
      "Step 8250 | Loss: 0.54174 | LR: 5.09e-04\n",
      "Step 8275 | Loss: 0.47790 | LR: 5.07e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.5299\n",
      "Step 8300 | Loss: 0.53855 | LR: 5.04e-04\n",
      "Step 8325 | Loss: 0.51702 | LR: 5.01e-04\n",
      "Step 8350 | Loss: 0.53295 | LR: 4.99e-04\n",
      "Step 8375 | Loss: 0.50569 | LR: 4.96e-04\n",
      "val loss: 0.5223\n",
      "Step 8400 | Loss: 0.48989 | LR: 4.94e-04\n",
      "Step 8425 | Loss: 0.50639 | LR: 4.91e-04\n",
      "Step 8450 | Loss: 0.53545 | LR: 4.88e-04\n",
      "Step 8475 | Loss: 0.51182 | LR: 4.86e-04\n",
      "val loss: 0.5198\n",
      "Step 8500 | Loss: 0.54226 | LR: 4.83e-04\n",
      "Step 8525 | Loss: 0.54020 | LR: 4.81e-04\n",
      "Step 8550 | Loss: 0.50128 | LR: 4.78e-04\n",
      "Step 8575 | Loss: 0.52730 | LR: 4.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "val loss: 0.5161\n",
      "Step 8600 | Loss: 0.50411 | LR: 4.73e-04\n",
      "Step 8625 | Loss: 0.52027 | LR: 4.70e-04\n",
      "Step 8650 | Loss: 0.51579 | LR: 4.68e-04\n",
      "Step 8675 | Loss: 0.50252 | LR: 4.65e-04\n",
      "val loss: 0.5182\n",
      "Step 8700 | Loss: 0.53592 | LR: 4.62e-04\n",
      "Step 8725 | Loss: 0.53216 | LR: 4.60e-04\n",
      "Step 8750 | Loss: 0.51642 | LR: 4.57e-04\n",
      "Step 8775 | Loss: 0.51746 | LR: 4.55e-04\n",
      "val loss: 0.5106\n",
      "Step 8800 | Loss: 0.47176 | LR: 4.52e-04\n",
      "Step 8825 | Loss: 0.55058 | LR: 4.49e-04\n",
      "Step 8850 | Loss: 0.50863 | LR: 4.47e-04\n",
      "Step 8875 | Loss: 0.52045 | LR: 4.44e-04\n",
      "val loss: 0.5074\n",
      "Step 8900 | Loss: 0.52288 | LR: 4.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 8925 | Loss: 0.50284 | LR: 4.39e-04\n",
      "Step 8950 | Loss: 0.53012 | LR: 4.36e-04\n",
      "Step 8975 | Loss: 0.51085 | LR: 4.34e-04\n",
      "val loss: 0.5135\n",
      "Step 9000 | Loss: 0.51386 | LR: 4.31e-04\n",
      "Step 9025 | Loss: 0.51361 | LR: 4.29e-04\n",
      "Step 9050 | Loss: 0.55076 | LR: 4.26e-04\n",
      "Step 9075 | Loss: 0.50843 | LR: 4.24e-04\n",
      "val loss: 0.5136\n",
      "Step 9100 | Loss: 0.53505 | LR: 4.21e-04\n",
      "Step 9125 | Loss: 0.50345 | LR: 4.18e-04\n",
      "Step 9150 | Loss: 0.50604 | LR: 4.16e-04\n",
      "Step 9175 | Loss: 0.52084 | LR: 4.13e-04\n",
      "val loss: 0.5237\n",
      "Step 9200 | Loss: 0.51933 | LR: 4.11e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 9225 | Loss: 0.51956 | LR: 4.08e-04\n",
      "Step 9250 | Loss: 0.54877 | LR: 4.06e-04\n",
      "Step 9275 | Loss: 0.50833 | LR: 4.03e-04\n",
      "val loss: 0.5102\n",
      "Step 9300 | Loss: 0.51131 | LR: 4.00e-04\n",
      "Step 9325 | Loss: 0.53579 | LR: 3.98e-04\n",
      "Step 9350 | Loss: 0.54976 | LR: 3.95e-04\n",
      "Step 9375 | Loss: 0.51468 | LR: 3.93e-04\n",
      "val loss: 0.5149\n",
      "Step 9400 | Loss: 0.50543 | LR: 3.90e-04\n",
      "Step 9425 | Loss: 0.51886 | LR: 3.88e-04\n",
      "Step 9450 | Loss: 0.50653 | LR: 3.85e-04\n",
      "Step 9475 | Loss: 0.49721 | LR: 3.83e-04\n",
      "val loss: 0.5140\n",
      "Step 9500 | Loss: 0.53568 | LR: 3.80e-04\n",
      "Step 9525 | Loss: 0.51525 | LR: 3.78e-04\n",
      "=== Epoch 3 Done. Avg Loss: 0.52033 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 9550 | Loss: 0.48757 | LR: 3.75e-04\n",
      "Step 9575 | Loss: 0.51915 | LR: 3.73e-04\n",
      "val loss: 0.5185\n",
      "Step 9600 | Loss: 0.52502 | LR: 3.70e-04\n",
      "Step 9625 | Loss: 0.51115 | LR: 3.68e-04\n",
      "Step 9650 | Loss: 0.51060 | LR: 3.65e-04\n",
      "Step 9675 | Loss: 0.51621 | LR: 3.63e-04\n",
      "val loss: 0.5192\n",
      "Step 9700 | Loss: 0.51793 | LR: 3.60e-04\n",
      "Step 9725 | Loss: 0.53343 | LR: 3.58e-04\n",
      "Step 9750 | Loss: 0.50156 | LR: 3.55e-04\n",
      "Step 9775 | Loss: 0.51994 | LR: 3.53e-04\n",
      "val loss: 0.5136\n",
      "Step 9800 | Loss: 0.52156 | LR: 3.50e-04\n",
      "Step 9825 | Loss: 0.51652 | LR: 3.48e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 9850 | Loss: 0.55670 | LR: 3.45e-04\n",
      "Step 9875 | Loss: 0.52065 | LR: 3.43e-04\n",
      "val loss: 0.5128\n",
      "Step 9900 | Loss: 0.51732 | LR: 3.40e-04\n",
      "Step 9925 | Loss: 0.51074 | LR: 3.38e-04\n",
      "Step 9950 | Loss: 0.51732 | LR: 3.35e-04\n",
      "Step 9975 | Loss: 0.51090 | LR: 3.33e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5162\n",
      "Step 10000 | Loss: 0.53954 | LR: 3.30e-04\n",
      "Step 10025 | Loss: 0.52859 | LR: 3.28e-04\n",
      "Step 10050 | Loss: 0.50210 | LR: 3.26e-04\n",
      "Step 10075 | Loss: 0.52021 | LR: 3.23e-04\n",
      "val loss: 0.5168\n",
      "Step 10100 | Loss: 0.54714 | LR: 3.21e-04\n",
      "Step 10125 | Loss: 0.50323 | LR: 3.18e-04\n",
      "Step 10150 | Loss: 0.53282 | LR: 3.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 10175 | Loss: 0.53253 | LR: 3.13e-04\n",
      "val loss: 0.5155\n",
      "Step 10200 | Loss: 0.48835 | LR: 3.11e-04\n",
      "Step 10225 | Loss: 0.54718 | LR: 3.09e-04\n",
      "Step 10250 | Loss: 0.52421 | LR: 3.06e-04\n",
      "Step 10275 | Loss: 0.52872 | LR: 3.04e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5138\n",
      "Step 10300 | Loss: 0.53073 | LR: 3.01e-04\n",
      "Step 10325 | Loss: 0.53257 | LR: 2.99e-04\n",
      "Step 10350 | Loss: 0.55199 | LR: 2.97e-04\n",
      "Step 10375 | Loss: 0.50031 | LR: 2.94e-04\n",
      "val loss: 0.5179\n",
      "Step 10400 | Loss: 0.52854 | LR: 2.92e-04\n",
      "Step 10425 | Loss: 0.52910 | LR: 2.90e-04\n",
      "Step 10450 | Loss: 0.52913 | LR: 2.87e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 10475 | Loss: 0.49307 | LR: 2.85e-04\n",
      "val loss: 0.5151\n",
      "Step 10500 | Loss: 0.52283 | LR: 2.82e-04\n",
      "Step 10525 | Loss: 0.49326 | LR: 2.80e-04\n",
      "Step 10550 | Loss: 0.52938 | LR: 2.78e-04\n",
      "Step 10575 | Loss: 0.54838 | LR: 2.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5223\n",
      "Step 10600 | Loss: 0.51697 | LR: 2.73e-04\n",
      "Step 10625 | Loss: 0.50671 | LR: 2.71e-04\n",
      "Step 10650 | Loss: 0.50345 | LR: 2.68e-04\n",
      "Step 10675 | Loss: 0.54236 | LR: 2.66e-04\n",
      "val loss: 0.5207\n",
      "Step 10700 | Loss: 0.52571 | LR: 2.64e-04\n",
      "Step 10725 | Loss: 0.51392 | LR: 2.62e-04\n",
      "Step 10750 | Loss: 0.52708 | LR: 2.59e-04\n",
      "Step 10775 | Loss: 0.52824 | LR: 2.57e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "val loss: 0.5193\n",
      "Step 10800 | Loss: 0.52292 | LR: 2.55e-04\n",
      "Step 10825 | Loss: 0.55674 | LR: 2.53e-04\n",
      "Step 10850 | Loss: 0.51297 | LR: 2.50e-04\n",
      "Step 10875 | Loss: 0.50712 | LR: 2.48e-04\n",
      "val loss: 0.5184\n",
      "Step 10900 | Loss: 0.53363 | LR: 2.46e-04\n",
      "Step 10925 | Loss: 0.50034 | LR: 2.44e-04\n",
      "Step 10950 | Loss: 0.51676 | LR: 2.41e-04\n",
      "Step 10975 | Loss: 0.51152 | LR: 2.39e-04\n",
      "val loss: 0.5184\n",
      "Step 11000 | Loss: 0.51295 | LR: 2.37e-04\n",
      "Step 11025 | Loss: 0.54096 | LR: 2.35e-04\n",
      "Step 11050 | Loss: 0.51572 | LR: 2.32e-04\n",
      "Step 11075 | Loss: 0.50261 | LR: 2.30e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "val loss: 0.5219\n",
      "Step 11100 | Loss: 0.51335 | LR: 2.28e-04\n",
      "Step 11125 | Loss: 0.51714 | LR: 2.26e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 11150 | Loss: 0.53203 | LR: 2.24e-04\n",
      "Step 11175 | Loss: 0.53459 | LR: 2.22e-04\n",
      "val loss: 0.5146\n",
      "Step 11200 | Loss: 0.49444 | LR: 2.19e-04\n",
      "Step 11225 | Loss: 0.53898 | LR: 2.17e-04\n",
      "Step 11250 | Loss: 0.50986 | LR: 2.15e-04\n",
      "Step 11275 | Loss: 0.51443 | LR: 2.13e-04\n",
      "val loss: 0.5129\n",
      "Step 11300 | Loss: 0.53301 | LR: 2.11e-04\n",
      "Step 11325 | Loss: 0.51013 | LR: 2.09e-04\n",
      "Step 11350 | Loss: 0.51464 | LR: 2.07e-04\n",
      "Step 11375 | Loss: 0.53810 | LR: 2.04e-04\n",
      "val loss: 0.5177\n",
      "Step 11400 | Loss: 0.50626 | LR: 2.02e-04\n",
      "Step 11425 | Loss: 0.50874 | LR: 2.00e-04\n",
      "Step 11450 | Loss: 0.51670 | LR: 1.98e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 11475 | Loss: 0.50573 | LR: 1.96e-04\n",
      "val loss: 0.5128\n",
      "Step 11500 | Loss: 0.51472 | LR: 1.94e-04\n",
      "Step 11525 | Loss: 0.51433 | LR: 1.92e-04\n",
      "Step 11550 | Loss: 0.48136 | LR: 1.90e-04\n",
      "Step 11575 | Loss: 0.51839 | LR: 1.88e-04\n",
      "val loss: 0.5131\n",
      "Step 11600 | Loss: 0.52558 | LR: 1.86e-04\n",
      "Step 11625 | Loss: 0.48771 | LR: 1.84e-04\n",
      "Step 11650 | Loss: 0.50146 | LR: 1.82e-04\n",
      "Step 11675 | Loss: 0.52429 | LR: 1.80e-04\n",
      "val loss: 0.5126\n",
      "Step 11700 | Loss: 0.51528 | LR: 1.78e-04\n",
      "Step 11725 | Loss: 0.52728 | LR: 1.76e-04\n",
      "Step 11750 | Loss: 0.51711 | LR: 1.74e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 11775 | Loss: 0.52984 | LR: 1.72e-04\n",
      "val loss: 0.5160\n",
      "Step 11800 | Loss: 0.51162 | LR: 1.70e-04\n",
      "Step 11825 | Loss: 0.54292 | LR: 1.68e-04\n",
      "Step 11850 | Loss: 0.53872 | LR: 1.66e-04\n",
      "Step 11875 | Loss: 0.52983 | LR: 1.64e-04\n",
      "val loss: 0.5104\n",
      "Step 11900 | Loss: 0.52848 | LR: 1.62e-04\n",
      "Step 11925 | Loss: 0.51544 | LR: 1.60e-04\n",
      "Step 11950 | Loss: 0.51806 | LR: 1.58e-04\n",
      "Step 11975 | Loss: 0.49157 | LR: 1.57e-04\n",
      "val loss: 0.5199\n",
      "Step 12000 | Loss: 0.49955 | LR: 1.55e-04\n",
      "Step 12025 | Loss: 0.52354 | LR: 1.53e-04\n",
      "Step 12050 | Loss: 0.51962 | LR: 1.51e-04\n",
      "Step 12075 | Loss: 0.54294 | LR: 1.49e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5118\n",
      "Step 12100 | Loss: 0.51350 | LR: 1.47e-04\n",
      "Step 12125 | Loss: 0.51278 | LR: 1.45e-04\n",
      "Step 12150 | Loss: 0.50450 | LR: 1.44e-04\n",
      "Step 12175 | Loss: 0.50573 | LR: 1.42e-04\n",
      "val loss: 0.5082\n",
      "Step 12200 | Loss: 0.52192 | LR: 1.40e-04\n",
      "Step 12225 | Loss: 0.52267 | LR: 1.38e-04\n",
      "Step 12250 | Loss: 0.51953 | LR: 1.36e-04\n",
      "Step 12275 | Loss: 0.52018 | LR: 1.35e-04\n",
      "val loss: 0.5164\n",
      "Step 12300 | Loss: 0.56025 | LR: 1.33e-04\n",
      "Step 12325 | Loss: 0.52854 | LR: 1.31e-04\n",
      "Step 12350 | Loss: 0.49688 | LR: 1.29e-04\n",
      "Step 12375 | Loss: 0.53384 | LR: 1.28e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5173\n",
      "Step 12400 | Loss: 0.52590 | LR: 1.26e-04\n",
      "Step 12425 | Loss: 0.51945 | LR: 1.24e-04\n",
      "Step 12450 | Loss: 0.51182 | LR: 1.22e-04\n",
      "Step 12475 | Loss: 0.51538 | LR: 1.21e-04\n",
      "val loss: 0.5178\n",
      "Step 12500 | Loss: 0.53399 | LR: 1.19e-04\n",
      "Step 12525 | Loss: 0.49883 | LR: 1.17e-04\n",
      "Step 12550 | Loss: 0.53100 | LR: 1.16e-04\n",
      "Step 12575 | Loss: 0.54379 | LR: 1.14e-04\n",
      "val loss: 0.5192\n",
      "Step 12600 | Loss: 0.53003 | LR: 1.12e-04\n",
      "Step 12625 | Loss: 0.54107 | LR: 1.11e-04\n",
      "Step 12650 | Loss: 0.51169 | LR: 1.09e-04\n",
      "Step 12675 | Loss: 0.54000 | LR: 1.07e-04\n",
      "val loss: 0.5177\n",
      "Step 12700 | Loss: 0.51495 | LR: 1.06e-04\n",
      "=== Epoch 4 Done. Avg Loss: 0.52031 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 12725 | Loss: 0.54247 | LR: 1.04e-04\n",
      "Step 12750 | Loss: 0.51345 | LR: 1.03e-04\n",
      "Step 12775 | Loss: 0.52322 | LR: 1.01e-04\n",
      "val loss: 0.5239\n",
      "Step 12800 | Loss: 0.50462 | LR: 9.95e-05\n",
      "Step 12825 | Loss: 0.55130 | LR: 9.79e-05\n",
      "Step 12850 | Loss: 0.53054 | LR: 9.64e-05\n",
      "Step 12875 | Loss: 0.51188 | LR: 9.49e-05\n",
      "val loss: 0.5196\n",
      "Step 12900 | Loss: 0.52321 | LR: 9.34e-05\n",
      "Step 12925 | Loss: 0.53542 | LR: 9.18e-05\n",
      "Step 12950 | Loss: 0.51485 | LR: 9.03e-05\n",
      "Step 12975 | Loss: 0.54132 | LR: 8.89e-05\n",
      "val loss: 0.5206\n",
      "Step 13000 | Loss: 0.49910 | LR: 8.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 13025 | Loss: 0.50552 | LR: 8.59e-05\n",
      "Step 13050 | Loss: 0.51098 | LR: 8.45e-05\n",
      "Step 13075 | Loss: 0.50355 | LR: 8.30e-05\n",
      "val loss: 0.5157\n",
      "Step 13100 | Loss: 0.54489 | LR: 8.16e-05\n",
      "Step 13125 | Loss: 0.52058 | LR: 8.02e-05\n",
      "Step 13150 | Loss: 0.49033 | LR: 7.88e-05\n",
      "Step 13175 | Loss: 0.52752 | LR: 7.74e-05\n",
      "val loss: 0.5155\n",
      "Step 13200 | Loss: 0.52510 | LR: 7.60e-05\n",
      "Step 13225 | Loss: 0.49879 | LR: 7.46e-05\n",
      "Step 13250 | Loss: 0.51774 | LR: 7.33e-05\n",
      "Step 13275 | Loss: 0.53128 | LR: 7.19e-05\n",
      "val loss: 0.5141\n",
      "Step 13300 | Loss: 0.53346 | LR: 7.06e-05\n",
      "Step 13325 | Loss: 0.52382 | LR: 6.92e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 13350 | Loss: 0.50632 | LR: 6.79e-05\n",
      "Step 13375 | Loss: 0.55694 | LR: 6.66e-05\n",
      "val loss: 0.5148\n",
      "Step 13400 | Loss: 0.53222 | LR: 6.53e-05\n",
      "Step 13425 | Loss: 0.51375 | LR: 6.40e-05\n",
      "Step 13450 | Loss: 0.51934 | LR: 6.28e-05\n",
      "Step 13475 | Loss: 0.54870 | LR: 6.15e-05\n",
      "val loss: 0.5081\n",
      "Step 13500 | Loss: 0.50674 | LR: 6.03e-05\n",
      "Step 13525 | Loss: 0.51515 | LR: 5.90e-05\n",
      "Step 13550 | Loss: 0.50869 | LR: 5.78e-05\n",
      "Step 13575 | Loss: 0.50722 | LR: 5.66e-05\n",
      "val loss: 0.5157\n",
      "Step 13600 | Loss: 0.52050 | LR: 5.54e-05\n",
      "Step 13625 | Loss: 0.53222 | LR: 5.42e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 13650 | Loss: 0.53446 | LR: 5.31e-05\n",
      "Step 13675 | Loss: 0.51351 | LR: 5.19e-05\n",
      "val loss: 0.5151\n",
      "Step 13700 | Loss: 0.56251 | LR: 5.08e-05\n",
      "Step 13725 | Loss: 0.53000 | LR: 4.96e-05\n",
      "Step 13750 | Loss: 0.53808 | LR: 4.85e-05\n",
      "Step 13775 | Loss: 0.53600 | LR: 4.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5229\n",
      "Step 13800 | Loss: 0.52740 | LR: 4.63e-05\n",
      "Step 13825 | Loss: 0.50615 | LR: 4.52e-05\n",
      "Step 13850 | Loss: 0.50517 | LR: 4.41e-05\n",
      "Step 13875 | Loss: 0.52116 | LR: 4.31e-05\n",
      "val loss: 0.5124\n",
      "Step 13900 | Loss: 0.49576 | LR: 4.20e-05\n",
      "Step 13925 | Loss: 0.53052 | LR: 4.10e-05\n",
      "Step 13950 | Loss: 0.48431 | LR: 3.99e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 13975 | Loss: 0.52512 | LR: 3.89e-05\n",
      "val loss: 0.5163\n",
      "Step 14000 | Loss: 0.51714 | LR: 3.79e-05\n",
      "Step 14025 | Loss: 0.51864 | LR: 3.69e-05\n",
      "Step 14050 | Loss: 0.50659 | LR: 3.60e-05\n",
      "Step 14075 | Loss: 0.49886 | LR: 3.50e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5235\n",
      "Step 14100 | Loss: 0.49633 | LR: 3.41e-05\n",
      "Step 14125 | Loss: 0.50579 | LR: 3.31e-05\n",
      "Step 14150 | Loss: 0.52430 | LR: 3.22e-05\n",
      "Step 14175 | Loss: 0.50911 | LR: 3.13e-05\n",
      "val loss: 0.5091\n",
      "Step 14200 | Loss: 0.51888 | LR: 3.04e-05\n",
      "Step 14225 | Loss: 0.52485 | LR: 2.95e-05\n",
      "Step 14250 | Loss: 0.52813 | LR: 2.86e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 14275 | Loss: 0.53194 | LR: 2.78e-05\n",
      "val loss: 0.5205\n",
      "Step 14300 | Loss: 0.53267 | LR: 2.69e-05\n",
      "Step 14325 | Loss: 0.51180 | LR: 2.61e-05\n",
      "Step 14350 | Loss: 0.49106 | LR: 2.53e-05\n",
      "Step 14375 | Loss: 0.48727 | LR: 2.44e-05\n",
      "val loss: 0.5127\n",
      "Step 14400 | Loss: 0.53529 | LR: 2.36e-05\n",
      "Step 14425 | Loss: 0.51063 | LR: 2.29e-05\n",
      "Step 14450 | Loss: 0.52307 | LR: 2.21e-05\n",
      "Step 14475 | Loss: 0.54066 | LR: 2.13e-05\n",
      "val loss: 0.5131\n",
      "Step 14500 | Loss: 0.50455 | LR: 2.06e-05\n",
      "Step 14525 | Loss: 0.51775 | LR: 1.99e-05\n",
      "Step 14550 | Loss: 0.49889 | LR: 1.91e-05\n",
      "Step 14575 | Loss: 0.50161 | LR: 1.84e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5105\n",
      "Step 14600 | Loss: 0.51046 | LR: 1.77e-05\n",
      "Step 14625 | Loss: 0.53141 | LR: 1.71e-05\n",
      "Step 14650 | Loss: 0.52333 | LR: 1.64e-05\n",
      "Step 14675 | Loss: 0.53042 | LR: 1.57e-05\n",
      "val loss: 0.5230\n",
      "Step 14700 | Loss: 0.50387 | LR: 1.51e-05\n",
      "Step 14725 | Loss: 0.50280 | LR: 1.45e-05\n",
      "Step 14750 | Loss: 0.50529 | LR: 1.38e-05\n",
      "Step 14775 | Loss: 0.49770 | LR: 1.32e-05\n",
      "val loss: 0.5170\n",
      "Step 14800 | Loss: 0.52554 | LR: 1.27e-05\n",
      "Step 14825 | Loss: 0.53203 | LR: 1.21e-05\n",
      "Step 14850 | Loss: 0.51211 | LR: 1.15e-05\n",
      "Step 14875 | Loss: 0.50390 | LR: 1.10e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5239\n",
      "Step 14900 | Loss: 0.53316 | LR: 1.04e-05\n",
      "Step 14925 | Loss: 0.52399 | LR: 9.91e-06\n",
      "Step 14950 | Loss: 0.53196 | LR: 9.41e-06\n",
      "Step 14975 | Loss: 0.53355 | LR: 8.91e-06\n",
      "val loss: 0.5188\n",
      "Step 15000 | Loss: 0.54028 | LR: 8.43e-06\n",
      "Step 15025 | Loss: 0.53705 | LR: 7.96e-06\n",
      "Step 15050 | Loss: 0.51230 | LR: 7.50e-06\n",
      "Step 15075 | Loss: 0.54069 | LR: 7.06e-06\n",
      "val loss: 0.5211\n",
      "Step 15100 | Loss: 0.51517 | LR: 6.63e-06\n",
      "Step 15125 | Loss: 0.54007 | LR: 6.22e-06\n",
      "Step 15150 | Loss: 0.56078 | LR: 5.81e-06\n",
      "Step 15175 | Loss: 0.52739 | LR: 5.43e-06\n",
      "val loss: 0.5176\n",
      "Step 15200 | Loss: 0.52197 | LR: 5.05e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 15225 | Loss: 0.51381 | LR: 4.69e-06\n",
      "Step 15250 | Loss: 0.49977 | LR: 4.34e-06\n",
      "Step 15275 | Loss: 0.52264 | LR: 4.00e-06\n",
      "val loss: 0.5100\n",
      "Step 15300 | Loss: 0.52686 | LR: 3.68e-06\n",
      "Step 15325 | Loss: 0.54444 | LR: 3.37e-06\n",
      "Step 15350 | Loss: 0.50365 | LR: 3.08e-06\n",
      "Step 15375 | Loss: 0.52186 | LR: 2.80e-06\n",
      "val loss: 0.5123\n",
      "Step 15400 | Loss: 0.50422 | LR: 2.53e-06\n",
      "Step 15425 | Loss: 0.52828 | LR: 2.28e-06\n",
      "Step 15450 | Loss: 0.47755 | LR: 2.03e-06\n",
      "Step 15475 | Loss: 0.49748 | LR: 1.81e-06\n",
      "val loss: 0.5133\n",
      "Step 15500 | Loss: 0.52922 | LR: 1.59e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 15525 | Loss: 0.50475 | LR: 1.39e-06\n",
      "Step 15550 | Loss: 0.52932 | LR: 1.20e-06\n",
      "Step 15575 | Loss: 0.54296 | LR: 1.03e-06\n",
      "val loss: 0.5159\n",
      "Step 15600 | Loss: 0.50074 | LR: 8.71e-07\n",
      "Step 15625 | Loss: 0.55918 | LR: 7.25e-07\n",
      "Step 15650 | Loss: 0.52138 | LR: 5.92e-07\n",
      "Step 15675 | Loss: 0.51700 | LR: 4.73e-07\n",
      "val loss: 0.5098\n",
      "Step 15700 | Loss: 0.50536 | LR: 3.67e-07\n",
      "Step 15725 | Loss: 0.53007 | LR: 2.74e-07\n",
      "Step 15750 | Loss: 0.53109 | LR: 1.96e-07\n",
      "Step 15775 | Loss: 0.48488 | LR: 1.30e-07\n",
      "val loss: 0.5159\n",
      "Step 15800 | Loss: 0.51576 | LR: 7.86e-08\n",
      "Step 15825 | Loss: 0.51008 | LR: 4.04e-08\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 15850 | Loss: 0.53304 | LR: 1.58e-08\n",
      "Step 15875 | Loss: 0.52595 | LR: 4.69e-09\n",
      "val loss: 0.5197\n",
      "=== Epoch 5 Done. Avg Loss: 0.52031 ===\n",
      "Saved final checkpoint: linear_decoder_ckpt_15884_final.pt\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "val_lossi = []\n",
    "total_epoch_loss = 0\n",
    "\n",
    "decoder.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    if step % 100 == 0 or last_step:\n",
    "        biojepa.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 10\n",
    "            for i in range(val_loss_steps):\n",
    "                xc, xct, xt, xtt, p_idx, p_mod, p_mode = val_loader.next_batch()\n",
    "                p_feats = input_bank[p_idx]\n",
    "                B, N = xc.shape\n",
    "\n",
    "                action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "                z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "                target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "                z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "                pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "                real_delta = xt - xc\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_accum / val_loss_steps\n",
    "            val_lossi.append(avg_val_loss)\n",
    "            print(f'val loss: {avg_val_loss:.4f}')\n",
    "        decoder.train()\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0 and not last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    xc, xct, xt, xtt, p_idx, p_mod, p_mode = train_loader.next_batch()\n",
    "    p_feats = input_bank[p_idx]\n",
    "    B, N = xc.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "        action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "    real_delta = xt - xc\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f'Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0:\n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f'=== Epoch {(step + 1) // steps_per_epoch} Done. Avg Loss: {avg_loss:.5f} ===')\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "    if last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}_final.pt')\n",
    "        print(f'Saved final checkpoint: linear_decoder_ckpt_{step}_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-header",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loss-plot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABW0AAAGGCAYAAAAAW6PhAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAlZpJREFUeJzt3Qd8U2X3wPHTQRfQsnehIEM2CIiIKAiKOEBxjz+Ke72iOF5x4OsCfVVEFOer4hZFloqgIsgQRZayZBYoe1OgpYU2/895wg1JmqRpSZs0+X0/n0Byc5M8eXJz++Tcc88TZbPZbAIAAAAAAAAACAnRwW4AAAAAAAAAAOAEgrYAAAAAAAAAEEII2gIAAAAAAABACCFoCwAAAAAAAAAhhKAtAAAAAAAAAIQQgrYAAAAAAAAAEEII2gIAAAAAAABACCFoCwAAAAAAAAAhhKAtAAAAAAAAAIQQgrYAECZuuukmSUtLK9Zj//Of/0hUVFTA2wQAAICyacOGDWZ8OGbMmGKNGXU9XT+Qunfvbi4AEAkI2gJACdMBqz+XmTNnSqQGmytUqBDsZgAAAJRZffv2laSkJDl48KDXda6//nqJi4uTPXv2lGrbimrFihUm2KtB41Ch43Qdr48bNy7YTQEQQWKD3QAACHeffPKJy+2PP/5YfvrppwLLmzdvflKv895770l+fn6xHvvEE0/Io48+elKvDwAAgODQgOy3334rEyZMkAEDBhS4PysrSyZNmiQXXHCBVK1atdivUxpjRg3aPv300yaj1v0ssh9//LFEXxsAQglBWwAoYTfccIPL7d9//90Ebd2Xexpca8aEv8qVK1fsNsbGxpoLAAAAymambcWKFeXzzz/3GLTVgO3hw4dNcPdkBHvMqJnCABApKI8AACFAMwlatWolCxculLPPPtsEax977DHHIPuiiy6SOnXqSHx8vJxyyiny7LPPSl5ens+atlYdspdfflneffdd8zh9fKdOneTPP/90eayn+mR6+95775WJEyeatuljW7ZsKVOnTvV4yljHjh0lISHBvM4777wT8Dq5X3/9tXTo0EESExOlWrVqJui9ZcsWl3W2b98uAwcOlHr16pn21q5dW/r16+dyet2CBQukd+/e5jn0uRo2bCg333xzwNoJAABQ2nRM079/f5k+fbrs3LmzwP0azNWgrgZ39+7dKw899JC0bt3alKhKTk6WPn36yF9//VXo63ga3+Xk5MgDDzwg1atXd7zG5s2bCzx248aNcvfdd0uzZs1MezXj98orr3QZp2n9XF2mevToUaCMmKeatvp+b7nlFqlZs6YZi7Zt21Y++ugjl3WKMi4+GevXrzftr1KlihnPn3HGGfL9998XWO/1118342pdp3LlymYcrZ+RRctc3H///WZsr+2sUaOGnHfeebJo0aKAtRVA6COtCgBChNYX0wHzNddcYwKSOvC0Bq86oB48eLD5/5dffpGhQ4dKZmamvPTSS4U+rw4AdeB3xx13mMHqf//7XzOo10FlYdm5c+bMkfHjx5sBtg7CR40aJZdffrls2rTJcWrd4sWLzal2GiDVU9k0mPzMM8+YgXugaB9oMFYH1sOHD5cdO3bIa6+9JnPnzjWvX6lSJbOetm358uXyr3/9ywxydRCvWc3aXuv2+eefb9qmp/bp43QQr+8RAACgLNMsWg1WfvXVV+bAu0WDtNOmTZNrr73WBEt1rKQH5TW4qAevdVylB9zPOeccU5pAEwWK4tZbb5VPP/1UrrvuOjnzzDPNWFUTDtxpcPS3334zY109wK5jsLfeessEYfV1NYCpyQv33XefGXNqAoNVPsxbGbHs7Gzz+LVr15r3rO9HD/RrMsP+/ftl0KBBARsXF0b7Ud+/ni2n70HHyvp5aBBba+FedtlljpJmev8VV1xh2nfkyBH5+++/5Y8//jB9qO68807zGH1PLVq0ML8TdFy+cuVKOe20006qnQDKEBsAoFTdc889Nvfd7znnnGOWvf322wXWz8rKKrDsjjvusCUlJdmOHDniWHbjjTfaGjRo4Lidnp5unrNq1aq2vXv3OpZPmjTJLP/2228dy5566qkCbdLbcXFxtrVr1zqW/fXXX2b566+/7lh2ySWXmLZs2bLFsWzNmjW22NjYAs/piba7fPnyXu/Pzc211ahRw9aqVStbdna2Y/l3331nnn/o0KHm9r59+8ztl156yetzTZgwwazz559/FtouAACAsuTYsWO22rVr27p06eKyXMeXOv6ZNm2aua3jx7y8PJd1dNwYHx9ve+aZZ1yW6eM+/PBDr2PGJUuWmNt33323y/Ndd911Zrmu72tMO2/ePLPexx9/7Fj29ddfm2UzZswosL6OmfViGTlypFn3008/dRk7ah9UqFDBlpmZWeRxsSfaFl1P2+bN/fffb9aZPXu2Y9nBgwdtDRs2tKWlpTn6vF+/fraWLVv6fL2UlBTzmwFAZKM8AgCECD31SbNJ3WlGhEUzA3bv3i3dunUzR/H/+eefQp/36quvNqddWfSxSjMKCtOrVy9z+pilTZs25hQ667GaVfvzzz/LpZde6pKV0bhxY5M1HAhazkAzZDXbV095s2gGx6mnnuo45Uz7Seuc6elz+/bt8/hcVkbud999J0ePHg1I+wAAAEJBTEyMyWKdN2+eS8kBzS7VM7h69uzpGHNGR0c7xnKaxalnc2nZgqKefj9lyhTzv2aOOtNT+32NaXUcpq+rY0YdnxX3tH99/Vq1apksYotmzGp7Dh06JL/++mvAxsX+tOX000+Xs846y7FM+/X22283n4dmEyt9v1o+wldZBl1HM2+3bt160u0CUHYRtAWAEFG3bl2PkyvoKWx6OlVKSooJmOqp/dYkZgcOHCj0eevXr+9y2xqoegts+nqs9XjrsRpM1dPSdMDtztOy4tD6Z0p/SLjToK11v/4AefHFF+WHH34wP0z09Do95U3r3Fr0tD8toaBlHLSmrda7/fDDD00tNgAAgLLOmmjMqo+qwcHZs2ebYK4GdVV+fr68+uqr0qRJEzN+0jGRji/1FH1/xpbOdBymAWDng/zexm06ZtQSX6mpqS6vq2UMivq6zq+v78MKQluscgrWODEQ42J/2uLpfbu35d///rcJ5mqAV9t+zz33mJJfznQMu2zZMtNXup7WEg5EYBlA2ULQFgBChHP2gUUHsRpo1IkhtE7st99+a2q0anDSGnQXxhqgu7NXQCi5xwaDZnWsXr3a1L3VrNwnn3zSDJS17q3S2mVaH0wzULRGmE5kppOQ6QRnmo0BAABQlumYRg9qf/HFF+a2/q/jNiuYq4YNG2bmStAD3FqLVuvd6vhSJ8byZ2xZXDrnwPPPPy9XXXWVqbv7448/mtfV2q8l+bqhNrbVsemqVavkyy+/NFm533zzjfn/qaeecqyjfaRBWp2wTM9m03ks9PPR5AQAkYOgLQCEMD3VX08d04m4dKKCiy++2JQscD6tK5h0JlsNjurkD+48LSuOBg0amP91cOtOl1n3WzTT48EHHzQ/BDRDITc3V1555RWXdXQmX/3RoKUXPvvsM5PNrANnAACAsk4DtDoG0sxZzbjVbE6dzNWiB7B79Ogh77//vsnA1UladXypyQJFpeMwDbiuW7fOZbmncZu+7o033mjGZToJ13nnnWeCle6vqwfZi/L6a9asKRD0tUqIuY8TS5K+lqf37akt5cuXN6Ua9IwvnTBXy37p2FQnJbPoJL9aHkwnjUtPTzfBbV0HQOQgaAsAIczKBnA++q9ByDfffFNCpX06yNfBpHPNLQ3YBioToGPHjiY4/Pbbb7uUMdDn1xl0rdmJtcav80DXCuBWrFjR8Tg99c09k6Jdu3bmf0okAACAcGBl1WopgiVLlrhk2VrjN/fx0Ndff23OQCoqaw6DUaNGuSwfOXJkgXU9va5mkmpdXWca0FT+BJEvvPBCUwpr7NixjmXHjh0zz6slCPSMtdKibZk/f745o8ty+PBheffddyUtLU1atGhhlmlChjMtj6b3ad9orV/tD/dyEToW1oxbxqtAZIkNdgMAAN6deeaZJqtWsxJ0QgXNPPjkk09CqjyB1tjSrNauXbvKXXfdZQaab7zxhrRq1cr8UPCHDlCfe+65AsurVKliMgy0HIRO0qYDb51oYseOHfLaa6+ZAfADDzxg1tWyCDrBhp5OpgPf2NhYmTBhgllXs0jURx99ZALeWiNYA7o6sdt7771nagXrQBsAAKCsa9iwoRlDTpo0ydx2D9rqmVtadkvHVrre0qVLzZlHjRo1KvJr6cFvHZvp+EoDjfp806dP93jGlb6ujmN1ngYdq2lwUye01QxS9+fUAK+O//Q5tf7tueeeawKX7nSSr3feeUduuukmWbhwoRkbakav1ojVwLEevA8kLWXgaSJgHas/+uijphyFBrJ13K7jWB17apasPs6qu6uZzTp5mo6ddR4GTULQsbMmImh7NVhdr149k43ctm1bE3zWftKJy9zPHgMQ3gjaAkAI00Hsd999Z073f+KJJ0wAVych0+Bk7969JVRqp2nW60MPPWRqyOqECfpDQAegnga1nmj2sD7WnQZWNWirA/GkpCR54YUXzOQNmoGhgVcdzOvsukpfV3806A8F/UGgQVut6aY103TyMaVBX82A0FIIGszVHw06uYP+UNEfOAAAAOFAA7W//fabGee4Tw772GOPmQxQLZ2gGaqnnXaafP/99yboWBwffPCBmVBMx1N69pUGWPX5dGzmTA+4azBW19OzozRoqcFI9zGtBjT1DCudo+CWW24xCQEzZszwGLTVOSG0nJi2XQOkmZmZZjIwLTug48dA81ZOq3v37qbUg/a5jlU101ffY5s2bcycFNaZYeqOO+4wfTBixAgzp4IGaDXIq2N9pWNeHf9qUsT48eNN6Qf9DDUwrgkSACJHlC2U0rUAAGHj0ksvNbVitc4YAAAAAADwHzVtAQAnLTs72+W2BmqnTJlisg4AAAAAAEDRkGkLADhpOrutnoKmtdA2btwob731lpkoYfHixWbGYgAAAAAA4D9q2gIATtoFF1xgJl7Q2Xt1soguXbrIsGHDCNgCAAAAAFAMZNoCAAAAAAAAQAihpi0AAAAAAAAAhBCCtgAAAAAAAAAQQqhpG0T5+fmydetWqVixokRFRQW7OQAAAGFNq4IdPHhQ6tSpI9HR5C5YGJMCAACE3piUoG0Q6eA4NTU12M0AAACIKBkZGVKvXr1gNyNkMCYFAAAIvTEpQdsg0mwG60NKTk4OdnMAAADCWmZmpglOWmMw2DEmBQAACL0xKUHbILJOP9PBMQNkAACA0kEJAFeMSQEAAEJvTEoxLwAAAAAAAAAIIQRtAQAAAAAAACCEELQFAAAAAAAAgBBC0BYAAAAAAAAAQghBWwAAAAAAAAAIIQRtAQAAAAAAACCExAa7AQAAAAAiQH6eyK7ZItnbRBJri1TvJhIdE+xWAQAAhCQybQPku+++k2bNmkmTJk3kf//7X7CbAwAAAISOjPEik9NEpvcQ+e06+/96W5cDAACgAIK2AXDs2DEZPHiw/PLLL7J48WJ56aWXZM+ePcFuFgAAABB8GpidfYVI1mbX5Vlb7MsJ3AIAABRA0DYA5s+fLy1btpS6detKhQoVpE+fPvLjjz8Gu1kAAABA8EsiLBwkIjYPdx5ftvB++3oAAAAoG0Hb4cOHS6dOnaRixYpSo0YNufTSS2XVqlUBfY1Zs2bJJZdcInXq1JGoqCiZOHGix/VGjx4taWlpkpCQIJ07dzaBWsvWrVtNwNai17ds2SKh5lhevtwy5k8ZMv7vYDcFAAAAkUBr2Lpn2LqwiWRl2NcDAABA2Qja/vrrr3LPPffI77//Lj/99JMcPXpUzj//fDl8+LDH9efOnWvWcbdixQrZsWOHx8foc7Vt29YEZb0ZO3asKX/w1FNPyaJFi8z6vXv3lp07d0pZ8uMKex/szMyRPYdygt0cAAAAhDuddCyQ6wEAAESIkA7aTp06VW666SZTekADpWPGjJFNmzbJwoULC6ybn59vArzXXXed5OWdOL1KM3PPPfdc+eijjzy+hpYyeO655+Syyy7z2o4RI0bIbbfdJgMHDpQWLVrI22+/LUlJSfLBBx+Y+zVL1zmzVq/rslCz7cARx/V8T2eoAQAAAIGUWDuw6wEAAESIkA7aujtw4ID5v0qVKgXui46OlilTppiJwAYMGGCCuOvWrTMBWy2r8MgjjxTrNXNzc02QuFevXi6vpbfnzZtnbp9++umybNkyE6w9dOiQ/PDDDyYT1xvN6tXgr5Z+KE1RztedbwAAAAAloXo3kaR6biNRZ1EiSan29QAAAFD2grYahL3//vula9eu0qpVK4/raHbrL7/8InPmzDEZtxqw1eDqW2+9VezX3b17t8ncrVmzpstyvb19+3ZzPTY2Vl555RXp0aOHtGvXTh588EGpWrWq1+fUjGAt2fDnn39KaXIO1P5vdnqpvjYAAAAiUHSMSIfXjt/wErjtMNK+HgAAABxipYzQQKdms2pA1pf69evLJ598Iuecc440atRI3n//fTPBWEnr27evuYQy515Ys+OgHMo5JhXiy8wmAAAAgLIotb9It3EiCwe5TUoWJdL1c/v9AAAAKHuZtvfee6989913MmPGDKlXT0+v8k4nHLv99tvlkksukaysLHnggQdO6rWrVasmMTExBSYy09u1atWSsmTP4VyX2/k2CtsCAACgFGhgtu8GkZ4zRLp8KhJfTURsIgdWiWz4QmTHTJH8E/NSAAAARLqQDtrabDYTsJ0wYYIpe9CwYcNCSxn07NlTmjdvLuPHj5fp06fL2LFj5aGHHip2G+Li4qRDhw7muZxLNejtLl26SFmRvvuwrNiaGexmAAAAwItZs2aZxAMt+aVnik2cOLHQx3z22Wdmwl6dJLd27dpy8803y549eyQkaQmEmt1FGl4vUv0s+7Jl/xH57TqR6T1EJqeJZIwPdisBAABCQkgHbbUkwqeffiqff/65VKxY0dSQ1Ut2dnaBdTWQ2qdPH2nQoIEJ1GqdWZ3s66effpIPP/xQXn31VY+voROHLVmyxFxUenq6ub5p0ybHOoMHD5b33ntPPvroI1m5cqXcddddcvjwYRk4cKCUFX+m7y2w7OCRY0FpCwAAAArS8aUGYHXSWn/MnTvXTMB7yy23yPLly+Xrr7+W+fPny2233SYhTQOzmycVXJ61RWT2FQRuAQAAtJCUTdNZQ5S3WrQahL3pppsKLNcAbbdu3SQhIcFl+eLFi6V69eoeSyvMnDnTTCDm7sYbb5QxY8Y4br/xxhvy0ksvmaCxTjY2atQo6dy5s5yMzMxMSUlJkQMHDkhycrKUpC/nb5KfVriWeFCP9jlVmtSsWKKvDQAAEApKc+wViHGwnm126aWXel3n5ZdfNhPurlu3zrHs9ddflxdffFE2b3auHRtC/aIlEDSj1qW2rbMokaR6In3TmZwMAACEJX/HXiE9C1VR48nnnXeex+Xt27f3+pju3bv79TpapkEv4eaFH/6R/93YsVQmawMAAEDgaKmuxx57TKZMmWLOONu5c6eMGzdOLrzwQp+Py8nJMRfnHw6lZtdsHwFbZRPJyrCvp6UUAAAAIlRIl0dA4PgKSx/MoUwCAABAWdO1a1dT0/bqq6828zDoJLmatVFYeYXhw4eb9axLampqqbVZsrcFdj0AAIAwRdA2QvhKJn7gS3s9XwAAAJQdK1askEGDBsnQoUNl4cKFMnXqVNmwYYPceeedPh83ZMgQczqedcnIyCi1Nkti7cCuBwAAEKZCujwCAsfmM9fWXoqCEgkAAABlh2bMarbtww8/bG63adNGypcvb+Z4eO6556R2bc+Bz/j4eHMJiurd7DVrddIxj+PT4zVtdT0AAIAIRqZthCisbO/7c9JLqykAAAAIgKysLImOdh3Ox8TYJ+8K2bmGdXKxDq8dv+ElYaDDSCYhAwAAEY+gbYRoUDXJ5/3z1u2R7QeOlFp7AAAA4OrQoUOyZMkSc1Hp6enm+qZNmxxlDQYMGOBY/5JLLpHx48fLW2+9JevXr5e5c+fKfffdJ6effrrUqVNHQlZqf5Fu40SS6rouj04QaTZIJK6KSH5esFoHAAAQEgjaRohayQmFrvPLPztLpS0AAAAoaMGCBdK+fXtzUYMHDzbXtWat2rZtmyOAq2666SYZMWKEvPHGG9KqVSu58sorpVmzZiaQG/I0cNt3g0jPGSL1+tuX5R8RWTVSZHoPkclpIhll4H0AAACUkChbyJ47Ff4yMzPNjL06AURycnKJvtaaHQflhR/+KXS9N284TeJjOR0NAACEn9Ice5UlQe0XDczOvsJDfdvjpRM0I1cDvAAAABE29iLTFi4mLNJJIQAAAIASpiUQFg7yMiHZ8WUL76dUAgAAiEgEbSNElJd5Htyt2XmopJsCAAAAiOyaLZK12ccKNpGsDPt6AAAAEYagbYTIzs33a72DR46G7mzDAAAACB/Z2wK7HgAAQBghaBshNu3N8mu9PYdyZeyfGSXeHgAAAES4xNqBXQ8AACCMELSNEN2bVfd73Z9W7CjRtgAAAABSvZtIUr0Tk44VECWSlGpfDwAAIMIQtI0Q5eNjg90EAAAA4IToGJEOrx2/4R64PX67w0j7egAAABGGoG0EifJ3NjIAAACgNKT2F+k2TiSprutyzcDV5Xo/AABABCJoG0Hu69nY73V3Zh4p0bYAAAAAhgZm+24QafOc/XbFZiJ90wnYAgCAiEbQNoLYbP6v+/6c9JJsCgAAAHCClkCofb79+rFDlEQAAAARj6BtBGleO1kql4/za93DucdKvD0AAACAQ2Id+/9HtovY8oPdGgAAgKAiaBtB4mKj5aUr2vi1bn4RsnIBAACAk5ZQ0z4BmS1P5MiuYLcGAAAgqAjaRhh/JyMrSikFAAAA4KRFx4ok1LBfP7It2K0BAAAIKoK2Eci/wC1RWwAAAJSyxNr2/7MJ2gIAgMhG0BYe5VEfAQAAAMGqa5u9NdgtAQAACCqCtvAoj7kfAAAAUNrItAUAADAI2sKj/Vm5wW4CAAAAIk2CFbQl0xYAAEQ2grYRyM+5yCSfEgkAAAAoTUlWeQQybQEAQGQjaBuB7unR2K/1Ji7ZUuJtAQAAABzItAUAADAI2kagdqmV5LVr2ztu925Zy+N6U5dtL8VWAQAAIOI5JiIj0xYAAEQ2grYRKtq5RIKf5RIAAACAUpuIzMbMuAAAIHIRtI1Q0U6FbetVTvS4Th41bQEAAFCaEo+fAWY7JpKzJ9itAQAACBqCthEqoVyMdG1cTc5oVFW6NKoa7OYAAAAAItHlROKr269TIgEAAESw2GA3AMFz81kNg90EAAAAoGCJhJxd9snIKrcJdmsAAACCgkxbAAAAAKGDycgAAAAI2sLuqUtaBrsJAAAAgNNkZFuD3RIAAICgIWgLo37VpGA3AQAAACDTFgAAgKAtCpN7LD/YTQAAAEAkIdMWAACAoC18e2zC0mA3AQAAAJGETFsAAACCtvBt3+HcYDcBAAAAkYRMWwAAAIK2OOGxi5pL4xoVgt0MAAAARDIraHtku4jNFuzWAAAABAVBWzicUr2C3HHOKcFuBgAAQESaNWuWXHLJJVKnTh2JioqSiRMnFvqYnJwcefzxx6VBgwYSHx8vaWlp8sEHH0iZllDL/n9+rkju3mC3BgAAIChig/OyCFU2D9kM+fk2iY6OCkp7AAAAIsXhw4elbdu2cvPNN0v//v39esxVV10lO3bskPfff18aN24s27Ztk/z8Mj6RbEy8SHxVkZw99hIJeh0AACDCELSFC08noH00b4MM7NowCK0BAACIHH369DEXf02dOlV+/fVXWb9+vVSpUsUs00zbsJBQ2x603fC5SO3eItW7iUTHBLtVAAAApYbyCHCR7yHTds6a3UFpCwAAALybPHmydOzYUf773/9K3bp1pWnTpvLQQw9JdnZ2oSUVMjMzXS4hJWO8yME19usrXhCZ3kNkcpp9OQAAQIQgaAtXzPUAAABQJmiG7Zw5c2TZsmUyYcIEGTlypIwbN07uvvtun48bPny4pKSkOC6pqakSMjQwO/sKkfwc1+VZW+zLCdwCAIAIQdAWfsVsPdW6BQAAQPBo7VqdsOyzzz6T008/XS688EIZMWKEfPTRRz6zbYcMGSIHDhxwXDIyMiQk5OeJLBzkZUR6fNnC++3rAQAAhDmCtnDhLTY7b92e0m4KAAAAfKhdu7Ypi6DZspbmzZubg+2bN2/2+rj4+HhJTk52uYSEXbNFsry32wRuszLs6wEAAIQ5grYotKatWpyxv9TbAgAAAO+6du0qW7dulUOHDjmWrV69WqKjo6VevXpS5mRvC+x6AAAAZRhBWwAAACAEaPB1yZIl5qLS09PN9U2bNjnKGgwYMMCx/nXXXSdVq1aVgQMHyooVK2TWrFny8MMPy8033yyJiYlS5iTWDux6AAAAZRhBW7ioUTHe4/JFG/eVelsAAAAiyYIFC6R9+/bmogYPHmyuDx061Nzetm2bI4CrKlSoID/99JPs379fOnbsKNdff71ccsklMmrUKCmTqncTSdIM4SgvK0SJJKXa1wMAAAhzscFuAEJLbEy03NKtobw/Oz3YTQEAAIgo3bt39zn565gxYwosO/XUU03gNixEx4h0eE1k9hXHA7fOfXE8kNthpH09AACAMEemLQo485RqwW4CAAAAIlFqf5Fu40QS67ou1wxcXa73AwAARACCtgAAAABChwZm+20QSahlv93hdZG+6QRsAQBARCFoCwAAACC0aAmECg3t15PqUBIBAABEHIK2AAAAAEJPQk37/0d2BLslAAAApY6gLQAAAIDQY5VHyN4e7JYAAACUOoK28NuSjP3BbgIAAAAiBZm2AAAgghG0hd9en75Gco7lBbsZAAAAiASJxzNtj5BpCwAAIg9BW3h0RqOqHpfbbKXeFAAAAERypm02mbYAACDyELSFR1FRRVsOAAAAlEhNWzJtAQBABCJoC4+qVogLdhMAAAAQyRKdatpyuhcAAIgwBG3hUZ9WtT0uZ7wMAACAUi2PkJctcuxgsFsDAABQqgjawqOEcjHBbgIAAAAiWWx5kdgK9uvUtQUAABGGoC0AAACA0ERdWwAAEKEI2gIAAAAI/bq2AAAAEYSgLbx664YOwW4CAAAAIpmVaZtNpi0AAIgsBG3hVVwsmwcAAABCYDIyMm0BAECEISoHAAAAIDRR0xYAAEQogrYokjlrdge7CQAAAIgU1LQFAAARiqAtiuSL+ZuC3QQAAABECmraAgCACEXQFgAAAEBooqYtAACIUARtAQAAAISmRKeatjZbsFsDAABQagjawqf/69Ig2E0AAABApGfa5ueKHD0Q7NYAAACUGoK28Klq+fhgNwEAAACRKiZBpFyK/Tp1bQEAQAQhaAufaqUkBLsJAAAAiGTUtQUAABGIoC18ql6xYKZtXj71xAAAABCEurYAAAARgqAtimz2ml3BbgIAAAAiBZm2AAAgAhG0RZF9Mm9jsJsAAACASJFwPNOWmrYAACCCELQFAAAAELrItAUAABGIoC0AAACA0EVNWwAAEIEI2gIAAAAIXfHV7f8fWCmyY6ZIfl6wWwQAAFDiCNoCAAAAIWLWrFlyySWXSJ06dSQqKkomTpzo92Pnzp0rsbGx0q5dOwkbGeNF/rjNfv1wusj0HiKT0+zLAQAAwhhBWwAAACBEHD58WNq2bSujR48u0uP2798vAwYMkJ49e0rY0MDs7CtEcna6Ls/aYl9O4BYAAISx2GA3AKEvoVyMHDnqehraxj2HpUHV8kFrEwAAQDjq06ePuRTVnXfeKdddd53ExMQUKTs3ZGkJhIWDRMTm4U5dFiWy8H6Ruv1EomOC0EAAAICSRaYtCtWrRY0Cy1ZuywxKWwAAAODqww8/lPXr18tTTz0lYWPXbJGszT5WsIlkZdjXAwAACEMEbVGoi9vUKbDs6wWbJT/fU+YDAAAASsuaNWvk0UcflU8//dTUs/VHTk6OZGZmulxCTva2wK4HAABQxhC0RaGio6I8Ll+982CptwUAAAB2eXl5piTC008/LU2bNvX7ccOHD5eUlBTHJTU1VUJOYu3ArgcAAFDGELRFseWRaQsAABA0Bw8elAULFsi9995rsmz18swzz8hff/1lrv/yyy8eHzdkyBA5cOCA45KRkSEhp3o3kaR69tq1HkWJJKXa1wMAAAhDTESGQtlsBGcBAABCTXJysixdutRl2ZtvvmmCtePGjZOGDRt6fFx8fLy5hDSdXKzDayKzrzgeuHUejx4P5HYYySRkAAAgbBG0BQAAAELEoUOHZO3atY7b6enpsmTJEqlSpYrUr1/fZMlu2bJFPv74Y4mOjpZWrVq5PL5GjRqSkJBQYHmZlNpfpNs4kYWDXCcl0wxcDdjq/QAAAGGK8ggoVEy0t9PSAAAAEEha7qB9+/bmogYPHmyuDx061Nzetm2bbNq0SSKGBmb7bhBpfKf9ds1eIn3TCdgCAICwF2Xj3Peg0Zl6dfIHrSWmp7eFsuzcPLn380Uuy+7v1VRa10sJWpsAAADCdexVmspEv6wfI/L7QJHafUR6TAl2awAAAEp87EWmLfySGFewXtictbuD0hYAAABEmPhq9v9zGH8CAIDIQNAWxbZgw95gNwEAAACRgKAtAACIMARtAQAAAIS2uKr2/wnaAgCACEHQFgAAAEBoSzieaXvsoEheTrBbAwAAUOII2gIAAAAIbeVSRKKOz7GQsyfYrQEAAChxBG0BAAAAhLaoaJH44yUScgnaAgCA8EfQFgAAAEDoYzIyAAAQQYoctM3OzpasrCzH7Y0bN8rIkSPlxx9/DHTbAAAAAMCOycgAAEAEKXLQtl+/fvLxxx+b6/v375fOnTvLK6+8Ypa/9dZbJdFGAAAAAJGOTFsAABBBihy0XbRokXTr1s1cHzdunNSsWdNk22ogd9SoUSXRRoSI6hXjg90EAAAARHrQ9ghBWwAAEP6KHLTV0ggVK1Y017UkQv/+/SU6OlrOOOMME7xF+KpcPi7YTQAAAECkB22ZiAwAAESAIgdtGzduLBMnTpSMjAyZNm2anH/++Wb5zp07JTk5uSTaiBDRuHqFAsvW7ToUlLYAAAAgwlAeAQAARJAiB22HDh0qDz30kKSlpZl6tl26dHFk3bZv374k2ogQcUnbOgWWDft+ZVDaAgAAgAgTz0RkAAAgchQ5aHvFFVfIpk2bZMGCBTJ16lTH8p49e8qrr74a6PYhhMTFFnlzAQAACGs6Hp4zZ47j9ujRo6Vdu3Zy3XXXyb59+4LatrBDpi0AAIggxYrC1apVy2TVai3bzMxMUy5B69yeeuqpgW8hAAAAEKIefvhhMx5WS5culQcffFAuvPBCSU9Pl8GDBwe7eeGFoC0AAIggsUV9wFVXXSVnn3223HvvvZKdnS0dO3aUDRs2iM1mky+//FIuv/zykmkpAAAAEGI0ONuiRQtz/ZtvvpGLL75Yhg0bJosWLTLBW5RE0JaJyAAAQPgrcqbtrFmzpFu3bub6hAkTTLB2//79MmrUKHnuuedKoo0AAABASIqLi5OsrCxz/eeff3ZM0lulShVHBi4CHLQ9dkgk70iwWwMAABBaQdsDBw6YQahVw0sza5OSkuSiiy6SNWvWlEQbAQAAgJB01llnmTIIzz77rMyfP9+MidXq1aulXr16wW5eeCmXLBJ1/ERBsm0BAECYK3LQNjU1VebNmyeHDx82QVsrm0AnWkhISCiJNgIAAAAh6Y033pDY2FgZN26cvPXWW1K3bl2z/IcffpALLrgg2M0LL1FRIvFV7depawsAAMJckWva3n///XL99ddLhQoVpEGDBtK9e3dH2YTWrVuXRBsBAACAkFS/fn357rvvCix/9dVXg9KeiCiRcGQHQVsAABD2ipxpe/fdd5tM2w8++EDmzJkj0dH2p2jUqBE1bQEAABBRdMKxpUuXOm5PmjRJLr30UnnsscckNzc3qG0LS0xGBgAAIkSRg7aqY8eOctlll0n58uXNRGRK63d17do10O1DiGlWq2KwmwAAABAy7rjjDlO/Vq1fv16uueYaM9/D119/LY888kiwmxfGQVsybQEAQHgrVtD2448/NqUQEhMTzaVNmzbyySefBL51CDl392gc7CYAAACEDA3YtmvXzlzXQO3ZZ58tn3/+uYwZM0a++eabYDcv/BC0BQAAEaLINW1HjBghTz75pNx7772OzFotk3DnnXfK7t275YEHHiiJdiJEVIgv8iYDAAAQtvSss/z8fHP9559/losvvtgxea+OjRFgTEQGAAAiRJEjcK+//rqZGXfAgAGOZX379pWWLVvKf/7zH4K2AAAAiBhaNkzndejVq5f8+uuvZpys0tPTpWbNmsFuXvgh0xYAAESIIpdH2LZtm5x55pkFlusyvQ8AAACIFCNHjjSTkelZaI8//rg0bmwvJTVu3DiPY2acJCYiAwAAEaLIQVsdiH711VcFlo8dO1aaNGkikea7776TZs2amff+v//9L9jNAQAAQCnSuR2WLl0qBw4ckKeeesqx/KWXXpKPPvooqG0LS2TaAgCACFHk8ghPP/20XH311TJr1ixHTdu5c+fK9OnTPQZzw9mxY8dk8ODBMmPGDElJSZEOHTrIZZddJlWrHq+1FSG2HzgitVISgt0MAACAoFm4cKGsXLnSXG/RooWcdtppwW5SeCJoCwAAIkSRg7aXX365/PHHH/Lqq6/KxIkTzbLmzZvL/PnzpX379hJJ9D1rLd+6deua23369JEff/xRrr32WokkW/ZnE7QFAAARaefOnSahQevZVqpUySzbv3+/9OjRQ7788kupXr16sJsYXgjaAgCACFHk8ghKM0o//fRTk1GgF72ugcthw4ZJWaLZwpdcconUqVNHoqKiHEFoZ6NHj5a0tDRJSEiQzp07m0CtZevWrY6ArdLrW7ZskUiTe8w+YzIAAECk+de//iWHDh2S5cuXy969e81l2bJlkpmZKffdd1+wmxd+4o+f0ZaXJXIsO9itAQAACK2grSc6CdmTTz4pZcnhw4elbdu2JjDridbp1fIHWp9MJ5jQdXv37m0yKiLZPefaJ9iw/G/2+qC1BQAAIJimTp0qb775pjnzzKLlEXR8+cMPP5RIUoGz8ePHy3nnnWcyepOTk6VLly4ybdo0CVuxFUWiy9mv5zIZGQAACF8BC9qWRVrO4LnnnjN1aD0ZMWKE3HbbbTJw4EAz+H777bclKSlJPvjgA3O/DqadM2v1ui7zJicnx2RdOF/KoqY1Kwa7CQAAACEhPz9fypU7HkR0osv0vkAnFXgK8mrQdsqUKeYMOC3LoEHfxYsXS1iKiqJEAgAAiAgRHbT1JTc31wx8e/Xq5VgWHR1tbs+bN8/cPv30083pbxqs1dPiNJtCM3G9GT58uJmwzLqkpqZKWZRvswW7CQAAACHh3HPPlUGDBpmyWRYdGz7wwAPSs2fPgCcVuBs5cqQ88sgj0qlTJ2nSpIkpV6b/f/vttxK2CNoCAIAIQNDWi927d0teXp7UrFnTZbne3r59u7keGxsrr7zyisloaNeunTz44INSterxOlseDBkyRA4cOOC4ZGRkSFkU5WGZjUAuAACIQG+88YY5e0rnQDjllFPMpWHDhmbZqFGjSr09mt178OBBqVKlioStuOPj7YxJIjtmiuTnBbtFAAAAARfr74pa29WXXbt2SSTq27evufgjPj7eXMq6igkFTwHcsCdLGlYrH5T2AAAABIueOaVzH/z888/yzz//mGVa39b5bK3S9PLLL5szwK666iqfJbv0YilTJbsyxovs+cN+fc0b9ktSPZEOr4mk9g926wAAAEo/aOtPXayzzz5bwkW1atUkJiZGduzY4bJcb9eqVSto7QpVv6/fQ9AWAABEJJ0wTOvK6sWiAVw9sL969epSa8fnn38uTz/9tEyaNElq1Kjhs2SXrlfmaMB29hV6jpfr8qwt9uXdxhG4BQAAkRe0nTFjhkSSuLg46dChg0yfPl0uvfRSx+lmevvee+8NdvNCzs8rdsi1p9cPdjMAAABCgmayrlu3rtRe78svv5Rbb71Vvv7660KzfLVkl/NZdJppG/JzLWgJhIWDCgZsDV0WJbLwfpG6/USiY4LQQAAAgCAFbcORnjq2du1ax+309HRZsmSJqQFWv359M5i98cYbpWPHjmbSMZ3oQWf0HThwYFDbDQAAAFi++OILufnmm03g9qKLLgrPkl27Zotkbfaxgk0kK8O+Xs3updgwAACAkhHRQdsFCxaYScQsVsaBBmrHjBkjV199tanVO3ToUDP5mE42NnXq1AKTkwEAAAClkVSgWbJbtmyRjz/+2FESQceur732mnTu3NkxYW5iYqKkpKRI2MjeFtj1AAAAQlxEB227d+8uNpunU6xO0FIIlEMAAABAKCQVbNu2TTZt2uS4/91335Vjx47JPffcYy4Wa/2wkVg7sOsBAACEuIgO2gIAAADFUblyZTMBmTcaSC2JpAL3QOzMmTMlIlTvJpJUzz7pmMe6tlH2+3U9AACAMEDQFgAAACginesApUgnF+vwmsjsK+wBWpfA7fHgeYeRTEIGAAAiO2i7f/9+mT9/vuzcuVPy8/Nd7hswYECg2oYQllatvGzYfdhl2ZfzN8k1p9cPWpsAAABKi5YfQClL7S/SbZzIgn+JZG89sVwzbDVgq/cDAABEatD222+/leuvv95MkpCcnOxyWpheJ2gbGU6pXqFA0PanFTsI2gIAAKDkaGC29kUiXyXYb589UaTOxWTYAgCAsBNd1Ac8+OCDcvPNN5ugrWbc7tu3z3HZu3dvybQSIadGxfhgNwEAAACRKDZeJLai/XpKSwK2AAAgLBU5aLtlyxa57777JCkpqWRahDKhe7PqwW4CAAAAIlV8Ffv/OSSNAACA8FTkoG3v3r1lwYIFJdMalBmxMUXedAAAAIDAiDsetM0laAsAAMJTkWvaXnTRRfLwww/LihUrpHXr1lKuXDmX+/v27RvI9qGMyTxyVJITXLcJAAAAIKAI2gIAgDBX5KDtbbfdZv5/5plnCtynE5Hl5eUFpmUok2at3iUXt6kT7GYAAACUmMGDB/u97ogRI0q0LRGL8ggAACDMFTlom5+fXzItQZmsaztz1a5gNwMAAKBULV682K/1NKEBJSSusv3/3H3BbgkAAEBoBG0By/91SSsQtI0SfpwAAIDwNmPGjGA3AZRHAAAAYc6voO2oUaPk9ttvl4SEBHPdl/vuuy9QbUMZREIJAAAAShxBWwAAEOb8Ctq++uqrcv3115ugrV73dQoYQdvCjR492lyo/wsAAFD2LViwQL766ivZtGmT5Obmutw3fvz4oLUrrFHTFgAAhDm/grbp6eker6N47rnnHnPJzMyUlJQUCSffLNws555aQxLKxQS7KQAAACXuyy+/lAEDBkjv3r3lxx9/lPPPP19Wr14tO3bskMsuuyzYzQtfZNoCAIAwFx3sBiD8jF+0JdhNAAAAKBXDhg0zZ6J9++23EhcXJ6+99pr8888/ctVVV0n9+vWD3bzwxURkAAAgzBVrIrLNmzfL5MmTPZ4CNmLEiEC1DWVU+u5DwW4CAABAqVi3bp1cdNFF5roGbQ8fPmxKhj3wwANy7rnnytNPPx3sJoYnMm0BAECYK3LQdvr06dK3b19p1KiRySJo1aqVbNiwQWw2m5x22mkl00qE9MRjNpvrMvfbAAAA4apy5cpy8OBBc71u3bqybNkyad26tezfv1+ysrKC3bzwr2mrQVsdfDIbLgAAiPTyCEOGDJGHHnpIli5daiYm++abbyQjI0POOeccufLKK0umlQhZ/zq3SbCbAAAAEDRnn322/PTTT+a6joUHDRokt912m1x77bXSs2fPYDcv/DNt84+KHDsc7NYAAAAEP2i7cuVKM9mCio2NlezsbKlQoYI888wz8uKLLwa+hQhpdSsnFli2L+uoZOwlswQAAIQvzahVb7zxhlxzzTXm+uOPPy6DBw82k5Bdfvnl8v777we5lWEsJlEkOt5+nRIJAAAgDBU5aFu+fHlHHdvatWubOl6W3bt3B7Z1KJP2Z+XKfyYvl50HjwS7KQAAACWiTZs20rlzZ3PWWcWKFc2y6OhoefTRR83cD6+88oopnYASouUQmIwMAACEsSIHbc844wyZM2eOuX7hhRfKgw8+KM8//7zcfPPN5j7AsmkP2bYAACA8/frrr9KyZUszFtZEhhtvvFFmz54d7GZFbl1bAACASA/ajhgxwmQVKJ0NV2t1jR07VtLS0jgFLAIx5QMAAIhE3bp1kw8++EC2bdsmr7/+upmYV+d4aNq0qSkZtn379mA3MXLq2uYQtAUAABEetM3Ly5PNmzdL/fr1HaUS3n77bfn777/NqWENGjQoqXYiRFUpHxfsJgAAAASNjocHDhxoMm9Xr15tJiMbPXq0GS/37ds32M2LjKAtmbYAACDSg7YxMTFy/vnny7591I2CXZTWE/PCVqotAQAACK7GjRvLY489Jk888YSpc/v9998Hu0nhzVHTlqAtAAAIP0Uuj9CqVStZv359ybQGAAAAKINmzZolN910k9SqVUsefvhh6d+/v8ydOzfYzYqQTFsSSgAAQPiJLeoDnnvuOXnooYfk2WeflQ4dOphTwpwlJycHsn0AAABASNq6dauMGTPGXNauXStnnnmmjBo1Sq666qoCY2SU4ERk1LQFAACRHLR95plnzOy4F154obmtNbqcT4232Wzmtta9BQAAAMJZnz595Oeff5Zq1arJgAED5Oabb5ZmzZoFu1mRhZq2AAAgjPkdtH366aflzjvvlBkzZpRsixA2bBS1BQAAYapcuXIybtw4ufjii828DwgCgrYAACCM+R201Uxadc4555RkewAAAICQN3ny5GA3AdZEZJRHAAAAkT4RmXM5BAAAAAAIek1bJiIDAACRPhFZ06ZNCw3c7t3LkW64ZmcDAAAAAUd5BAAAEMaKFLTVurYpKSkl1xqElXdnrZf6VZOkdkpisJsCAACAcM20PXZIJC9XJCYu2C0CAAAITtD2mmuukRo1agTu1REWKiXFyf6sXI/3vf7LWhl2WetSbxMAAEBZNGvWLHnppZdk4cKFsm3bNpkwYYJceumlPh8zc+ZMGTx4sCxfvlxSU1PliSeekJtuuknCXjlNJtGzAG32EgmJNYPdIgAAgNKvaUs928AZPXq0tGjRQjp16iTh4NE+p3q9b+8hz8FcAAAAFHT48GFp27atGS/6Iz09XS666CLp0aOHLFmyRO6//3659dZbZdq0aRL2oqJF4irZr1MiAQAARGqmLfVJA+eee+4xl8zMzLAoN1G9YnywmwAAABAW+vTpYy7+evvtt6Vhw4byyiuvmNvNmzeXOXPmyKuvviq9e/eWiKhrq1m2TEYGAAAiNdM2Pz+f0ggAAABACJk3b5706tXLZZkGa3W5Nzk5OSZ5wPlSZjEZGQAAiPSgLQAAAIDQsn37dqlZ07WWq97WQGx2drbHxwwfPtyc7WVdtA5umZ+MLIegLQAACC8EbQEAAIAIMmTIEDlw4IDjkpGRIWUWmbYAACDSa9oCAAAACC21atWSHTt2uCzT28nJyZKYmOjxMfHx8eYSFuIq2/8naAsAAMIMmbYIiEpJcR6XR0WVelMAAAAiRpcuXWT69Okuy3766SezPCI4Mm2ZiAwAAIQXgrYIiHqVPWdyAAAAwH+HDh2SJUuWmItKT0831zdt2uQobTBgwADH+nfeeaesX79eHnnkEfnnn3/kzTfflK+++koeeOABiQjUtAUAAGGKoC0C4uI2tT0uJ9MWAADAfwsWLJD27dubixo8eLC5PnToUHN727ZtjgCuatiwoXz//fcmu7Zt27byyiuvyP/+9z/p3bu3RARq2gIAgDBFTVsERJOaFYPdBAAAgDKve/fuYrPZvN4/ZswYj49ZvHixRCRq2gIAgDBFpi1K3MptmbJ4E3XGAAAAEGDlUuz/H9oosmOmSH5esFsEAAAQEARtUeJenrZK3vhlrezPyg12UwAAABAuMsaLzL3afj1nh8j0HiKT0+zLAQAAyjiCtihROUfzHdcPHjkW1LYAAAAgTGhgdvYVIkd2uC7P2mJfTuAWAACUcQRtAQAAAJQdWgJh4SAR8VT79/iyhfdTKgEAAJRpBG0BAAAAlB27Zotkbfaxgk0kK8O+HgAAQBlF0BalxsdEyAAAAIB/srcFdj0AAIAQRNAWAAAAQNmRWDuw6wEAAIQggrYAAAAAyo7q3USS6olIlJcVokSSUu3rAQAAlFEEbVFqcvPyg90EAAAAlHXRMSIdXjt+wz1we/x2h5H29QAAAMoogrYImJ7Na/q8/7u/t5ZaWwAAABDGUvuLdBsnklTXdblm4OpyvR8AAKAMI2iLgLmqo56m5t36XYdLrS0AAAAIcxqY7btBpNWT9tsprUX6phOwBQAAYYGgLQImNobNCQAAAKVISyDU7m2/fuwQJREAAEDYIMqGUmMLdgMAAAAQfhKPl0jI3ipiY8QJAADCA0FbAAAAAGVXYh37//k5Ijl7gt0aAACAgCBoi4BKiOOUNAAAAJSimDiR+Or269lbgt0aAACAgCBoGwSjR4+WFi1aSKdOnSTcRPm4z8bpagAAACgJScdLJGQRtAUAAOGBoG0Q3HPPPbJixQr5888/JdykJJYLdhMAAAAQaRLr2f/P3hzslgAAAAQEQVsE1GXtj2c5AAAAAKWFTFsAABBmCNoioJLiYr3el52bV6ptAQAAQIRIPB60paYtAAAIEwRtUapyj+UHuwkAAAAIN2TaAgCAMEPQFgFVpXycz/vzmYwMAAAAgUamLQAACDMEbRFQtVISfN5/LJ+gLQAAAEoq05aJyAAAQHggaIuAG96/tdf7Hv3m71JtCwAAACJAUj37/7n7RI5lB7s1AAAAJ42gLQKuRrL3bFsmIwMAAEDAlUsRiUmyX6dEAgAACAMEbVHqjuXly5GjBG8BAAAQIFFRTEYGAADCCkFblLonJi6Tez5bJIdyjgW7KQAAAAgXTEYGAADCCEFblLpdB3PM/+/+uk7GzE0Xm43JyQAAAHCSmIwMAACEkdhgNwCRa/nWTPN/hwZVpHW9lGA3BwAAAOEwGRnlEQAAQBgg0xZBl019WwAAAJwsyiMAAIAwQtAWJSIulk0LAAAApYiJyAAAQBghsoYSceOZacFuAgAAQJk0evRoSUtLk4SEBOncubPMnz/f5/ojR46UZs2aSWJioqSmpsoDDzwgR44ckYhDpi0AAAgjBG1RImomJwS7CQAAAGXO2LFjZfDgwfLUU0/JokWLpG3bttK7d2/ZuXOnx/U///xzefTRR836K1eulPfff988x2OPPSYRm2mbvVUkn/JbAACgbCNoCwAAAISIESNGyG233SYDBw6UFi1ayNtvvy1JSUnywQcfeFz/t99+k65du8p1111nsnPPP/98ufbaawvNzg1LCbVEoqJFbHkiOZ6D3AAAAGUFQVuUiJioqGA3AQAAoEzJzc2VhQsXSq9evRzLoqOjze158+Z5fMyZZ55pHmMFadevXy9TpkyRCy+80Ovr5OTkSGZmpsslLETHisTXtF9f94HIjplk3AIAgDIrNtgNQHiqVzmxSOsfOZony7dmSuu6KUxiBgAAItLu3bslLy9PatY8Hng8Tm//888/Hh+jGbb6uLPOOktsNpscO3ZM7rzzTp/lEYYPHy5PP/20hJ2M8SI5u+3X/37C/n9SPZEOr4mk9g9q0wAAAIqK6BhKRHR0lLx/Uye/1tUfGG/NXCdvzlgrn/y+scTbBgAAEC5mzpwpw4YNkzfffNPUwB0/frx8//338uyzz3p9zJAhQ+TAgQOOS0ZGhoRFwHb2FSK2o67Ls7bYl+v9AAAAZQiZtgi6j3/fKEdy7aeu/bZ2t9xyVsNgNwkAAKDUVatWTWJiYmTHjh0uy/V2rVq1PD7mySeflP/7v/+TW2+91dxu3bq1HD58WG6//XZ5/PHHTXkFd/Hx8eYSNrQEwsJBmgrg4U5dFiWy8H6Ruv1EomOC0EAAAICiI9MWQWcFbAEAACJZXFycdOjQQaZPn+5Ylp+fb2536dLF42OysrIKBGY18GudzRQRds0WydrsYwWbSFaGfT0AAIAygqBtAF122WVSuXJlueKKK4LdlJBRI7l4WRxH8/Jl+sodsjPzSMDbBAAAEKoGDx4s7733nnz00UeycuVKueuuu0zm7MCBA839AwYMMOUNLJdccom89dZb8uWXX0p6err89NNPJvtWl1vB27CXvS2w6wEAAIQAyiME0KBBg+Tmm282g2zYPXR+M3lk3N9FesyPy7fL2D9P1FbztzYuAABAWXf11VfLrl27ZOjQobJ9+3Zp166dTJ061TE52aZNm1wya5944gmJiooy/2/ZskWqV69uArbPP/+8RIzE2oFdDwAAIARE2SLmvKnSmwzijTfekHHjxhW6bmZmpqSkpJgJIJKTkyUcHc45Jvd9sfiknoOgLQAACIRIGHtFZL9oTdvJafZJxzzWtY0SSaon0jedmrYAAKDMjL1CojyCZgXccMMNUrVqVUlMTDQTKCxYsCBgzz9r1iyTcVCnTh2TiTBx4kSP640ePVrS0tIkISFBOnfuLPPnzw9YGwAAAACUAA3Ednjt+I0otzuP3+4wkoAtAAAoU4IetN23b5907dpVypUrJz/88IOsWLFCXnnlFVMb1pO5c+fK0aNHCyzXx7nPtGvROmBt27Y1QVlvxo4da2qIPfXUU7Jo0SKzfu/evWXnzp2OdfT0tFatWhW4bN26tVjvPRJEuY+bAQAAgEBL7S/SbZxIUl3X5Zphq8v1fgAAgDIk6DVtX3zxRUlNTZUPP/zQsaxhw4Ye19XZc++55x5p0qSJmWzBmlxh1apVcu6555qg6yOPPFLgcX369DEXX0aMGCG33XabY5KHt99+W77//nv54IMP5NFHHzXLlixZclLvFQAAAEAJ0cBs3X4if94lsu49kZo9RHr8RIYtAAAok4KeaTt58mTp2LGjXHnllVKjRg1p3769mTHXE510YcqUKbJ48WIzc64GcdetW2cCtpdeeqnHgK0/cnNzZeHChdKrVy+X19Lb8+bNk0DTjN8WLVpIp07UagUAAAACRgO09frZrx/ZRcAWAACUWUEP2q5fv17eeustkz07bdo0ueuuu+S+++6Tjz76yOP6Wpf2l19+kTlz5sh1111nArYaXNXnKK7du3dLXl6eY1Zei97WWXv9pe3Q4LMGluvVq+c14KvZwlrO4c8//5RwFx2A+gjv/LpOxi3cHJD2AAAAIMyltLT/f3CVSH7BsmoAAABlQdDLI2i2rGbaDhs2zNzWTNtly5aZ8gQ33nijx8fUr19fPvnkEznnnHOkUaNG8v7775sJxoLt559/DnYTQk5CuRjp176uTFqss/kWz/z0veb/KzrUC2DLAAAAEJbK1xeJrSBy7JDIwTUiKS2C3SIAAICyl2lbu3ZtUyrAWfPmzWXTpk1eH6MTjt1+++1yySWXSFZWljzwwAMn1YZq1aqZ+rjuE5np7Vq1ap3Uc0Okb9s6AXuu3GP5EqkO5xyT0TPWyuJN+4LdFAAAgNAVFX0iULt/WbBbAwAAUDaDtl27djUTiTlbvXq1NGjQwGspg549e5rA7vjx42X69OkyduxYeeihh4rdhri4OOnQoYN5LucMYL3dpUuXYj8vAuvH5dvlrk8XRmzQcsLiLbJo4z5545e1Ptfbn5UrU5Zuk8wjnA4IAAAiVEor+/8Hlge7JQAAAGUzaKtZsr///rspj7B27Vr5/PPP5d133zV1X91pILVPnz4moKuB2tjYWJOl+9NPP8mHH34or776qsfXOHTokCxZssRcVHp6urnunM07ePBgMwGa1tJduXKlqa17+PBhGThwYAm+exTF2D8zzP/vzV7vWJaxN0v+3GAvnxDuDmT7F4R95cfV8s3CzaYWcGnIy7fJ69PXyLd/bS2V1wtnx/LyZfnWA5JzLC+o7bDZbEF9fUC3wZmrdsranQeD3RQAZVUlK2hLpi0AACibgl7TtlOnTjJhwgQZMmSIPPPMM9KwYUMZOXKkXH/99QXWjY6ONsHdbt26mexYS9u2bU092erVq3t8jQULFkiPHj1cArRKa+aOGTPGXL/66qtl165dMnToUDP5WLt27WTq1KkFJidD8EXJifrF/5lsz56o1KecNKlZUSLVgg17ZfGm/XLjmWmydX+2WfbPttIJdvy1eb8sybBfLm5TOyTqS7sHfwLRpiNH8+TvzQekVd1kSYqLLVJQOzpKfLZBg7TloqNl/KItMm35dmlVN0UeOK+pBIMeCHlp2iq5pG0dOa8F+z8Ex8ptB+WTeRvN9fdv6hTQ59bv28if10jruilyYevaZpmewbFxT5b0a1fH8V3Vfce+rKNSpfyJ8UagrNt1SH5bt0f6t68r5eNjQ2Y/B4TlZGRk2gIAgDIq6EFbdfHFF5uLP8477zyPy3UCM2+6d+/uV+bYvffeay4IvMtOqysTFhV/MjL34Nk/2zNl98Fcx7It+7OLFbTVH+//m50u7VIrSdfG1SQU7Mw8IlUrxEuMRvr89NZMe1ZtnUqJJ53NWy4mqkhByaNOdYZXbMuUlnVSJFQs3XxA3p29XgZ2TZPT6lcucP+G3YdF4xwNqpYv9Lk+/X2jzFu3R5rXTpaHejfzuwbzo+P/lprJCfLvC071uE5W7jH51+eLpW7lRNmZmWOWLdtywOO6+fk2+WjeBmlSo6Kc1aRkttePfttg6id/OX9TmQ7a6j5/875s850oynepuDQj9OsFm+Xa0+tLWrXCt6dA2nMoRxLjYor0vQ11OzKPuHyPq1aIO+n9m2X26t2yevtBc7GCtlbZmYbVykvb1Erm+sfzNsqs1btkYNeGfn3f9O9JfGyMX20Y9v1Kx/7z5rMansS7se9nnpq8TNKqlpc7zjnlpJ4LCMvyCDoRWd4RkZiEYLcIAACgbJVHQGS4uE3gJiNTL01dJR/OTXfc1hquGvwqqhn/7DR1Yj+Yc+K5TubU9o17Dp/UqeXz0/fKkPFLC61b640/dWw1ILd+16EC7dT+Gzx2iQkgFtfewycC6aFg5M+rJUsncPPQnxpgefa7FfLMtyv8muBOA7Zq5bbMImXTHcg6aoJD1mt6yihUW/bZM6SdA7TutBTInDW7XbZ9b/QzLuzUcg32aWZtuJVa0Ozm75duM5n4/vRVIAyf8o+s3XnIZCkHos/04I0/fac1rB8Z9/dJfW9Lkh4I8ncb0NIgL037x7x39+/xkxMDd3rz0Tzv3/d9WSf2YRqwVeMXby70OfW7dveni+SL+d4nUfVk2wHX731xLN2y3xzw0b8fwaDboB7kcQ60AyEhsbZIuUoitnyRzH+C3RoAAIAiI2iLsLDnUK48UciPeg14vTlzrcnUtRzOCUztUP3hfccnC00AcPJJ1HbVydbU35v3+1zv8z82FQhsqIN+BG0fn7BUnv9+pQydtNwEmi1WWYWSsGr7QXnuuxWy/UDo/KjPzj3x2ef6COKcDOdYlWbqalBHg6neOJ/d/LiH7TnLqc2HcrwfpNDPVT9jDSQ6b+/uNNingU0NujjaLIGjQev7xy6RuWt3S2lZsTXTfBetzH4r2F5afPW3v778M8McvPnln52FrrthT8kG3U+G7nP1QNCnf3gOZLofxBjx42pT1sW5brk3U5dtMwH54hwUKE4VgX2Hc30elPrm+Pb284odRX/y499Z533xU5OWycKNrkFYPWCkWccnY/ehHPmhGAc59YCg1kr39HfnzZnr5KcVO8w+Bwgp+mW3SiSsfU9kx0yR/ODWjAcAACgKgrYIG5rR+Nu63V5PLX975jpZuGGfqRlqOZkSgJpRpYFIzdrSIKrlh6XbSzy7cPrKHfLyjwUz+rT+YmEOHjnmCAw8890Kk2Xsrb36Q70o2VPe3vZ/p/4j6bsPm4BxoOjzecpS0/eiwZzv/vYdPD+a5/sz+npBhkxcvMVrgMUKmv6Vsd/0kWYw6+RvemDAus/mFALVrG41aclWl2xa5wC9c8avp+CIs0FfLPbatld/Xu0x0OuNlhcpKn+2cS3bcejIMa+Z7PoczsHzQHj713V+tU3X0c9MaYbiLWP+NOUyvK0bSJrd7Ct4bwX+vphvn3zRX1ZQUfdJup8r7ECMZiS/OPUf+XjehiK9jvaHfr9029U+1L7Ti3PgUb8Xus9VMz0EnzUgqQcxpi47sT8uyqSLWopCs85X7/Dej9553/F7+qT1e/rQ13/Jw1//Zb6jGvjUgzD6HdXLJ79vdGTTOwektX89cQ/G6vvQAw3WpJrvzlpvSnu8OWOdSxtenrbKZB1bZ1R4e35PdB+lj/v3uL9l3MLNjnrB/npv1npzRsuwKQUDs+t22j8D6/sEhIyM8SL77JMQy5o3Rab3EJmcZl8OAABQBoRPATyEvGoV4s2P3ZL0/mx7cEgncZqzdrd0a1KtQI3VzONBSw1s+PubV7Pn4mOjZXvmEaleIV4WbtznCKzoBFzO9Hn/9cViubpTqnRr4nlyPF0nNjqqwMQxW4twqqxmFxdGgyixMd6Pzegp+XppX7+SVEwouDt44Ev7j51eLWqaWp2F0felAR0NNnVMqyxNC6kzrIGIaA/1RjULTIObZzSqampMutPMUA2Ye5qkaP3uwyYI4um18m02R388+s3fXgNfs9fscgSTtOal1vl1psFu7bdbujV0bHOnN6ziOD1ZJ8u7q7vn2pLOm5xmUnpqq0UnR/p9/V656cw0U7PUH/M37C3yJHR60OHcU2tIz+Y1PYazNFClgd20qklmm9WM8GnLd8i/+zSTGhUTTLDm+SkrJS4m2nzm+lyvTV9tshOdg0b6HaqUdGJSp1HT15rA37OXtvJYr1S/d6//skbapVYutL6ubutaEsHfwNGrP6+R5VsOyH/6tjTBdqXlMty3Jw1UaYahftZnnlLN5bPR7MJzmlaXzo2qFtjWvv17qzSrVVFOrZVc4LWtCRSv6pQqp6dVkVU7DsrqHQfl+s4NXOrvFjVYrEFFbf8Py7bLpMVb5Ks/M2T09adJQrkYrxnwVm3XAV3SHN8trfPd49Qa0qFBwTrQavnWTI81yv9I3+uoDT5q+hqfbdXApHVw5IJWtQoEbbU+tj/8KW1SnAOAevDF8RpOwWg9IPPaz2tMQHzRpn2ScyxfjrgdeNADEfd+vkhqpSTI85e1LrBvcw7Grt91WNbvsu9DNMjd6aYqkukhaG1z2y+f1qCyCYzr/im1iu9av/od0zY7+8cpyDxpyRbzXbu6U8F9/OZ9WfLNwi0mg935oF8gJ0nTgyWala/7DSZTQ8BoYHb2FQUPxWRtsS/vNk4ktX+wWgcAAOAXgrYoNUMuPFUe/OqvUnmtV3+yZxr+mb5XujerLld2TC0Q4Bn05WLJOer7B7+up0FeDYb4ss3ttH/90T5m7gaXoK0GfzTYq0EZzUxqU6+SNKlZwQQdLm1f16xTWHs8ZdxqoM0b/YGdkljOY2DUpb1H86SCjxnMfz4enPIUWNtxMMcl+GdlHWvbfM36/u1fW+X7v7fJExc3l3qVkwpk0Wk9SX3d/93Y0SzT+FXGviyzrqfgvwZRNAhVvWK8x9f7z7fLTSbyK1e2LRDY00CKftbaBxq4cw6aaNDCPQBl1Z8d7xS4WnM820yl7/Yv+29xxj6f91u1jSsnlZNrNGheSDzjj/V7HEFkbzQ7TwNPul1YtGyFfm66LXkKE+r7t2r5avBUg5VqyDdLzWc8/Z+dsuP4d0CzSPWzd/fYeHuWta5vTdhkZRnPXLVLrutc31Eb9NPfN5kAsW63GoDWi6egrQaPNVA++PymJvg92SmL2Rf9rDVg6xxAtWzakyWxMVEmcN+ndW0TsDXtnp3uCNpqlrf12eg217Ku64Ghuz9b5KibevvZjcwkWsfybWbbLe8UfNegql4sjWtUcAkMO9P9hH4nNMCrQc7356RLxwaVpVH1Ci7r6T7GynxUus/VwK3Szz0hNtocuNDtetnWAwUCa3rART9rveh3z1MQbb+XjH6tSettQkf3A0jHnDLdta+d37fep7XGPdGAbrLTASbNPNX95yVt6/ickK5cTLQklIuWzOzCg47jFm029Ykt+U67Zee/BRrc9cR6rKdyMEcK2cfr9uCcaawZ2Toh2pUd67msZ/WP7kfvdDpApJN06rL/OyPNBI3Vr6vstXmd6T5Oy5bowRTdDyv9/uu+UQ9E9mlVW+Jio+WpSa7fj8Lo9yGxXIzUr5okM1ftNH/vPvt9kzSomiRDLmzu8TG6z1Xl42PNgTrgpGkJhIWDvOTO67IokYX3i9TtJxLt3wFRAACAYCBoi1KjGXZPXNzCkSFZWjQgpBlgzrbuP1IgQKqZUZefVs9k52pwQX/Q6mndGnDxRTOUnDMKnekpwyOuaicpSeUcwR+LBqysoJVm5DWvXTAjTwNIX/65SfqfZg/qurMCbd7oKb2WmikJcnEb+0zpnjj/tNFgg/ukZprZq8ua1qjoCALvOphjMvq80cDVRi81N63SAyN/XmPeX5dGVR0BIufTup/+doUkJ5aTepUTZdqy7SZj29Ns69ZERZqB5okVaH3lx1UuARkr+OiNBhD9yS5z3gasLGhPiZIaLNRT12t4CS57okFSb5mmGpTSAF5qlSSXAKAlyilYqx/bM98uN0GsFnUKbm/uNJidFBfrMvmaFbAtbNI0XwdUtISJpwxqpXV4lfsEaVZbrACg1n21Sk74OwmXFcDzVTP16W+Xu+wnnGk90cl/bSlQWsO9VIXzRFdWRqlFM3a90VISziUGrM9NA9P/c2qzFbDTYNvdPRq7rP/mjLUF9k8a0G5dN0UGf7VEqpSPk5eubFsgGLc4Y7+cVr+y7Dx44j3f+tEC879+/zTI1zGtitx5TiOJ9pK8/8f6vSZj11O5jbs+WyQ9mtVwBOed6QEuK5PTF+1/DdK6Z53rvqR3y1omyOge6L7r04UFnkffh1c2MZMX+jtxmeen8Px90CDvR7/5LkXhXL5HaRkc/Vul9X69scpQWJN0qrdmrpWn+7XyeDaIxb1sie7nrL/Puu+yDiZ6ovtoPSuhldsBCy2Fo4Zf3tqlBIPuc/VgR/n4GHMQRv++9mtX12U/pN9NICB2zRbJ8jWBoH7RM+zr1exeig0DAAAoGoK2KFXeAjUlzbluptZX9FRjUdfROoV60Qwz6wdtYWUINODgyxOTlhV6arfWKnTPSr31oz8dQT8NZHkLRmqWmj8TkWkmpK8sTOfsU0+1ZzVYYpVK0KCuvidPp/E609OsFxyv02jRQK9zNqwGO7VdOmHUg+c3sy90Su6zgndWZqRm2VqBAaUBy+ucSjfo6ca+uAdsC5N9tHh1GjVg740VXG1ay3f5CPfgTYcGBYNNf28+YPrO24RbWntUywt8+Fu61E5JcARGvAXJNOva4m8wtCismtMawHEPcvmqb6sZoLccD9ZPWbbdEbD197O4qE1tUybA/eCJP211/w6cDF/fQc3qH3Y8aG25/WN74NQb9yCtJ3rgJya6gbnubTKtnZk5puSDHigq0K7j33P9Lt+6Ya80qu59P67rDvMwIZUG9jUDW4PHTWu5Zgcrq7SIL1b/e9pOtK7szV3TzPatmarfLNrs8b1Y78Oi35sup5zI7tT9fyBp9nGTGhVNQPmDuelea657U9SzL4pS39yd8wFVzdb1FrTVyTatg3Xe/i55OtClE5U5l/zQA2jmDILjKIyAgMneFtj1AAAAgoSgLeCBlWEWCJq15Ssb1eI+67i/5Sydg8bb3DIDi2K0H8Ef53Zq8OHspp5r9lrcA7ZWLVlPQR8NIv6+fo8J6K4twuRCv63dbS4WrckZSBrM8sZbhrW/3CcvKqwdOuu7v4Fh50xzvfg6nds58GWVOSjK6dAa4AmE575f4bP0gwZtNQjtz/fJnXUKeChz/3wDRTPYdXI+X7Vyf165w+/t2deBkQmFfDYaePUny7uodB9QKzlBxi/yPyivNIO5Vd3Atsc5qKwZspoF37JOcpEDtidDD8JpzVsNkheXp/IOyvn7562MhafAvaft7sv5JybxpJwtAiaxdmDXAwAACJIoW0lPcw+vMjMzJSUlRQ4cOCDJyYH/ERuq/Ak0oSCtgWuVUwg0rSXIzN8IFq036s8p6Dq531gPJSDgm5YTcA4k3nHOKY7J12A/e8D9oFm40Cxib1n4oUaz4fuf5lq7tyRE6tgrovpFa9pOTrNPOuaxXEmUSFI9kb7p1LQFAAAhPfbyPq08gJBSUgFbRcAWweRvzVACtsXjXk5gwuKiZaOGu3AN2KqyErAFAkoDsR1eO37DPYX7+O0OIwnYAgCAkEfQFqXOmkTqyo6pwW4KAEQcXyU/gGChPAICKrW/SLdxIklutZnLJduX6/0AAAAhjpq2KHVdG1czs5TrKbtfLyBzDgCASOdnwj3gPw3M1u0nsmu2SPqnIuvfF0luTsAWAACUGWTaIig0YAsAAFCSE/EhwmkJhJrdRVo/Zb+95w+RIycmLwUAAAhlBG0RVH3b1Ql2EwAAABDOyqeKVGpjn5jsn1dFNnwhsmOmfdIyAACAEEV5BARVQjkybgEAAFDCKjQW2f+3yIphJ5Yl1bNPWkbJBAAAEILItEVQMe8IAAAASlTGeJHN4wsuz9oiMvsK+/0AAAAhhqAtgiqa6aIBAABQUrQEwsJBXu602f9beD+lEgAAQMghaIugalMvJdhNAAAAQLjaNVska7OPFWwiWRn29QAAAEIIQVsEVY3kBHnpyrbBbgYAAADCUfa2wK4HAABQSgjaIuiqlI8LdhMAAABCxujRoyUtLU0SEhKkc+fOMn/+fJ/r79+/X+655x6pXbu2xMfHS9OmTWXKlCml1t6Qllg7sOsBAACUktjSeiEAAAAAvo0dO1YGDx4sb7/9tgnYjhw5Unr37i2rVq2SGjVqFFg/NzdXzjvvPHPfuHHjpG7durJx40apVKlSUNofcqp3E0mqZ590zKph6yLKfr+uBwAAEELItEVIePbSVsFuAgAAQNCNGDFCbrvtNhk4cKC0aNHCBG+TkpLkgw8+8Li+Lt+7d69MnDhRunbtajJ0zznnHGnblvJTRnSMSIfXjt/wNAGuTeSUW0u5UQAAAIUjaIuQUKdSotx8VkPH7WtPrx/U9gAAAJQ2zZpduHCh9OrVy7EsOjra3J43b57Hx0yePFm6dOliyiPUrFlTWrVqJcOGDZO8vDyvr5OTkyOZmZkul7CW2l+k2ziRpLqe71/6lMjkNJGM8aXdMgAAAK8I2iJkRDklP3RvVj2YTQEAACh1u3fvNsFWDb4609vbt2/3+Jj169ebsgj6OK1j++STT8orr7wizz33nNfXGT58uKSkpDguqampEvY0cNt3g0jrpz3fr+UTZl9B4BYAAIQMgrYIGR0bVJHalRLknGbVJTYmWiomUHIZAADAl/z8fFPP9t1335UOHTrI1VdfLY8//rgpq+DNkCFD5MCBA45LRkaGRIx173m543i924X3i+R7z1IGAAAoLUTFEDLiYqPl2X6tJOp4ym3N5AQ5eORQsJsFAABQKqpVqyYxMTGyY8cOl+V6u1atWh4fU7t2bSlXrpx5nKV58+YmM1fLLcTFxRV4THx8vLlEnF2zRbI2+1jBJpKVYV+vZvdSbBgAAEBBZNoGwejRo83EEp06dQp2U0KOFbBV+TZPM/wCAACEJw2warbs9OnTXTJp9bbWrfVEJx9bu3atWc+yevVqE8z1FLCNaNnbArseAABACSJoGwQ6UcSKFSvkzz//DHZTQlpMtOfNs2G18lKWUfYBABAJWtZNCXYTyqTBgwfLe++9Jx999JGsXLlS7rrrLjl8+LAMHDjQ3D9gwABT3sCi9+/du1cGDRpkgrXff/+9mYhMx5twk1jbv/USapR0SwAAAApF0BYh68YzG0j1ivFyU9c0Gda/tWN5vcqJ8thFzeXKjmVz0gx9L29cd1qJPX9KUjmJdEnxBMYDKb5c6fyp6JhWRS5q4+cP6jCTVsYPRllOb1hFIt2AM9MkkjSrVdHj8napleSGzvVLvT3hQGvSvvzyyzJ06FBp166dLFmyRKZOneqYnGzTpk2ybduJTFCdRGzatGkmGaBNmzZy3333mQDuo48+GsR3EaKqdxNJqqfndvle77cbRZY+I7LhC5EdM6lxCwAAgoKgLUJW7ZREeeHyNtKtSXVT39Y5KHlK9QpyQata0v3UgpkQ5eNjZfT1p8nwy08Eer3V0HV3dSffgeD/3dhRTlZ0VJQkxp2oOxdorT1kNsVER8m/ejaRSHHLWQ1NwKA0xMYU8sPPSc2UE9txWdKyTsFtqkWd5IC/jk1s0v+0enJfGdlW3fvg+jPqy/91aVCs5+rerHqBZc9c2spxvcspVaV5bfvrXdK2js/n6tXCddb50tIhrbLc1q2R3HBGg5MqjVNUZzauJqGkU1rlQtfx9PenMFd0qFdq+xD9HjatVVHeuqGD2fYsnj6mGhXjPX4GGryu4fS3G0Vz7733ysaNGyUnJ0f++OMP6dy5s+O+mTNnypgxY1zW19IJv//+uxw5ckTWrVsnjz32mEuNWxwXHSPS4bXjN3zsd45sEVn6lMhv14lM7yEyOU0kY3xptRIAAMAgaIsy455zG0vnRlWkT6sTmXjnHw9OVHAqOfDspa0koVyM1Kjo+8ei/tDUH6SvXNXWsUx/eGomryepVZL8Ciy8dGVbqVbBPrnHnd1PMYHeN284TWokx0vtSgkSX4wf686nmg4+v6ncfFbDAsEhDeTc2q2RpFUtmLFXt3KiCWI+eH4zOadZdRnYtaHfr3l/r6ZS1uinVLl8XJFKU5zVpHiBn8Ry/v8ojosp+Nn/p29Lef269l4fo9vzVZ1S5bLT6vp87icubiFF1ad1balSPk7Ob1nTsZ140qNZDUlOdM3g7teuYOBQD6iMvKadyZDv2riaeW+n1vachedJzPHvV5t6rkHii9vWlucuOxHAdA/Qu3MOFLWp51/wXr9XpzUoPNjmfIDn7u6NXZade2rNIpc/0cDYuc1ryFmNq8nT/Vqaz8RSt1Ki2Z/oASj9bj/Uu5nZZ13avq7f26S+L2cnERv1Sj8D3cdpf0RHR3kMQBcm+iTa1axmRXn5yrbSs3lwgtXufyeS4mLNtu9OPzvdb+tBCfe/A9pvFk8HLfTviG4bwy7zfDDyZA8Epjh9v0+pUcFkvP/7glNNcPma0+tLtybVZMiFp5plztvWGY2qyhVeznqxntPffavu64BSkdpfpNs4kUTfB8BcZG0RmX0FgVsAAFCqCNqizDitfmW5/exTTEDWohm4+kP48Qube/zxaQVAruyop8IVpD9IdX0NLGnWXPm4GLnjnFOK3cbeLWuZINiLV7SR92/qJJ3SqphAb3xsjDx/aWt5tl+rImeUaXaVJep41qMGxNxpIEczovLyC07gVq9ykvlf3+OALmnSqu6JDMHCgoGn1Cjeadut6qaYQHJRAsT+0mCB9q9zMFsDXhYN4nvq5jNP8Rw80Odyb6cGMq/rXN9kKXujn7O+T0+ZcxrI0mxwzfrW/9VlbsE2fYwV5PGmTqVEs11d0LKW16CqBgo91Xp27wPnLD3NitRtS4OCV3eqb4JeT3sINDWoWt5sN69c2dYEl/U0fm/fpxFXtZOKCeVMhrweWND39nDvE0EeZ9q37n1hbevu35FL29U1mffe+sddcuKJ/vTWVov2bb/2dc336tZuDc2+4Nbj2aIPnOca8GxUvby8dm17s/31al7TBMo0s99ZLS/tdKZ9bjn31BpyfecG5j3r91SD4T1OreE4WKL7E+cDUJ4yNJ0D2hpc85Ul/b8bC06Aqdu488Er53ZaGfrOz6sHgJz3k/qZ6z7O4v756XZgce8v5zMQCqPfo/9e0aZAIF4fqgdp3Lcp99ueXO60f1X3nusaiPeVyayvqd8jqySEBuA1sO7+ni3lYjSgXUPaplYqkIF63vGAc/v6lVzOLNEDiQ9f0MylTz0FhIde3KLAgarh/VtL45oVxF+3dGto9hEDu7qWd6gQHys3dW0ojWtUlEbVK0j9qkmmlIluW7ed3cjc74v7fs8T/Tvu6bsMlGjg9oyPivAAHVvZRObfKZKbbS+ZQOkEAABQwij8iDJPgxj6A1gDLO5ZbpefVld6NKsuVSvES1Zunnz/d8HZgPXH8EPnN3NcL+4PRw1q9PWQfegpk6oonLOIG1RN8lkGQeXbTgRtn7y4hfy2bk+BrMhKSXHmB7oGWjo0qGyCy6//skYubF1b3p+d7pJxpVl7VSvESc6xfOnTqpYJno2avsbl+TTwu2jjflP7dPX2g2bZmadUlc6N7KfVfjj3xHO+ek07eeDLJY7bGuQYv2izrN912K/+0KCCeyCqUbXyJuCl72lnZo65/fv6PY77NciTWiVR+rWrazLDdDtZuT1TPpiTLs9deiJzTYMjY+ZuMNlw1mvMWLVTtu0/Yq73blVLpi3b7nhOzajWgJsGNk+tVVH+M3m547mcTxfW+ssauDiQfdSxbFCvJi51THWdrxdkmADi3DW7ZfehHJdAbGxMtAmqDhm/VHYdzCnweXqi2XLf/WXf5jXDWgP2t4z50xGsdOYpM1n1al7Dsf1qcFm3KbVu1yEpKn2NtvVSpG/buvLnhr0udZ6dA1XurICVtiH/+EEJzRrXbd1ThmFUYbUKj9PAsvMBEP0+eAsyaxBXg6nKefurnFRODuccc8mO1X7fduCIeU+rtmc6tm3dZjQLWQOxJ9rqqlxMdJHKC2iJGP1OapB37rrdJuvx5xU7XNbRgOyctbvl7Kb2DFgNjv+0coccyDrqCIa6b0OaSazt1It1gGT2mt3mfw06aqDynV/X2d+Dj+7W19Rt7fEJS83t+3o2lvfnpJvvqdYmH/b9Sq/PoW3Yn3XU7H90X2IFB3X535v3ez2QMmnJVrmodW2pdfwgxed/bPLaPt3n6cX6XhRGA/YtaidLz+Y1pHqFeLNt6japB6hqpyT4PCjnfN/tZzeSz37fJJv3ZZnAcccGlaV1vRRT+mfv4VzHegO6NDDbhDP3gLA+l/4NfKF/a/lm0Wb5cfkOc4BBt7UhfZrL4K+WOD5rX/SglrcDW84Bfg0QF+Xgo25b7w7oaPZp+nfG2p/e3eMUaVYrWWKjo4pVLgI4aTk7i/GYXSLj9GBI/ollWiNXSy5oINgXDe7umi2Svc0+IZrW19VyDQAAAF4QtEXYsDIenekPSw3YWqdoOgdtnfNRvf0A1UDIyJ9Xe7xPT2F1Dl5qpqtzFnBhNANq7Q7/Al+aWbU4Y7/JtrRY78udc/BLg4LeJjhy/nGuj7GCl85B28HnNTV9M7x/G7HZbCZwaGUvfr1gs0tg5uI29sCwFfzwlD2qn1Fygutp9lqnU09rXr9rvaPNG3YfdgRo61dJMpdvFp54PW+8BRw6NazsuE+zxKx13dc/tVayyRJ1dt+5TeTrhZtNZqVOuLNia6Zk7M2SMxvbA9IaNDyvRU3Jyj0RuPNE+855m2tSo6JLwFEDZ2c0qmICHBrwnrlqlyNgatHPQjMfP5m3UdbssAfHlX42nuhifT+LNu2Tc44H7CwVT3KyNvdvjAacCqNBpP/rYs/is8om6FfPV8C2pVPdWD2AYAVIrXqyh5wCpo62+RlPcs7K96ferid6oObNGetcgvRaD9SybMsBefWn1Y5AvbvaJ5ld2Pz4JFDa/9ZnoAHVb//aasqxKN2mrO+ndQaCbm97Duea9lnfAw0Az/xnp9fMVz2goNu/HvgoCit4am2TesZBbl6+2UdosFOzb/XAjTvNSvUUzPNVYkYPpDiXzNB9i5b3eGHqP7Ju5yHHgaJ3Z60vtP6wBvWVHtyxskGt9jhnP+vBBE8H+zTz/MlJy8w2615mRtvpvj1YNYuLwgpoW/sYzZq/6ni5Am9/1/S7t2F3lhw5WrzsQE/P67wP0slD3cv0aLBXv+fntaglH/+2wbzXDg2YtA5BpoHTYnEK2DqXTtCSC94Ct1pWYeEgkazNRQ/2hiqC0Chr2GYBlEEEbREx3LPvfP3w14Ds3qxcl0BUtQqumWgNq5/cbO+aXeQvzazydLqtBh8m/7VVBjrNVq71QPW0YOes3KLQrLhpy7eb57aC0PYSASfae0Gr2ibrMD9fJOdYnksgVn+wb9yT5VKCwZLkpe6iZidatB7mmONBW33FO4+fhu0raOspoKaBXkvV8p4D3P7QDLZ7epw4ZVrrOu44kGMyd4uT3emLle2oAR3nshjuffVon1Plt3W7HQF2z+HEE4FS56zau3s0NoFObxME3dClgSzYsFf+2XYiKOyJe6DVPRvQmQZYNdjX02niQM2M1om2CgucnlpIIEuzLzXrNi42SoZP+ccsS6ua5Mj49sUK4PtDt3VPNPA04qqKLiUZnHkrr6HlPDSL1HnbLwotXbBpb5bJXHanAUQNGJaPj/EZeNPtTAOjlutOr+8I2nrapvq2rWMu7rzVAbeCiu6vq8FF6wCQVZ/X/futwVFv2Zeasa11Vr+c7z2D1pkGVbWNVtBWA4YjrmrrMfjoXF1G96G6nerBGs3OL2o2qNZ4HnVte8k9ll+kxzrvzwrbq2jWsztfWbBaG1fv37QnSyYs3uLIWHY+o6M4tB3z1u0xZ1vo5KHenN2kmjSsWt5xQAEIKg3YaOBUg64+/5IWRh8bJbLwfpG6/QoGgTRgq0Fd99fwJ9h7MkGnkgxQhWMQuqwE95zbllDDvllp1niotTPUPr8tk4K/zYbydhUJ7Y/kPgv23w5fzxkqfRTCCNoiYjj/jtVA1i1nNfLrh7CeMq9Zj9d2stdH1JqWOUftgUo9rdWfDFCP7QlAkE+DD+7ZWfqD/GQm5NFJrzR7sLCsYauGpfvp6fqDvVvBhEKfASwNSGsmWpUKcVInJcGUKPCHngKsp557yvzreko1WbJpvwlGaNAlUPR9ewr2OR8E0OzBkqbZkVbQ1iqJoRN27T18VH5baz+N3RMth+GLZiXqxcqY9vYzVrMj9VT0f4/729zWkhTeDNKDIIdzCwSKixuwdGdl3TpndGumn25X7sEonRBQSzwcOZpfIOvbF+eyI56Cc940rVlRmtSsKHXcglQaDKzn/7xnBVilC4rTJm981W/2RAPD2UfzPJbn0HI1enbA+S1qObJ4d2YekVP8PNil9YV90ex2K2jr7WCQMz0IkhAbYyaz9B3YPPE5W5PvWRNLFldJnPqv+8t563f7VS/WmfW+dR+mmb6aaa1Z2Xqw7WRoeQctHWHVT/f1+kU5WAKUKP1RqAEbE1CNOvnAbVaGyI7pItFxJ358Vj3THijy+NyFBHst1g/azZNENnxmL9FQWNCpJIOq/gSh9f348yO8KD/ktS/3/Fb0H/ZFDXKeTN+VxPtxftzBNSJr3xPJ9vLbozifcUkEU0o7QFNYH8VVFck9UTbNQT/j2ZeLNNPv4MXet41AtDlQ21VJB+q9vVdP7U+sK9L4dpGKTQq2y3n79nVfcfcPgX5/J/Mc3t6rp20xvppI2g0i9foVf59WVEXZ9gpbtzj95+s5lft93vooIUjbfgggaIuIUSmxnPnxrBleOkGLvzX59JR5vThn9lm1FXUSIStoW9SAhwaaVm7LLHA6rnUqriU2uvRr/RWlzIM/tJzCL//sdJw2rp+DZp85c85q1omOlmTsL1B31Z3Wa8w6mudxIhzNrrMmUSoN+npWVp23+rDOijgfnV8ua2/vX19BW39pMD47N8/U6vVGg1k647tm0WqGtDf6nfOW2VuYOKcMXi2dsXzLgUK/a3pAxDpl3L2UidaV1dPyvZQB9srD/H5+0bZqZnRZ463khntgOEU8B4c1cO5csub/CqnTqzWXtRav7hf/dW4TvwKdGmhM333Y7C8Ko5+5HpAqTKNqFeTxi5qb8g1FCeqXFG9/p5zLYRRG6+Qu2rjP4z7H/XM6mXa61xoHygT9EapBRvcfjcU14wLXYGa5ZJGjrmM9j8HenTNFavX078duYYFSDe6uGuk9QNX6aZGWjxfvx6j+qPUZhBaReQNFylUUydYMZg8/wv0JAuXuKxigjooRseUV7Yd9UYOcXgPSPoJ71mv7Cqor9/fqz/vx9Jy++AqcewoQeco+9fUZ+BOkK2o/nGzgz58+8hSwdabfF/fvjK9+8BVs9RRg3fqdl++kl8+rKNtwcfqvKH2pz1/9LJFNYwu+tn7Hlz7luV3u27ev+/zd9n29V3+C7EUJXnoLzHpql6/36i5n94ntrTj7tMKC3u7b387ZIsuePsm/HcfXbf6QyMYv/AuwOu9jfO1Ti9pHzor6PfS1rRTloGgQRNn8+WWGEpGZmSkpKSly4MABSU4uei07FJ0G1DTeY52aGwiTlmyRvHybSx1LfxzLy5ff1+81p4nqZDwaANFajCN+XO2oH6l1SzVLMZDtDQUaaPns941mQiHNQnSn/bnz4BGplXxiYh8r81Mn53ri+GRYZc3RvHy585OF5vp7AzoWe3I6i9ZK1Uw5LWmg2bGWd2etk/npe+W/V7T1mY3pi9a71KCtPwHokvDj8u2ydMsBlwBe5pGj8sPSbSab21MNUWsbeeSCUwtkV+/PypW/Nx8wmZZWlrg/rOe899zG0r7+SaTGlhHW+3Xfpkqa7g9XbMs0mcmBPmjkD61Jrdu7t1rhpWnr/mx5cuIyc10n8CrqAUF3Wg5Fvzc66V5xJ9oMJ4y9PIv4fnHP1Fv1ukjuyR8A9Vu5yiKn3u8ajPAW6PEktoJITIL9x64/EuqKNPEQ/Cgs6LN3iciSh07qrfoMAhVXUYImrg+0/2cFLianFT14X+zXLsHn9LQ9uD+nt+zT4irtfiiJ1ysqDeIXdiDCH7HJBQ90BIK/fRQKfXmybfEVZNfAYtUz7PtUb/RgVvNHAxOYDYTiBL3jKvsO8Afib0dR2qz7mPwckWNFn7y6SJq5HUwr7ECH3/3l9PehhAK3/o69CNoGUcQPkOHyo1pPr9c6t9/+vc3UXzwtAgJERbF40z4zkdyt3Rq5TGxU1mhwSDNB3ctKFDfQte3AEbO9OGfk6W5dA9/hFuwvzNg/N8n2AzlyX8/GRZrd3pe1Ow+aSZt6Nq8RsOcMZRrcW7b1gAzq2bRETutH0YK2gTi4A1eMvTyjX9wcyxWZVM//DMdwFUrBnJIUX12k8yciszRTGigif4KCKAP0t1kE7O9QBFH2jNu+6SVSKoGgbRnAABkAAHgL2loThyFwGHt5Rr944DhVXvFzKfydbF1jAEBY6jlDpGb3oI29SKMBAAAAAE/1bpPcJ/zjQEp4ImALAPBASwQFERORAQAAhAjCBkCIBW7dJ3TKOyoy8/xgtwwAAJQG/dsfRARtAQAAQoRzCVtKIwAhQOvYOZ8WqZOWaY07nVGbwywAAIR3Tdvq3YLaCsojAAAAhIhayQnSLrWSdG1cLdhNAeAtiNvhteM3OLAClF18fwEUsn/oMLJEJiErCoK2AAAAIUKza//Vs4ncfFbDYDcFQFHr3UbF+BkgOolgUVw1kdgKEnHBL599WwYV9/0k1hNp/bTImZ+LnPuzSPdpInFVAt26sk37qP7VPrbVKJHmD3uoVw2/af9qPxdn+46k77L1fW12v0h8df8fF4nqXBxafZRUz/53Xv/eBxnlEQAAAADgZOvdVj1TZM9vIpsniWz4TCRnl+sPQM3YUQsHiWRtLtrr6Y/+ev3sp2lumSQy+4rjd3gp0ZCUenKv52+gtvlDIhu/cH1+DVQ0vk0kd1/BfvAVBNo1VyTb6Xn0B3za9fb37atv9Ye9Lc/z81ptqdhEJL6qyG/Xi+Ts9v89akA0JtG1XS6ruL22trlqZ5Gt3x3vIw+fjwZxmj/q//tx7gf9/N2zvjq/V/j2YHK18n2/3dhkkXIVRbK3FHztuMoia98LbD94+sx9PWdhr+feRxlXFdz2re+hfn/bDj/x/U2oYW9izk6Rg2sKvleX91NM+p1scI3IypePL/CzvIrzNlxYO/3tP1/r+frMrf2K9p+WivHUf877Ql/3FWXbL2z7K2m+tjdf79X5+9r+Zf//XhRl2w/09ufPehpg3fOH/2329ffC2zblbTva+p3IqpHe9ysno7B9bZBE2Ww2ijEFSWZmpqSkpMiBAwckOTk52M0BAAAIa4y9PKNfSoD7j0/nH4DO9xUWeHH+QessY3zBgJS3H5xFeT1nvn6E+/qhXZTX9vd5fPWtv0ETq98KDXCaN2//TzOtnIPzvoJTzq/n6fPx9ln6ej+++qEo24M+58oXRJY+5f979fVZBqofTjbwV9Rtxd9AjLfHeXo/3g6y1L3Y87bo6Tm8BWYLa3Nx+q8ofVnc/vNXUbZ9b+/VV5DdPbDo62CWv4HZ0u6HogS9/dmO/P3bUZTvbqEHLYuxn/clo5Dvoad+0GCvr/4qic81QGMvgrZBxAAZAACg9DD28ox+CTJfgRd/AzbFDUj5G8wpSrv8fe0g/Ej2+oPfPWDjLcAayu/Vn9crSjC5NNtVlljvp7DgVCT1SbB5609/DygV92BJsAX6oERpP39p/93MD63vHUHbMoABMgAAQOlh7OUZ/YKIEw4Bm+IKscBFmUZfAijhsRc1bQEAAAAAkUMDazW7uy5zvx1J7x3FQ18CKGFakRwAAAAAAAAAECII2gIAAAAAAABACCFoCwAAAAAAAAAhhKAtAAAAAAAAAIQQgrYAAAAAAAAAEEII2gIAAAAAAABACIkNdgMimc1mM/9nZmYGuykAAABhzxpzWWMw2DEmBQAACL0xKUHbIDp48KD5PzU1NdhNAQAAiKgxWEpKSrCbETIYkwIAAITemDTKRqpB0OTn58vWrVulYsWKEhUVVSqRfB2MZ2RkSHJycom/XllAn3hGvxREn3hGvxREn3hGvxREn5R+v+iwVwfHderUkehoqoQFY0zKdu8Z/VIQfeIZ/VIQfeIZ/VIQfVIQfRKcfvF3TEqmbRDpB1OvXr1Sf13d4PgyuqJPPKNfCqJPPKNfCqJPPKNfCqJPSrdfyLANjTEp271n9EtB9Iln9EtB9Iln9EtB9ElB9Enp94s/Y1JSDAAAAAAAAAAghBC0BQAAAAAAAIAQQtA2gsTHx8tTTz1l/ocdfeIZ/VIQfeIZ/VIQfeIZ/VIQfeIZ/RLe+Hw9o18Kok88o18Kok88o18Kok8Kok9Cu1+YiAwAAAAAAAAAQgiZtgAAAAAAAAAQQgjaAgAAAAAAAEAIIWgLAAAAAAAAACGEoG2EGD16tKSlpUlCQoJ07txZ5s+fL+Fi+PDh0qlTJ6lYsaLUqFFDLr30Ulm1apXLOkeOHJF77rlHqlatKhUqVJDLL79cduzY4bLOpk2b5KKLLpKkpCTzPA8//LAcO3bMZZ2ZM2fKaaedZopRN27cWMaMGSNlwQsvvCBRUVFy//33S6T3yZYtW+SGG24w7zsxMVFat24tCxYscNyvZb6HDh0qtWvXNvf36tVL1qxZ4/Ice/fuleuvv16Sk5OlUqVKcsstt8ihQ4dc1vn777+lW7du5juXmpoq//3vfyUU5eXlyZNPPikNGzY07/eUU06RZ5991vRDJPXJrFmz5JJLLpE6deqY78rEiRNd7i/NPvj666/l1FNPNevo9jllyhQJtT45evSo/Pvf/zbtK1++vFlnwIABsnXr1rDuE3+2FWd33nmnWWfkyJFh3S/+9MnKlSulb9++kpKSYrYZ/butf2Mi/W9SJArnMWlpjVnDWXHHrOEoEGPWcBKoMWtZV1pj1rKktMasZU1pjVnLklmlNGYNKJ2IDOHtyy+/tMXFxdk++OAD2/Lly2233XabrVKlSrYdO3bYwkHv3r1tH374oW3ZsmW2JUuW2C688EJb/fr1bYcOHXKsc+edd9pSU1Nt06dPty1YsMB2xhln2M4880zH/ceOHbO1atXK1qtXL9vixYttU6ZMsVWrVs02ZMgQxzrr16+3JSUl2QYPHmxbsWKF7fXXX7fFxMTYpk6dagtl8+fPt6WlpdnatGljGzRoUET3yd69e20NGjSw3XTTTbY//vjDtH/atGm2tWvXOtZ54YUXbCkpKbaJEyfa/vrrL1vfvn1tDRs2tGVnZzvWueCCC2xt27a1/f7777bZs2fbGjdubLv22msd9x84cMBWs2ZN2/XXX2+2yy+++MKWmJhoe+edd2yh5vnnn7dVrVrV9t1339nS09NtX3/9ta1ChQq21157LaL6RLfvxx9/3DZ+/Hgd+dsmTJjgcn9p9cHcuXPNd+i///2v+U498cQTtnLlytmWLl1qC6U+2b9/v9k3jB071vbPP//Y5s2bZzv99NNtHTp0cHmOcOsTf7YVi96v771OnTq2V199Naz7pbA+0X1slSpVbA8//LBt0aJF5vakSZNcxiGR+DcpEoX7mLQ0xqzhrLhj1nAUqDFrOAnUmLWsK40xa1lTGmPWsqg0xqxlzZRSGLMGGkHbCKA7pXvuucdxOy8vz3whhw8fbgtHO3fuNF/AX3/91bGj1h+y+ofdsnLlSrOO7rStL290dLRt+/btjnXeeustW3Jysi0nJ8fcfuSRR2wtW7Z0ea2rr77aDMBD1cGDB21NmjSx/fTTT7ZzzjnHMQCO1D7597//bTvrrLO83p+fn2+rVauW7aWXXnIs076Kj483QROlgQDtpz///NOxzg8//GCLioqybdmyxdx+8803bZUrV3b0k/XazZo1s4Waiy66yHbzzTe7LOvfv78JFkVqn7j/AS/NPrjqqqvMZ+Ksc+fOtjvuuMMWTL4Ges4/tnW9jRs3RkSf+OqXzZs32+rWrWsCM/qj23kAHO794qlP9O/CDTfc4PUxkfo3KRJF2pi0JMas4epkxqzhKBBj1nATiDFruCmpMWtZVlJj1rKupMasZZmU0Jg10CiPEOZyc3Nl4cKF5rQIS3R0tLk9b948CUcHDhww/1epUsX8r+9fT4tw7gM9nbR+/fqOPtD/9ZSJmjVrOtbp3bu3ZGZmyvLlyx3rOD+HtU4o96Om7euppO7tjtQ+mTx5snTs2FGuvPJKc1pi+/bt5b333nPcn56eLtu3b3d5T3pahJ6+6dwvemqIPo9F19fv1R9//OFY5+yzz5a4uDiXftFTIPft2yeh5Mwzz5Tp06fL6tWrze2//vpL5syZI3369InYPnFXmn1Q1r5T7vtePc1I+yGS+yQ/P1/+7//+z5y637JlywL3R1q/aH98//330rRpU9M+3ffqd8f5dLRI/ZsUaSJxTFoSY9ZwdTJj1nAUiDFruAnEmDXcBWrMGu6KM2YNR4EYs4aT/ACNWQONoG2Y2717t6n/4/wjR+lt3aGH4xdNa2B17dpVWrVqZZbp+9QfvtZO2VMf6P+e+si6z9c6+oMxOztbQs2XX34pixYtMvXT3EVqn6xfv17eeustadKkiUybNk3uuusuue++++Sjjz5yeV++vi/6v+7AncXGxpofXEXpu1Dx6KOPyjXXXGP+2JQrV878KNDvkNYuitQ+cVeafeBtnVDvI63tpPXCrr32WlPzKpL75MUXXzTvU/ctnkRav+zcudPUPtM6lRdccIH8+OOPctlll0n//v3l119/jei/SZEm0sakJTVmDUcnO2YNR4EYs4abQIxZw12gxqzhrLhj1nAUiDFrONkZoDFroMWWyLMCQTxKv2zZMnPUNZJlZGTIoEGD5KeffjITfeDEDyQ9Ujhs2DBzWwd7ur28/fbbcuONN0ok+uqrr+Szzz6Tzz//3BxhXbJkiRkAa3H2SO0TFI0ebb7qqqvMxBf6AzOS6dH31157zQQfNIMD9v2u6tevnzzwwAPmert27eS3334z+95zzjknyC0EgoMxqx1jVs8YsxbEmBUnizHrCYxZy86YlUzbMFetWjWJiYkpMJud3q5Vq5aEk3vvvVe+++47mTFjhtSrV8+xXN+nnpK3f/9+r32g/3vqI+s+X+voETqdmTPUdsJ6pEhn0NajYXrRo0OjRo0y1/VIUKT1idJZVFu0aOGyrHnz5o7ZIK335ev7ov9r3zrT2ct1Zs2i9F2o0NNhrMwFPfVYT5HRP1JWtksk9om70uwDb+uEah9Zg9+NGzeaH9xWxkKk9sns2bPNe9ZTpKx9r/bNgw8+KGlpaRHZLzoO0X4obN8biX+TIk0kjUlLcswabgIxZg1HgRizhptAjFnDXaDGrOHoZMes4SZQY9ZwUi1AY9ZAI2gb5jR1u0OHDqb+j/MRBL3dpUsXCQd6pEwHvxMmTJBffvlFGjZs6HK/vn89hca5D7QuoH7xrD7Q/5cuXeqyU7J25taXVtdxfg5rnVDsx549e5r3o0egrYserdfTh6zrkdYnSk9B1PfpTOtiNWjQwFzXbUd3ts7vSU+r1Zo9zv2iO2n9kWHR7U6/V1rzxlpn1qxZZnDg3C/NmjWTypUrSyjJysoydYmc6Y9q60hjJPaJu9Lsg7L0nbIGv2vWrJGff/5Zqlat6nJ/JPaJ/oD8+++/Xfa9mgGkPzT19NZI7Bcdh3Tq1MnnvjcS/05HokgYk5bGmDXcBGLMGo4CMWYNN4EYs4a7QI1Zw00gxqzhJlBj1nASF6Axa8CVyPRmCClffvmlmTFyzJgxZgbA22+/3VapUiWXGZjLsrvuusuWkpJimzlzpm3btm2OS1ZWlmOdO++801a/fn3bL7/8YluwYIGtS5cu5mI5duyYrVWrVrbzzz/ftmTJEtvUqVNt1atXtw0ZMsSxzvr1621JSUm2hx9+2MwQOHr0aFtMTIxZtyxwnok3UvtEZwqNjY21Pf/887Y1a9bYPvvsM9P+Tz/91LHOCy+8YL4fkyZNsv3999+2fv362Ro2bGjLzs52rHPBBRfY2rdvb/vjjz9sc+bMMbMdX3vttS6zStasWdP2f//3f2YmTv0O6uu88847tlBz4403mhlDv/vuO1t6erpt/PjxtmrVqplZ2COpT3TW6sWLF5uL/mkcMWKEuW7NKltafTB37lyzjb788svmO/XUU0+ZGUqXLl0aUn2Sm5tr69u3r61evXpm/+C8783JyQnbPvFnW3HnPhNvOPZLYX2i+xVt27vvvmv2va+//rr5WzF79uyI/psUicJ9TFoaY9ZIUNQxazgK1Jg1nARqzFrWlcaYtawpjTFrWVQaY9ay5mApjFkDjaBthNCNTTesuLg42+mnn277/fffbeFCv2yeLh9++KFjHf0jdffdd9sqV65sBjyXXXaZ2VE727Bhg61Pnz62xMREMwB48MEHbUePHnVZZ8aMGbZ27dqZfmzUqJHLa5S1AXCk9sm3335rfvjrj8ZTTz3V7JCd5efn25588kkTMNF1evbsaVu1apXLOnv27DF/rCpUqGBLTk62DRw40PwBcPbXX3/ZzjrrLPMcOsDUAVQoyszMNNuF7h8SEhLMZ/j444+7DGIioU90O/a0H9EfCKXdB1999ZWtadOm5jvVsmVL2/fff28LtT7RH0ve9r36uHDtE3+2FX8GwOHWL/70yfvvv29r3Lix2c+0bdvWNnHiRJfniNS/SZEonMekpTVmDXfFGbOGo0CMWcNJoMasZV1pjVnLktIas5Y1pTVmLUtmlNKYNZCi9J+SyeEFAAAAAAAAABQVNW0BAAAAAAAAIIQQtAUAAAAAAACAEELQFgAAAAAAAABCCEFbAAAAAAAAAAghBG0BAAAAAAAAIIQQtAUAAAAAAACAEELQFgAAAAAAAABCCEFbAAAAAAAAAAghBG0BAAAAAPCie/fucv/99ztup6WlyciRI30+JioqSiZOnHjSrx2o5ymJfigJ/vStJ//3f/8nw4YNK5E2oXRNnTpV2rVrJ/n5+cFuChB0BG0BIMLt2rVL7rrrLqlfv77Ex8dLrVq1pHfv3jJ37tyQ+7EAAADgr0suuUQuuOACj/fNnj3bjHH+/vvvIj/vn3/+KbfffrsE0n/+8x8TqHK3bds26dOnj5S03Nxc+e9//ytt27aVpKQkqVatmnTt2lU+/PBDOXr0qISyv/76S6ZMmSL33XeflFXa9g4dOpixuKftQOm22q1bN0lISJDU1FTzebn7+uuv5dRTTzXrtG7d2vRLcY0ZM0YqVaokpU2/s+XKlZPPPvus1F8bCDUEbQEgwl1++eWyePFi+eijj2T16tUyefJkk0mxZ8+eYDcNAACg2G655Rb56aefZPPmzQXu02Bkx44dpU2bNkV+3urVq5vAZmnQg+kayCvpgK0esH/hhRdMMPq3336T+fPnyz333COvv/66LF++XEKZtvHKK6+UChUqBLUd2o8n4+abb5arr77a432ZmZly/vnnS4MGDWThwoXy0ksvmUD/u+++61hHP7drr73WbPc6tr/00kvNZdmyZVLW3HTTTTJq1KhgNwMIOoK2ABDB9u/fbzJNXnzxRenRo4cZCJ5++ukyZMgQ6du3rzlFTV122WUmG8W6rSZNmiSnnXaaOZLfqFEjefrpp+XYsWOO+3X9t956y2SHJCYmmnXGjRsXlPcJAAAiz8UXX2wCrJox6OzQoUMmI1GDW3qQWgNddevWNYFYzU784osvinQK/5o1a+Tss882Y6IWLVqYQLG7f//739K0aVPzGjomevLJJx0ZrNo+HUdpxqiOn/Ritdn9jKelS5fKueeea8ZWVatWNUFWfT/OwS4N1L388stSu3Zts44GX31ly+p7mTVrlkyfPt2sq5me2sbrrrtO/vjjD2nSpIljXT1l/ZFHHpEqVaqYgLIGDt3Hlrfeeqvp9+TkZNNWfV/Ovv32W+nUqZPpL83o1XGmN//73/9Mtqe2zZO8vDwzvtSsamc5OTny0EMPmc+1fPny0rlzZ5k5c6YjAKr998MPP7g8ZsKECVKxYkXJysoytzMyMuSqq64yr6/vt1+/frJhw4YCff38889LnTp1pFmzZvLMM89Iq1atCrRT+1Q/c280QKl9r/3uiWadalD4gw8+kJYtW8o111xjsnNHjBjhWOe1114zWaoPP/ywNG/eXJ599lkzVn/jjTe8vq5+NvobQN+3fl6a7btgwQLTVwMHDpQDBw44tknrs/bVt84Zurrd6rajn7MeFND+LOx1Lfp56u1169Z5bTsQCQjaAkAE04wEveigSgdgnk7/s7JR9PQ867YGegcMGCCDBg2SFStWyDvvvGMGaDpodaaDU83k1YHZ9ddfbwaYK1euLKV3BwAAIllsbKwZr+gYxWazOZZrwFaDfRqsPXLkiAkYff/99yYjUYOgWh9VM039oUHM/v37S1xcnAlwvv322yZA606DU9oOHTdpcO29996TV1991dyn2ZUPPvigCcbpeEsvnjIuDx8+bIJflStXNmMyfR8///yz3HvvvS7rzZgxwwS79H89k0pf1z1w7R4Q7NWrl7Rv377AfXqaugbmLPp8elvfq56er0FK5yC1Zrzu3LnTBEQ1I1SDhj179pS9e/ea+7WfNUh74YUXmmxQDcZqwoAn+vyPPvqo/Pjjj+Y5vJUM0MCiZk070z6ZN2+efPnll2YdbZcGNDXArkFCDeh//vnnBfpBg7AaWNcgt/a1fm467tWyYTpm1udwzqjV9q9atcr0wXfffWeyZXWsa42Zlb5PbYMGQYtL34seGNDtzKLt09fet2+fYx39HJ3pOrrcGx2f16tXz7RXPy/tb/3MzzzzTBPM176ytkkN1BbWtxYNfOvvgo8//tj0nQbz9XdAYa9r0bJtNWvWNH0PRDQbACCijRs3zla5cmVbQkKC7cwzz7QNGTLE9tdffznu1z8VEyZMcHlMz549bcOGDXNZ9sknn9hq167t8rg777zTZZ3OnTvb7rrrrhJ7LwAAAM5WrlxpxiQzZsxwLOvWrZvthhtu8PqYiy66yPbggw86bp9zzjm2QYMGOW43aNDA9uqrr5rr06ZNs8XGxtq2bNniuP+HH37wOH5y9tJLL9k6dOjguP3UU0/Z2rZtW2A95+d59913zZjt0KFDjvu///57W3R0tG379u3m9o033mjad+zYMcc6V155pe3qq6/22pbExETbfffd5/V+534466yzXJZ16tTJ9u9//9tcnz17ti05Odl25MgRl3VOOeUU2zvvvGOud+nSxXb99dd7fQ2rbx955BEzrly2bJnPNmnfxMTE2PLz8x3LNm7caJY5fybW+FXHudbjKlSoYDt8+LC5feDAATMW1s/OGtc2a9bM5XlzcnJMX+lnbvV1zZo1zXJnffr0cRnv/utf/7J1797d5g9v28F5551nu/32212WLV++3GwfK1asMLfLlStn+/zzz13WGT16tK1GjRpeX69ixYq2MWPGeLzvww8/tKWkpLgs86dv9XHart9//73A9/CPP/4o9HUt7du3t/3nP//xuQ4Q7si0BYAIp5mwW7duNbVs9Si5nt6kWRG+MjI0c1YzK6xMXb3cdttt5ii8dUqZ6tKli8vj9DaZtgAAoLTopEyaNainlau1a9ea7D0tjaA041ZPI9eyCHoKvI5ppk2bJps2bfLr+XVco5NC6enx3sY/auzYsWZiLy0poK/xxBNP+P0azq+lE4U5Z77qc2q2r2ZcWjRjNyYmxnFbyyRo9qs3zlnIhXGvAez83Do+1FINWpLBeYyYnp7uOM19yZIlXrNmLa+88orJRJ4zZ455L75kZ2ebmr96+r5zCQn9XLUchXM7fv31V0c7NNNXMzt1/Ku++eYbk1VqZarqe9FtRTNtrcfr9qGZ2c6n7Ot245z9qnRMrCU2dF3NytWMXs3ADUWDBw825Sz0fWtN48LKEfjTt1aWu5bAcP4easkE63eAP6+rJSycf1cAkSg22A0AAASf1po677zzzEVLGugg6qmnnjK1ujzRAbnWXtPTAT09FwAAQKjQAO2//vUvGT16tCn5dMopp8g555xj7tMJnbRcgZ4KrgE4DYjef//9Jz2plDM9lVxPB9exk56unpKSYk4t1+BkSXA+zVxpQFMDu95oAO6ff/456efW8aEGcZ3rm1o0YGcF4grTrVs3U0bhq6++MqfN+6I1cTWwp5+XFTzVdmjQWk+7dw5eK2uyMl33iiuuMAFVPW1f/9eSFBpstJ5Dy2ZoyQR3Wq/X4hxAd67HqoFkrZGrr6OlFvS1ToYG+3fs2OGyzLqt9/lax7rfE61Tq7WLtb+1pIWO/3Xb9FZn2J++9Yc/r6slNZz7GohEZNoCAArQSTS0bpo1ONcj6s40E1czOho3blzgEh194k/L77//7vI4va0TIwAAAJQWnUxKxycamNMam5r1aGVmar1NnWDqhhtuMFmsOhHU6tWr/X5uHdfoBEt6tpG38c9vv/1mJnt9/PHHTe1VnZxp48aNLutocM99vOXptTQD1BqjWe3X96aTYBWXBs+0Nq7WXnWnAUfn1/NFx4fbt283gU/38aEGV61MXW+Tilm0xq0G8oYNG2YmVPNFJ/hSWivYorV5tS81A9i9Hc4BTA2kT506VZYvXy6//PKLue38XrRGa40aNQo8hwbdfdH3f+ONN5oDBHrRoLA/wWpfNHtbJ4tznlBO6+jq5641jq113PtW1/GU+e0etH/ggQdM7WBNyNA2e9sm/e1bnZzYeWIx/d2gdW2dfwd4e11lZTR7qrMMRBKCtgAQwXTGZJ3V99NPPzUTCejpazqphU78oD9grBmSdQCog3BrooOhQ4eaHz2aMaIDXT3VSY+O66l+zvS59HRE/fGjR9B1Ug/3yTIAAABKkmYAahblkCFDTHDV+UwiDaBqYEsDqzqeueOOOwpkK/qip3dr8EmDdBpQ1dILGpx1pq+hpRB0rKSBqFGjRpksTGc63tJxmJYP2L17t8cJYjWoqGc06WvppGk60ZhmEOvEaTppU3FpZrGWWdCyBZqNrO9j/fr1JtP1jDPOcJlgqrC+0AChTualgbgNGzaYftX+sAJ4Oh7U0gH6v/a3nm7/4osvFnguLWkxZcoUM9bULGhvNBNTA6xaSsGin4f2lU5CN378eNOvOgYdPny4yey06MReGmjUdRs2bCidO3d23KfLNNCs42H9TPU5NIP4vvvuk82bNxfaF3rWmgaCNSjsT2kELcWgn72Ot7Xkg17Xi5XxrYF1DaJq1riOvbXchmaIa5kBi04QrK+nGdyaOa3ZrNrv3sbe+jp6n74vPYigBwB0YjArsKrbpGbW6u8A3SY1o9nfvtWkD902dcI6zcrV75xuSxqQL+x1rQMfmq1cWMAZCHvBLqoLAAgenSji0UcftZ122mlmooGkpCQz6cITTzxhy8rKMutMnjzZ1rhxYzPJhk4OYZk6daqZuEwnZNBJJ04//XQzQYZF/8To5Ac6cUJ8fLwtLS3NNnbs2KC8TwAAENl+++03Mza58MILXZbv2bPH1q9fPzMplU7YpGOgAQMGmGX+TESmVq1aZSboiouLszVt2tSMkdwnInv44YdtVatWNa+jk4Lp450nedIx2eWXX26rVKmSeaxO5qTcn+fvv/+29ejRw0yaVaVKFdttt91mO3jwoON+nRzLue1K267vwRd9/eHDh9tat27teO6uXbuayaKOHj3qsR+Uvpa+piUzM9NMvFWnTh0zMVZqaqqZeGzTpk2Odb755htbu3btTH9Vq1bN1r9/f699++uvv9rKly9vGzVqlNe2v/nmm7YzzjjDZVlubq5t6NChZvyp7dBJzS677DLTf850wjPtY13X3bZt28y2oG3UsWyjRo1Mf+ukZd762plOeNeyZUubP7RvtR3ul/T0dMc6OlGwbmfalrp169peeOGFAs/z1VdfmW1Q+1ZfWyeq80YnULvmmmvMZ6Tr62d277332rKzsx3r6KTCut1qW3SSNH/61prATD9n7TNtb69evcwkZv6+rk66dscdd/jVd0A4i9J/gh04BgCEHz3tULNINNsCAAAAKAmauallAjT7NFQyMzXMohnWd999t0s2bCTQyYw1e1vLIRSHZvXq56lZwpoBDUQyJiIDAAAAAABlktaL1bJdGuwLBbt27TKlMLTUwcCBA4PdnDJHy2q8+eabBGwBgrYAAAAAAKAs6969u4QKnbxM6+G+++67jknC4D+drE8vAEQojwAAAAAAAAAAISQ62A0AAAAAAAAAAJxA0BYAAAAAAAAAQghBWwAAAAAAAAAIIQRtAQAAAAAAACCEELQFAAAAAAAAgBBC0BYAAAAAAAAAQghBWwAAAAAAAAAIIQRtAQAAAAAAACCEELQFAAAAAAAAAAkd/w+m2Ah56J/SpQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(lossi, alpha=0.7)\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].set_ylabel('Train Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].plot(val_lossi, 'o-', color='orange')\n",
    "axes[1].set_xlabel('Validation Check (every 100 steps)')\n",
    "axes[1].set_ylabel('Val Loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Final train loss: 0.4943\n",
      "Final val loss: 0.5197\n",
      "Checkpoint saved: /Users/djemec/data/jepa/v0_4/checkpoints/linear_decoder_ckpt_15884_final.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*60)\n",
    "print(f'Final train loss: {lossi[-1]:.4f}')\n",
    "print(f'Final val loss: {val_lossi[-1]:.4f}')\n",
    "print(f'Checkpoint saved: {checkpoint_dir / f\"linear_decoder_ckpt_{max_steps-1}_final.pt\"}')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
