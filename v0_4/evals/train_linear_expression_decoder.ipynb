{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Train Linear Expression Decoder\n",
    "\n",
    "Trains a linear probe decoder on frozen BioJEPA latent representations to predict expression deltas.\n",
    "\n",
    "The trained decoder is used by evaluation notebooks (eval_1, eval_2, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import biojepa_ac_v0_4 as model\n",
    "from bio_dataloader import TrainingLoader\n",
    "from linear_expression_decoder import BenchmarkDecoder, BenchmarkDecoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "n_genes = 5000\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "n_embd = 8\n",
    "pert_latent_dim = 320\n",
    "pert_mode_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_4')\n",
    "train_dir = data_dir / 'training'\n",
    "checkpoint_dir = data_dir / 'checkpoints'\n",
    "pert_dir = data_dir / 'pert_embd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Bank (DNA): torch.Size([1250, 1536])\n"
     ]
    }
   ],
   "source": [
    "input_bank = torch.from_numpy(np.load(pert_dir / 'input_embeddings_dna.npy')).float().to(DEVICE)\n",
    "print(f'Input Bank (DNA): {input_bank.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Load BioJEPA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "config = model.BioJepaConfig(\n",
    "    num_genes=n_genes,\n",
    "    n_layer=n_layers,\n",
    "    heads=n_heads,\n",
    "    embed_dim=n_embd,\n",
    "    n_pre_layer=n_layers,\n",
    "    pert_latent_dim=pert_latent_dim,\n",
    "    pert_mode_dim=pert_mode_dim\n",
    ")\n",
    "biojepa = model.BioJepa(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-checkpoint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_ckpt_31769_final.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "keys = biojepa.load_state_dict(checkpoint['model'])\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freeze-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "biojepa.freeze_encoders()\n",
    "biojepa.eval()\n",
    "for param in biojepa.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "data-loaders",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 11 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "found 2 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = TrainingLoader(batch_size=batch_size, split='train', data_dir=train_dir, device=DEVICE)\n",
    "val_loader = TrainingLoader(batch_size=batch_size, split='val', data_dir=train_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoder-header",
   "metadata": {},
   "source": [
    "## Initialize Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "init-decoder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder parameters: 9\n"
     ]
    }
   ],
   "source": [
    "decoder_config = BenchmarkDecoderConfig(embed_dim=n_embd)\n",
    "decoder = BenchmarkDecoder(decoder_config).to(DEVICE)\n",
    "print(f'Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 3177\n",
      "Total steps: 15885\n"
     ]
    }
   ],
   "source": [
    "lr_decoder = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "train_total_examples = 101682\n",
    "steps_per_epoch = train_total_examples // batch_size\n",
    "max_steps = epochs * steps_per_epoch\n",
    "\n",
    "print(f'Steps per epoch: {steps_per_epoch}')\n",
    "print(f'Total steps: {max_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-header",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "training-loop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1.8767\n",
      "Step 0 | Loss: 1.83220 | LR: 4.00e-05\n",
      "Step 25 | Loss: 1.89842 | LR: 4.25e-05\n",
      "Step 50 | Loss: 1.87045 | LR: 4.98e-05\n",
      "Step 75 | Loss: 1.86177 | LR: 6.16e-05\n",
      "val loss: 1.8115\n",
      "Step 100 | Loss: 1.78725 | LR: 7.79e-05\n",
      "Step 125 | Loss: 1.77972 | LR: 9.85e-05\n",
      "Step 150 | Loss: 1.76144 | LR: 1.23e-04\n",
      "Step 175 | Loss: 1.78028 | LR: 1.52e-04\n",
      "val loss: 1.7638\n",
      "Step 200 | Loss: 1.73949 | LR: 1.84e-04\n",
      "Step 225 | Loss: 1.72866 | LR: 2.20e-04\n",
      "Step 250 | Loss: 1.77460 | LR: 2.58e-04\n",
      "Step 275 | Loss: 1.63535 | LR: 2.99e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 1.5952\n",
      "Step 300 | Loss: 1.69372 | LR: 3.43e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 325 | Loss: 1.59931 | LR: 3.87e-04\n",
      "Step 350 | Loss: 1.51630 | LR: 4.34e-04\n",
      "Step 375 | Loss: 1.51397 | LR: 4.81e-04\n",
      "val loss: 1.3614\n",
      "Step 400 | Loss: 1.45552 | LR: 5.28e-04\n",
      "Step 425 | Loss: 1.35887 | LR: 5.76e-04\n",
      "Step 450 | Loss: 1.27029 | LR: 6.23e-04\n",
      "Step 475 | Loss: 1.23644 | LR: 6.68e-04\n",
      "val loss: 1.1619\n",
      "Step 500 | Loss: 1.23403 | LR: 7.13e-04\n",
      "Step 525 | Loss: 1.12980 | LR: 7.55e-04\n",
      "Step 550 | Loss: 1.07218 | LR: 7.96e-04\n",
      "Step 575 | Loss: 1.05646 | LR: 8.33e-04\n",
      "val loss: 0.9857\n",
      "Step 600 | Loss: 0.92603 | LR: 8.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 625 | Loss: 0.91578 | LR: 8.98e-04\n",
      "Step 650 | Loss: 0.87404 | LR: 9.26e-04\n",
      "Step 675 | Loss: 0.87123 | LR: 9.49e-04\n",
      "val loss: 0.7972\n",
      "Step 700 | Loss: 0.78899 | LR: 9.68e-04\n",
      "Step 725 | Loss: 0.76500 | LR: 9.83e-04\n",
      "Step 750 | Loss: 0.74791 | LR: 9.93e-04\n",
      "Step 775 | Loss: 0.73986 | LR: 9.99e-04\n",
      "val loss: 0.6875\n",
      "Step 800 | Loss: 0.64473 | LR: 1.00e-03\n",
      "Step 825 | Loss: 0.70520 | LR: 1.00e-03\n",
      "Step 850 | Loss: 0.64056 | LR: 1.00e-03\n",
      "Step 875 | Loss: 0.62902 | LR: 1.00e-03\n",
      "val loss: 0.6318\n",
      "Step 900 | Loss: 0.63776 | LR: 1.00e-03\n",
      "Step 925 | Loss: 0.60260 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 950 | Loss: 0.58945 | LR: 1.00e-03\n",
      "Step 975 | Loss: 0.59940 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "val loss: 0.5823\n",
      "Step 1000 | Loss: 0.60299 | LR: 1.00e-03\n",
      "Step 1025 | Loss: 0.56997 | LR: 9.99e-04\n",
      "Step 1050 | Loss: 0.55817 | LR: 9.99e-04\n",
      "Step 1075 | Loss: 0.55922 | LR: 9.99e-04\n",
      "val loss: 0.5656\n",
      "Step 1100 | Loss: 0.51037 | LR: 9.99e-04\n",
      "Step 1125 | Loss: 0.60695 | LR: 9.99e-04\n",
      "Step 1150 | Loss: 0.53420 | LR: 9.99e-04\n",
      "Step 1175 | Loss: 0.57069 | LR: 9.98e-04\n",
      "val loss: 0.5433\n",
      "Step 1200 | Loss: 0.54071 | LR: 9.98e-04\n",
      "Step 1225 | Loss: 0.55294 | LR: 9.98e-04\n",
      "Step 1250 | Loss: 0.52298 | LR: 9.98e-04\n",
      "Step 1275 | Loss: 0.54173 | LR: 9.97e-04\n",
      "val loss: 0.5447\n",
      "Step 1300 | Loss: 0.55958 | LR: 9.97e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 1325 | Loss: 0.50781 | LR: 9.97e-04\n",
      "Step 1350 | Loss: 0.50302 | LR: 9.97e-04\n",
      "Step 1375 | Loss: 0.54386 | LR: 9.96e-04\n",
      "val loss: 0.5284\n",
      "Step 1400 | Loss: 0.52633 | LR: 9.96e-04\n",
      "Step 1425 | Loss: 0.51275 | LR: 9.96e-04\n",
      "Step 1450 | Loss: 0.54379 | LR: 9.95e-04\n",
      "Step 1475 | Loss: 0.54929 | LR: 9.95e-04\n",
      "val loss: 0.5126\n",
      "Step 1500 | Loss: 0.56401 | LR: 9.95e-04\n",
      "Step 1525 | Loss: 0.51807 | LR: 9.94e-04\n",
      "Step 1550 | Loss: 0.51300 | LR: 9.94e-04\n",
      "Step 1575 | Loss: 0.53554 | LR: 9.93e-04\n",
      "val loss: 0.5160\n",
      "Step 1600 | Loss: 0.51144 | LR: 9.93e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 1625 | Loss: 0.53631 | LR: 9.93e-04\n",
      "Step 1650 | Loss: 0.49881 | LR: 9.92e-04\n",
      "Step 1675 | Loss: 0.50403 | LR: 9.92e-04\n",
      "val loss: 0.5219\n",
      "Step 1700 | Loss: 0.52698 | LR: 9.91e-04\n",
      "Step 1725 | Loss: 0.55789 | LR: 9.91e-04\n",
      "Step 1750 | Loss: 0.52836 | LR: 9.90e-04\n",
      "Step 1775 | Loss: 0.53694 | LR: 9.90e-04\n",
      "val loss: 0.5124\n",
      "Step 1800 | Loss: 0.51266 | LR: 9.89e-04\n",
      "Step 1825 | Loss: 0.51744 | LR: 9.88e-04\n",
      "Step 1850 | Loss: 0.53047 | LR: 9.88e-04\n",
      "Step 1875 | Loss: 0.49927 | LR: 9.87e-04\n",
      "val loss: 0.5128\n",
      "Step 1900 | Loss: 0.50982 | LR: 9.87e-04\n",
      "Step 1925 | Loss: 0.52884 | LR: 9.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 1950 | Loss: 0.49830 | LR: 9.86e-04\n",
      "Step 1975 | Loss: 0.49682 | LR: 9.85e-04\n",
      "val loss: 0.5161\n",
      "Step 2000 | Loss: 0.50514 | LR: 9.84e-04\n",
      "Step 2025 | Loss: 0.54010 | LR: 9.84e-04\n",
      "Step 2050 | Loss: 0.52518 | LR: 9.83e-04\n",
      "Step 2075 | Loss: 0.52034 | LR: 9.82e-04\n",
      "val loss: 0.5192\n",
      "Step 2100 | Loss: 0.53594 | LR: 9.82e-04\n",
      "Step 2125 | Loss: 0.52025 | LR: 9.81e-04\n",
      "Step 2150 | Loss: 0.50133 | LR: 9.80e-04\n",
      "Step 2175 | Loss: 0.52352 | LR: 9.79e-04\n",
      "val loss: 0.5153\n",
      "Step 2200 | Loss: 0.49974 | LR: 9.79e-04\n",
      "Step 2225 | Loss: 0.50511 | LR: 9.78e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 2250 | Loss: 0.51390 | LR: 9.77e-04\n",
      "Step 2275 | Loss: 0.51585 | LR: 9.76e-04\n",
      "val loss: 0.5240\n",
      "Step 2300 | Loss: 0.51123 | LR: 9.76e-04\n",
      "Step 2325 | Loss: 0.52592 | LR: 9.75e-04\n",
      "Step 2350 | Loss: 0.53008 | LR: 9.74e-04\n",
      "Step 2375 | Loss: 0.54132 | LR: 9.73e-04\n",
      "val loss: 0.5216\n",
      "Step 2400 | Loss: 0.54588 | LR: 9.72e-04\n",
      "Step 2425 | Loss: 0.49896 | LR: 9.71e-04\n",
      "Step 2450 | Loss: 0.51392 | LR: 9.71e-04\n",
      "Step 2475 | Loss: 0.51508 | LR: 9.70e-04\n",
      "val loss: 0.5161\n",
      "Step 2500 | Loss: 0.51767 | LR: 9.69e-04\n",
      "Step 2525 | Loss: 0.54719 | LR: 9.68e-04\n",
      "Step 2550 | Loss: 0.56371 | LR: 9.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 2575 | Loss: 0.52095 | LR: 9.66e-04\n",
      "val loss: 0.5141\n",
      "Step 2600 | Loss: 0.52337 | LR: 9.65e-04\n",
      "Step 2625 | Loss: 0.54011 | LR: 9.64e-04\n",
      "Step 2650 | Loss: 0.52448 | LR: 9.63e-04\n",
      "Step 2675 | Loss: 0.52512 | LR: 9.62e-04\n",
      "val loss: 0.5232\n",
      "Step 2700 | Loss: 0.51839 | LR: 9.61e-04\n",
      "Step 2725 | Loss: 0.52753 | LR: 9.60e-04\n",
      "Step 2750 | Loss: 0.51207 | LR: 9.59e-04\n",
      "Step 2775 | Loss: 0.51044 | LR: 9.58e-04\n",
      "val loss: 0.5127\n",
      "Step 2800 | Loss: 0.53702 | LR: 9.57e-04\n",
      "Step 2825 | Loss: 0.51559 | LR: 9.56e-04\n",
      "Step 2850 | Loss: 0.54864 | LR: 9.55e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 2875 | Loss: 0.50917 | LR: 9.54e-04\n",
      "val loss: 0.5203\n",
      "Step 2900 | Loss: 0.51202 | LR: 9.53e-04\n",
      "Step 2925 | Loss: 0.52053 | LR: 9.52e-04\n",
      "Step 2950 | Loss: 0.53771 | LR: 9.50e-04\n",
      "Step 2975 | Loss: 0.50038 | LR: 9.49e-04\n",
      "val loss: 0.5104\n",
      "Step 3000 | Loss: 0.49379 | LR: 9.48e-04\n",
      "Step 3025 | Loss: 0.52537 | LR: 9.47e-04\n",
      "Step 3050 | Loss: 0.52248 | LR: 9.46e-04\n",
      "Step 3075 | Loss: 0.52360 | LR: 9.45e-04\n",
      "val loss: 0.5196\n",
      "Step 3100 | Loss: 0.54405 | LR: 9.43e-04\n",
      "Step 3125 | Loss: 0.52054 | LR: 9.42e-04\n",
      "Step 3150 | Loss: 0.50034 | LR: 9.41e-04\n",
      "Step 3175 | Loss: 0.51971 | LR: 9.40e-04\n",
      "=== Epoch 1 Done. Avg Loss: 0.74114 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5192\n",
      "Step 3200 | Loss: 0.50159 | LR: 9.38e-04\n",
      "Step 3225 | Loss: 0.52273 | LR: 9.37e-04\n",
      "Step 3250 | Loss: 0.50388 | LR: 9.36e-04\n",
      "Step 3275 | Loss: 0.53318 | LR: 9.35e-04\n",
      "val loss: 0.5173\n",
      "Step 3300 | Loss: 0.52163 | LR: 9.33e-04\n",
      "Step 3325 | Loss: 0.53255 | LR: 9.32e-04\n",
      "Step 3350 | Loss: 0.50003 | LR: 9.31e-04\n",
      "Step 3375 | Loss: 0.49866 | LR: 9.29e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5197\n",
      "Step 3400 | Loss: 0.52856 | LR: 9.28e-04\n",
      "Step 3425 | Loss: 0.54780 | LR: 9.27e-04\n",
      "Step 3450 | Loss: 0.53069 | LR: 9.25e-04\n",
      "Step 3475 | Loss: 0.51888 | LR: 9.24e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5129\n",
      "Step 3500 | Loss: 0.54828 | LR: 9.23e-04\n",
      "Step 3525 | Loss: 0.51384 | LR: 9.21e-04\n",
      "Step 3550 | Loss: 0.51898 | LR: 9.20e-04\n",
      "Step 3575 | Loss: 0.51897 | LR: 9.18e-04\n",
      "val loss: 0.5190\n",
      "Step 3600 | Loss: 0.50818 | LR: 9.17e-04\n",
      "Step 3625 | Loss: 0.52947 | LR: 9.16e-04\n",
      "Step 3650 | Loss: 0.49871 | LR: 9.14e-04\n",
      "Step 3675 | Loss: 0.52229 | LR: 9.13e-04\n",
      "val loss: 0.5126\n",
      "Step 3700 | Loss: 0.49621 | LR: 9.11e-04\n",
      "Step 3725 | Loss: 0.50584 | LR: 9.10e-04\n",
      "Step 3750 | Loss: 0.52939 | LR: 9.08e-04\n",
      "Step 3775 | Loss: 0.52475 | LR: 9.07e-04\n",
      "val loss: 0.5158\n",
      "Step 3800 | Loss: 0.51154 | LR: 9.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 3825 | Loss: 0.51786 | LR: 9.04e-04\n",
      "Step 3850 | Loss: 0.51565 | LR: 9.02e-04\n",
      "Step 3875 | Loss: 0.50190 | LR: 9.01e-04\n",
      "val loss: 0.5299\n",
      "Step 3900 | Loss: 0.50394 | LR: 8.99e-04\n",
      "Step 3925 | Loss: 0.52465 | LR: 8.97e-04\n",
      "Step 3950 | Loss: 0.53563 | LR: 8.96e-04\n",
      "Step 3975 | Loss: 0.50192 | LR: 8.94e-04\n",
      "val loss: 0.5191\n",
      "Step 4000 | Loss: 0.51760 | LR: 8.93e-04\n",
      "Step 4025 | Loss: 0.52673 | LR: 8.91e-04\n",
      "Step 4050 | Loss: 0.53292 | LR: 8.89e-04\n",
      "Step 4075 | Loss: 0.52570 | LR: 8.88e-04\n",
      "val loss: 0.5171\n",
      "Step 4100 | Loss: 0.48992 | LR: 8.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 4125 | Loss: 0.53498 | LR: 8.84e-04\n",
      "Step 4150 | Loss: 0.55944 | LR: 8.83e-04\n",
      "Step 4175 | Loss: 0.51747 | LR: 8.81e-04\n",
      "val loss: 0.5191\n",
      "Step 4200 | Loss: 0.54925 | LR: 8.79e-04\n",
      "Step 4225 | Loss: 0.50946 | LR: 8.78e-04\n",
      "Step 4250 | Loss: 0.53613 | LR: 8.76e-04\n",
      "Step 4275 | Loss: 0.51254 | LR: 8.74e-04\n",
      "val loss: 0.5073\n",
      "Step 4300 | Loss: 0.52515 | LR: 8.73e-04\n",
      "Step 4325 | Loss: 0.52477 | LR: 8.71e-04\n",
      "Step 4350 | Loss: 0.54172 | LR: 8.69e-04\n",
      "Step 4375 | Loss: 0.49500 | LR: 8.67e-04\n",
      "val loss: 0.5076\n",
      "Step 4400 | Loss: 0.50438 | LR: 8.65e-04\n",
      "Step 4425 | Loss: 0.53891 | LR: 8.64e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 4450 | Loss: 0.55790 | LR: 8.62e-04\n",
      "Step 4475 | Loss: 0.52028 | LR: 8.60e-04\n",
      "val loss: 0.5194\n",
      "Step 4500 | Loss: 0.50430 | LR: 8.58e-04\n",
      "Step 4525 | Loss: 0.53315 | LR: 8.56e-04\n",
      "Step 4550 | Loss: 0.53429 | LR: 8.55e-04\n",
      "Step 4575 | Loss: 0.53625 | LR: 8.53e-04\n",
      "val loss: 0.5173\n",
      "Step 4600 | Loss: 0.52710 | LR: 8.51e-04\n",
      "Step 4625 | Loss: 0.51955 | LR: 8.49e-04\n",
      "Step 4650 | Loss: 0.50132 | LR: 8.47e-04\n",
      "Step 4675 | Loss: 0.52549 | LR: 8.45e-04\n",
      "val loss: 0.5175\n",
      "Step 4700 | Loss: 0.52145 | LR: 8.43e-04\n",
      "Step 4725 | Loss: 0.52076 | LR: 8.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 4750 | Loss: 0.49097 | LR: 8.40e-04\n",
      "Step 4775 | Loss: 0.49752 | LR: 8.38e-04\n",
      "val loss: 0.5164\n",
      "Step 4800 | Loss: 0.52740 | LR: 8.36e-04\n",
      "Step 4825 | Loss: 0.51534 | LR: 8.34e-04\n",
      "Step 4850 | Loss: 0.51364 | LR: 8.32e-04\n",
      "Step 4875 | Loss: 0.50932 | LR: 8.30e-04\n",
      "val loss: 0.5075\n",
      "Step 4900 | Loss: 0.54643 | LR: 8.28e-04\n",
      "Step 4925 | Loss: 0.49940 | LR: 8.26e-04\n",
      "Step 4950 | Loss: 0.52966 | LR: 8.24e-04\n",
      "Step 4975 | Loss: 0.52942 | LR: 8.22e-04\n",
      "val loss: 0.5100\n",
      "Step 5000 | Loss: 0.52298 | LR: 8.20e-04\n",
      "Step 5025 | Loss: 0.53138 | LR: 8.18e-04\n",
      "Step 5050 | Loss: 0.51860 | LR: 8.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 5075 | Loss: 0.49936 | LR: 8.14e-04\n",
      "val loss: 0.5166\n",
      "Step 5100 | Loss: 0.48827 | LR: 8.12e-04\n",
      "Step 5125 | Loss: 0.53378 | LR: 8.10e-04\n",
      "Step 5150 | Loss: 0.49451 | LR: 8.08e-04\n",
      "Step 5175 | Loss: 0.52207 | LR: 8.06e-04\n",
      "val loss: 0.5187\n",
      "Step 5200 | Loss: 0.55789 | LR: 8.04e-04\n",
      "Step 5225 | Loss: 0.50525 | LR: 8.02e-04\n",
      "Step 5250 | Loss: 0.50669 | LR: 8.00e-04\n",
      "Step 5275 | Loss: 0.53910 | LR: 7.98e-04\n",
      "val loss: 0.5143\n",
      "Step 5300 | Loss: 0.51204 | LR: 7.96e-04\n",
      "Step 5325 | Loss: 0.52773 | LR: 7.93e-04\n",
      "Step 5350 | Loss: 0.53489 | LR: 7.91e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 5375 | Loss: 0.51025 | LR: 7.89e-04\n",
      "val loss: 0.5193\n",
      "Step 5400 | Loss: 0.53408 | LR: 7.87e-04\n",
      "Step 5425 | Loss: 0.51067 | LR: 7.85e-04\n",
      "Step 5450 | Loss: 0.52877 | LR: 7.83e-04\n",
      "Step 5475 | Loss: 0.52714 | LR: 7.81e-04\n",
      "val loss: 0.5143\n",
      "Step 5500 | Loss: 0.49064 | LR: 7.78e-04\n",
      "Step 5525 | Loss: 0.56475 | LR: 7.76e-04\n",
      "Step 5550 | Loss: 0.50379 | LR: 7.74e-04\n",
      "Step 5575 | Loss: 0.50324 | LR: 7.72e-04\n",
      "val loss: 0.5169\n",
      "Step 5600 | Loss: 0.50832 | LR: 7.70e-04\n",
      "Step 5625 | Loss: 0.55023 | LR: 7.68e-04\n",
      "Step 5650 | Loss: 0.51353 | LR: 7.65e-04\n",
      "Step 5675 | Loss: 0.52834 | LR: 7.63e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "val loss: 0.5124\n",
      "Step 5700 | Loss: 0.51676 | LR: 7.61e-04\n",
      "Step 5725 | Loss: 0.54038 | LR: 7.59e-04\n",
      "Step 5750 | Loss: 0.49396 | LR: 7.57e-04\n",
      "Step 5775 | Loss: 0.52096 | LR: 7.54e-04\n",
      "val loss: 0.5215\n",
      "Step 5800 | Loss: 0.50668 | LR: 7.52e-04\n",
      "Step 5825 | Loss: 0.52245 | LR: 7.50e-04\n",
      "Step 5850 | Loss: 0.51875 | LR: 7.48e-04\n",
      "Step 5875 | Loss: 0.53352 | LR: 7.45e-04\n",
      "val loss: 0.5167\n",
      "Step 5900 | Loss: 0.52464 | LR: 7.43e-04\n",
      "Step 5925 | Loss: 0.55160 | LR: 7.41e-04\n",
      "Step 5950 | Loss: 0.50438 | LR: 7.38e-04\n",
      "Step 5975 | Loss: 0.52392 | LR: 7.36e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.5174\n",
      "Step 6000 | Loss: 0.51631 | LR: 7.34e-04\n",
      "Step 6025 | Loss: 0.52551 | LR: 7.32e-04\n",
      "Step 6050 | Loss: 0.51703 | LR: 7.29e-04\n",
      "Step 6075 | Loss: 0.52623 | LR: 7.27e-04\n",
      "val loss: 0.5118\n",
      "Step 6100 | Loss: 0.53957 | LR: 7.25e-04\n",
      "Step 6125 | Loss: 0.51601 | LR: 7.22e-04\n",
      "Step 6150 | Loss: 0.51717 | LR: 7.20e-04\n",
      "Step 6175 | Loss: 0.51960 | LR: 7.18e-04\n",
      "val loss: 0.5188\n",
      "Step 6200 | Loss: 0.50597 | LR: 7.15e-04\n",
      "Step 6225 | Loss: 0.51914 | LR: 7.13e-04\n",
      "Step 6250 | Loss: 0.48898 | LR: 7.11e-04\n",
      "Step 6275 | Loss: 0.54767 | LR: 7.08e-04\n",
      "val loss: 0.5275\n",
      "Step 6300 | Loss: 0.49681 | LR: 7.06e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6325 | Loss: 0.52150 | LR: 7.03e-04\n",
      "Step 6350 | Loss: 0.50322 | LR: 7.01e-04\n",
      "=== Epoch 2 Done. Avg Loss: 0.52038 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 6375 | Loss: 0.52036 | LR: 6.99e-04\n",
      "val loss: 0.5165\n",
      "Step 6400 | Loss: 0.51162 | LR: 6.96e-04\n",
      "Step 6425 | Loss: 0.50528 | LR: 6.94e-04\n",
      "Step 6450 | Loss: 0.54555 | LR: 6.91e-04\n",
      "Step 6475 | Loss: 0.52786 | LR: 6.89e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5161\n",
      "Step 6500 | Loss: 0.53491 | LR: 6.87e-04\n",
      "Step 6525 | Loss: 0.51131 | LR: 6.84e-04\n",
      "Step 6550 | Loss: 0.54240 | LR: 6.82e-04\n",
      "Step 6575 | Loss: 0.49961 | LR: 6.79e-04\n",
      "val loss: 0.5275\n",
      "Step 6600 | Loss: 0.50584 | LR: 6.77e-04\n",
      "Step 6625 | Loss: 0.52019 | LR: 6.75e-04\n",
      "Step 6650 | Loss: 0.51030 | LR: 6.72e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6675 | Loss: 0.52979 | LR: 6.70e-04\n",
      "val loss: 0.5139\n",
      "Step 6700 | Loss: 0.49704 | LR: 6.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 6725 | Loss: 0.49883 | LR: 6.65e-04\n",
      "Step 6750 | Loss: 0.53625 | LR: 6.62e-04\n",
      "Step 6775 | Loss: 0.51787 | LR: 6.60e-04\n",
      "val loss: 0.5222\n",
      "Step 6800 | Loss: 0.53372 | LR: 6.57e-04\n",
      "Step 6825 | Loss: 0.52170 | LR: 6.55e-04\n",
      "Step 6850 | Loss: 0.57433 | LR: 6.52e-04\n",
      "Step 6875 | Loss: 0.49871 | LR: 6.50e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5146\n",
      "Step 6900 | Loss: 0.55596 | LR: 6.47e-04\n",
      "Step 6925 | Loss: 0.52672 | LR: 6.45e-04\n",
      "Step 6950 | Loss: 0.52032 | LR: 6.42e-04\n",
      "Step 6975 | Loss: 0.49731 | LR: 6.40e-04\n",
      "val loss: 0.5120\n",
      "Step 7000 | Loss: 0.52458 | LR: 6.37e-04\n",
      "Step 7025 | Loss: 0.55169 | LR: 6.35e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 7050 | Loss: 0.50803 | LR: 6.32e-04\n",
      "Step 7075 | Loss: 0.50993 | LR: 6.30e-04\n",
      "val loss: 0.5202\n",
      "Step 7100 | Loss: 0.52293 | LR: 6.27e-04\n",
      "Step 7125 | Loss: 0.54148 | LR: 6.25e-04\n",
      "Step 7150 | Loss: 0.52207 | LR: 6.22e-04\n",
      "Step 7175 | Loss: 0.52149 | LR: 6.20e-04\n",
      "val loss: 0.5205\n",
      "Step 7200 | Loss: 0.53062 | LR: 6.17e-04\n",
      "Step 7225 | Loss: 0.53163 | LR: 6.15e-04\n",
      "Step 7250 | Loss: 0.48062 | LR: 6.12e-04\n",
      "Step 7275 | Loss: 0.52342 | LR: 6.10e-04\n",
      "val loss: 0.5181\n",
      "Step 7300 | Loss: 0.50130 | LR: 6.07e-04\n",
      "Step 7325 | Loss: 0.50672 | LR: 6.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 7350 | Loss: 0.54056 | LR: 6.02e-04\n",
      "Step 7375 | Loss: 0.50413 | LR: 6.00e-04\n",
      "val loss: 0.5204\n",
      "Step 7400 | Loss: 0.51698 | LR: 5.97e-04\n",
      "Step 7425 | Loss: 0.52307 | LR: 5.94e-04\n",
      "Step 7450 | Loss: 0.49327 | LR: 5.92e-04\n",
      "Step 7475 | Loss: 0.52080 | LR: 5.89e-04\n",
      "val loss: 0.5228\n",
      "Step 7500 | Loss: 0.53944 | LR: 5.87e-04\n",
      "Step 7525 | Loss: 0.49813 | LR: 5.84e-04\n",
      "Step 7550 | Loss: 0.51482 | LR: 5.82e-04\n",
      "Step 7575 | Loss: 0.53932 | LR: 5.79e-04\n",
      "val loss: 0.5167\n",
      "Step 7600 | Loss: 0.50794 | LR: 5.76e-04\n",
      "Step 7625 | Loss: 0.51458 | LR: 5.74e-04\n",
      "Step 7650 | Loss: 0.51783 | LR: 5.71e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 7675 | Loss: 0.51743 | LR: 5.69e-04\n",
      "val loss: 0.5107\n",
      "Step 7700 | Loss: 0.51706 | LR: 5.66e-04\n",
      "Step 7725 | Loss: 0.52167 | LR: 5.64e-04\n",
      "Step 7750 | Loss: 0.48226 | LR: 5.61e-04\n",
      "Step 7775 | Loss: 0.53267 | LR: 5.58e-04\n",
      "val loss: 0.5093\n",
      "Step 7800 | Loss: 0.51547 | LR: 5.56e-04\n",
      "Step 7825 | Loss: 0.50035 | LR: 5.53e-04\n",
      "Step 7850 | Loss: 0.49869 | LR: 5.51e-04\n",
      "Step 7875 | Loss: 0.51165 | LR: 5.48e-04\n",
      "val loss: 0.5094\n",
      "Step 7900 | Loss: 0.50968 | LR: 5.45e-04\n",
      "Step 7925 | Loss: 0.48832 | LR: 5.43e-04\n",
      "Step 7950 | Loss: 0.48901 | LR: 5.40e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 7975 | Loss: 0.55017 | LR: 5.38e-04\n",
      "val loss: 0.5264\n",
      "Step 8000 | Loss: 0.52529 | LR: 5.35e-04\n",
      "Step 8025 | Loss: 0.52213 | LR: 5.33e-04\n",
      "Step 8050 | Loss: 0.51426 | LR: 5.30e-04\n",
      "Step 8075 | Loss: 0.49899 | LR: 5.27e-04\n",
      "val loss: 0.5266\n",
      "Step 8100 | Loss: 0.50283 | LR: 5.25e-04\n",
      "Step 8125 | Loss: 0.50586 | LR: 5.22e-04\n",
      "Step 8150 | Loss: 0.50424 | LR: 5.20e-04\n",
      "Step 8175 | Loss: 0.51816 | LR: 5.17e-04\n",
      "val loss: 0.5157\n",
      "Step 8200 | Loss: 0.50139 | LR: 5.14e-04\n",
      "Step 8225 | Loss: 0.48138 | LR: 5.12e-04\n",
      "Step 8250 | Loss: 0.53286 | LR: 5.09e-04\n",
      "Step 8275 | Loss: 0.51383 | LR: 5.07e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.5228\n",
      "Step 8300 | Loss: 0.55120 | LR: 5.04e-04\n",
      "Step 8325 | Loss: 0.51587 | LR: 5.01e-04\n",
      "Step 8350 | Loss: 0.53486 | LR: 4.99e-04\n",
      "Step 8375 | Loss: 0.51688 | LR: 4.96e-04\n",
      "val loss: 0.5132\n",
      "Step 8400 | Loss: 0.52122 | LR: 4.94e-04\n",
      "Step 8425 | Loss: 0.50690 | LR: 4.91e-04\n",
      "Step 8450 | Loss: 0.51126 | LR: 4.88e-04\n",
      "Step 8475 | Loss: 0.51106 | LR: 4.86e-04\n",
      "val loss: 0.5177\n",
      "Step 8500 | Loss: 0.52972 | LR: 4.83e-04\n",
      "Step 8525 | Loss: 0.50250 | LR: 4.81e-04\n",
      "Step 8550 | Loss: 0.50193 | LR: 4.78e-04\n",
      "Step 8575 | Loss: 0.55490 | LR: 4.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "val loss: 0.5135\n",
      "Step 8600 | Loss: 0.51651 | LR: 4.73e-04\n",
      "Step 8625 | Loss: 0.54444 | LR: 4.70e-04\n",
      "Step 8650 | Loss: 0.53846 | LR: 4.68e-04\n",
      "Step 8675 | Loss: 0.56210 | LR: 4.65e-04\n",
      "val loss: 0.5182\n",
      "Step 8700 | Loss: 0.50609 | LR: 4.62e-04\n",
      "Step 8725 | Loss: 0.55545 | LR: 4.60e-04\n",
      "Step 8750 | Loss: 0.50084 | LR: 4.57e-04\n",
      "Step 8775 | Loss: 0.50152 | LR: 4.55e-04\n",
      "val loss: 0.5183\n",
      "Step 8800 | Loss: 0.54721 | LR: 4.52e-04\n",
      "Step 8825 | Loss: 0.53048 | LR: 4.49e-04\n",
      "Step 8850 | Loss: 0.52766 | LR: 4.47e-04\n",
      "Step 8875 | Loss: 0.53596 | LR: 4.44e-04\n",
      "val loss: 0.5106\n",
      "Step 8900 | Loss: 0.50560 | LR: 4.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 8925 | Loss: 0.53746 | LR: 4.39e-04\n",
      "Step 8950 | Loss: 0.52597 | LR: 4.36e-04\n",
      "Step 8975 | Loss: 0.51870 | LR: 4.34e-04\n",
      "val loss: 0.5133\n",
      "Step 9000 | Loss: 0.53969 | LR: 4.31e-04\n",
      "Step 9025 | Loss: 0.52855 | LR: 4.29e-04\n",
      "Step 9050 | Loss: 0.53889 | LR: 4.26e-04\n",
      "Step 9075 | Loss: 0.51587 | LR: 4.24e-04\n",
      "val loss: 0.5192\n",
      "Step 9100 | Loss: 0.50072 | LR: 4.21e-04\n",
      "Step 9125 | Loss: 0.53097 | LR: 4.18e-04\n",
      "Step 9150 | Loss: 0.53529 | LR: 4.16e-04\n",
      "Step 9175 | Loss: 0.51931 | LR: 4.13e-04\n",
      "val loss: 0.5068\n",
      "Step 9200 | Loss: 0.51484 | LR: 4.11e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 9225 | Loss: 0.50162 | LR: 4.08e-04\n",
      "Step 9250 | Loss: 0.51312 | LR: 4.06e-04\n",
      "Step 9275 | Loss: 0.54145 | LR: 4.03e-04\n",
      "val loss: 0.5131\n",
      "Step 9300 | Loss: 0.53020 | LR: 4.00e-04\n",
      "Step 9325 | Loss: 0.54615 | LR: 3.98e-04\n",
      "Step 9350 | Loss: 0.52254 | LR: 3.95e-04\n",
      "Step 9375 | Loss: 0.54194 | LR: 3.93e-04\n",
      "val loss: 0.5142\n",
      "Step 9400 | Loss: 0.52943 | LR: 3.90e-04\n",
      "Step 9425 | Loss: 0.48320 | LR: 3.88e-04\n",
      "Step 9450 | Loss: 0.49969 | LR: 3.85e-04\n",
      "Step 9475 | Loss: 0.53046 | LR: 3.83e-04\n",
      "val loss: 0.5258\n",
      "Step 9500 | Loss: 0.52228 | LR: 3.80e-04\n",
      "Step 9525 | Loss: 0.50117 | LR: 3.78e-04\n",
      "=== Epoch 3 Done. Avg Loss: 0.52033 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 9550 | Loss: 0.53463 | LR: 3.75e-04\n",
      "Step 9575 | Loss: 0.50634 | LR: 3.73e-04\n",
      "val loss: 0.5095\n",
      "Step 9600 | Loss: 0.54591 | LR: 3.70e-04\n",
      "Step 9625 | Loss: 0.51257 | LR: 3.68e-04\n",
      "Step 9650 | Loss: 0.52172 | LR: 3.65e-04\n",
      "Step 9675 | Loss: 0.53109 | LR: 3.63e-04\n",
      "val loss: 0.5197\n",
      "Step 9700 | Loss: 0.51465 | LR: 3.60e-04\n",
      "Step 9725 | Loss: 0.52719 | LR: 3.58e-04\n",
      "Step 9750 | Loss: 0.48507 | LR: 3.55e-04\n",
      "Step 9775 | Loss: 0.53046 | LR: 3.53e-04\n",
      "val loss: 0.5109\n",
      "Step 9800 | Loss: 0.49092 | LR: 3.50e-04\n",
      "Step 9825 | Loss: 0.50582 | LR: 3.48e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 9850 | Loss: 0.50369 | LR: 3.45e-04\n",
      "Step 9875 | Loss: 0.52220 | LR: 3.43e-04\n",
      "val loss: 0.5154\n",
      "Step 9900 | Loss: 0.52930 | LR: 3.40e-04\n",
      "Step 9925 | Loss: 0.51311 | LR: 3.38e-04\n",
      "Step 9950 | Loss: 0.52326 | LR: 3.35e-04\n",
      "Step 9975 | Loss: 0.51147 | LR: 3.33e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5201\n",
      "Step 10000 | Loss: 0.54133 | LR: 3.30e-04\n",
      "Step 10025 | Loss: 0.51627 | LR: 3.28e-04\n",
      "Step 10050 | Loss: 0.50362 | LR: 3.26e-04\n",
      "Step 10075 | Loss: 0.51759 | LR: 3.23e-04\n",
      "val loss: 0.5241\n",
      "Step 10100 | Loss: 0.53826 | LR: 3.21e-04\n",
      "Step 10125 | Loss: 0.49146 | LR: 3.18e-04\n",
      "Step 10150 | Loss: 0.52438 | LR: 3.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 10175 | Loss: 0.47728 | LR: 3.13e-04\n",
      "val loss: 0.5155\n",
      "Step 10200 | Loss: 0.52086 | LR: 3.11e-04\n",
      "Step 10225 | Loss: 0.54482 | LR: 3.09e-04\n",
      "Step 10250 | Loss: 0.49804 | LR: 3.06e-04\n",
      "Step 10275 | Loss: 0.52416 | LR: 3.04e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5239\n",
      "Step 10300 | Loss: 0.53193 | LR: 3.01e-04\n",
      "Step 10325 | Loss: 0.53096 | LR: 2.99e-04\n",
      "Step 10350 | Loss: 0.49644 | LR: 2.97e-04\n",
      "Step 10375 | Loss: 0.52305 | LR: 2.94e-04\n",
      "val loss: 0.5236\n",
      "Step 10400 | Loss: 0.52107 | LR: 2.92e-04\n",
      "Step 10425 | Loss: 0.51146 | LR: 2.90e-04\n",
      "Step 10450 | Loss: 0.52567 | LR: 2.87e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 10475 | Loss: 0.54001 | LR: 2.85e-04\n",
      "val loss: 0.5197\n",
      "Step 10500 | Loss: 0.50827 | LR: 2.82e-04\n",
      "Step 10525 | Loss: 0.55741 | LR: 2.80e-04\n",
      "Step 10550 | Loss: 0.51448 | LR: 2.78e-04\n",
      "Step 10575 | Loss: 0.49757 | LR: 2.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5172\n",
      "Step 10600 | Loss: 0.53198 | LR: 2.73e-04\n",
      "Step 10625 | Loss: 0.52198 | LR: 2.71e-04\n",
      "Step 10650 | Loss: 0.51684 | LR: 2.68e-04\n",
      "Step 10675 | Loss: 0.53549 | LR: 2.66e-04\n",
      "val loss: 0.5206\n",
      "Step 10700 | Loss: 0.54092 | LR: 2.64e-04\n",
      "Step 10725 | Loss: 0.52106 | LR: 2.62e-04\n",
      "Step 10750 | Loss: 0.52683 | LR: 2.59e-04\n",
      "Step 10775 | Loss: 0.51369 | LR: 2.57e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "val loss: 0.5220\n",
      "Step 10800 | Loss: 0.51328 | LR: 2.55e-04\n",
      "Step 10825 | Loss: 0.53592 | LR: 2.53e-04\n",
      "Step 10850 | Loss: 0.51303 | LR: 2.50e-04\n",
      "Step 10875 | Loss: 0.52660 | LR: 2.48e-04\n",
      "val loss: 0.5159\n",
      "Step 10900 | Loss: 0.51575 | LR: 2.46e-04\n",
      "Step 10925 | Loss: 0.51278 | LR: 2.44e-04\n",
      "Step 10950 | Loss: 0.50242 | LR: 2.41e-04\n",
      "Step 10975 | Loss: 0.51983 | LR: 2.39e-04\n",
      "val loss: 0.5148\n",
      "Step 11000 | Loss: 0.50134 | LR: 2.37e-04\n",
      "Step 11025 | Loss: 0.52042 | LR: 2.35e-04\n",
      "Step 11050 | Loss: 0.50043 | LR: 2.32e-04\n",
      "Step 11075 | Loss: 0.52575 | LR: 2.30e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "val loss: 0.5064\n",
      "Step 11100 | Loss: 0.50379 | LR: 2.28e-04\n",
      "Step 11125 | Loss: 0.52951 | LR: 2.26e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 11150 | Loss: 0.55569 | LR: 2.24e-04\n",
      "Step 11175 | Loss: 0.53798 | LR: 2.22e-04\n",
      "val loss: 0.5201\n",
      "Step 11200 | Loss: 0.51375 | LR: 2.19e-04\n",
      "Step 11225 | Loss: 0.53693 | LR: 2.17e-04\n",
      "Step 11250 | Loss: 0.52476 | LR: 2.15e-04\n",
      "Step 11275 | Loss: 0.52885 | LR: 2.13e-04\n",
      "val loss: 0.5121\n",
      "Step 11300 | Loss: 0.53584 | LR: 2.11e-04\n",
      "Step 11325 | Loss: 0.53579 | LR: 2.09e-04\n",
      "Step 11350 | Loss: 0.50820 | LR: 2.07e-04\n",
      "Step 11375 | Loss: 0.53335 | LR: 2.04e-04\n",
      "val loss: 0.5166\n",
      "Step 11400 | Loss: 0.51864 | LR: 2.02e-04\n",
      "Step 11425 | Loss: 0.51173 | LR: 2.00e-04\n",
      "Step 11450 | Loss: 0.51136 | LR: 1.98e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 11475 | Loss: 0.50404 | LR: 1.96e-04\n",
      "val loss: 0.5132\n",
      "Step 11500 | Loss: 0.51946 | LR: 1.94e-04\n",
      "Step 11525 | Loss: 0.51086 | LR: 1.92e-04\n",
      "Step 11550 | Loss: 0.51700 | LR: 1.90e-04\n",
      "Step 11575 | Loss: 0.50393 | LR: 1.88e-04\n",
      "val loss: 0.5172\n",
      "Step 11600 | Loss: 0.51728 | LR: 1.86e-04\n",
      "Step 11625 | Loss: 0.51215 | LR: 1.84e-04\n",
      "Step 11650 | Loss: 0.55095 | LR: 1.82e-04\n",
      "Step 11675 | Loss: 0.55626 | LR: 1.80e-04\n",
      "val loss: 0.5252\n",
      "Step 11700 | Loss: 0.53742 | LR: 1.78e-04\n",
      "Step 11725 | Loss: 0.51894 | LR: 1.76e-04\n",
      "Step 11750 | Loss: 0.51688 | LR: 1.74e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 11775 | Loss: 0.52594 | LR: 1.72e-04\n",
      "val loss: 0.5234\n",
      "Step 11800 | Loss: 0.54509 | LR: 1.70e-04\n",
      "Step 11825 | Loss: 0.53321 | LR: 1.68e-04\n",
      "Step 11850 | Loss: 0.53479 | LR: 1.66e-04\n",
      "Step 11875 | Loss: 0.53106 | LR: 1.64e-04\n",
      "val loss: 0.5173\n",
      "Step 11900 | Loss: 0.49576 | LR: 1.62e-04\n",
      "Step 11925 | Loss: 0.50461 | LR: 1.60e-04\n",
      "Step 11950 | Loss: 0.52265 | LR: 1.58e-04\n",
      "Step 11975 | Loss: 0.51224 | LR: 1.57e-04\n",
      "val loss: 0.5125\n",
      "Step 12000 | Loss: 0.53251 | LR: 1.55e-04\n",
      "Step 12025 | Loss: 0.52468 | LR: 1.53e-04\n",
      "Step 12050 | Loss: 0.49916 | LR: 1.51e-04\n",
      "Step 12075 | Loss: 0.50905 | LR: 1.49e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5228\n",
      "Step 12100 | Loss: 0.51952 | LR: 1.47e-04\n",
      "Step 12125 | Loss: 0.53109 | LR: 1.45e-04\n",
      "Step 12150 | Loss: 0.52322 | LR: 1.44e-04\n",
      "Step 12175 | Loss: 0.50417 | LR: 1.42e-04\n",
      "val loss: 0.5061\n",
      "Step 12200 | Loss: 0.51834 | LR: 1.40e-04\n",
      "Step 12225 | Loss: 0.53767 | LR: 1.38e-04\n",
      "Step 12250 | Loss: 0.50485 | LR: 1.36e-04\n",
      "Step 12275 | Loss: 0.50502 | LR: 1.35e-04\n",
      "val loss: 0.5153\n",
      "Step 12300 | Loss: 0.54372 | LR: 1.33e-04\n",
      "Step 12325 | Loss: 0.50916 | LR: 1.31e-04\n",
      "Step 12350 | Loss: 0.52462 | LR: 1.29e-04\n",
      "Step 12375 | Loss: 0.52027 | LR: 1.28e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5122\n",
      "Step 12400 | Loss: 0.53481 | LR: 1.26e-04\n",
      "Step 12425 | Loss: 0.50362 | LR: 1.24e-04\n",
      "Step 12450 | Loss: 0.52146 | LR: 1.22e-04\n",
      "Step 12475 | Loss: 0.50821 | LR: 1.21e-04\n",
      "val loss: 0.5197\n",
      "Step 12500 | Loss: 0.49275 | LR: 1.19e-04\n",
      "Step 12525 | Loss: 0.52159 | LR: 1.17e-04\n",
      "Step 12550 | Loss: 0.53572 | LR: 1.16e-04\n",
      "Step 12575 | Loss: 0.51993 | LR: 1.14e-04\n",
      "val loss: 0.5150\n",
      "Step 12600 | Loss: 0.53141 | LR: 1.12e-04\n",
      "Step 12625 | Loss: 0.52539 | LR: 1.11e-04\n",
      "Step 12650 | Loss: 0.50936 | LR: 1.09e-04\n",
      "Step 12675 | Loss: 0.51664 | LR: 1.07e-04\n",
      "val loss: 0.5203\n",
      "Step 12700 | Loss: 0.54957 | LR: 1.06e-04\n",
      "=== Epoch 4 Done. Avg Loss: 0.52031 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 12725 | Loss: 0.51757 | LR: 1.04e-04\n",
      "Step 12750 | Loss: 0.51914 | LR: 1.03e-04\n",
      "Step 12775 | Loss: 0.52608 | LR: 1.01e-04\n",
      "val loss: 0.5167\n",
      "Step 12800 | Loss: 0.53628 | LR: 9.95e-05\n",
      "Step 12825 | Loss: 0.52017 | LR: 9.79e-05\n",
      "Step 12850 | Loss: 0.52666 | LR: 9.64e-05\n",
      "Step 12875 | Loss: 0.54836 | LR: 9.49e-05\n",
      "val loss: 0.5176\n",
      "Step 12900 | Loss: 0.54182 | LR: 9.34e-05\n",
      "Step 12925 | Loss: 0.51795 | LR: 9.18e-05\n",
      "Step 12950 | Loss: 0.48412 | LR: 9.03e-05\n",
      "Step 12975 | Loss: 0.51009 | LR: 8.89e-05\n",
      "val loss: 0.5080\n",
      "Step 13000 | Loss: 0.53276 | LR: 8.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 13025 | Loss: 0.52762 | LR: 8.59e-05\n",
      "Step 13050 | Loss: 0.47832 | LR: 8.45e-05\n",
      "Step 13075 | Loss: 0.53078 | LR: 8.30e-05\n",
      "val loss: 0.5185\n",
      "Step 13100 | Loss: 0.51403 | LR: 8.16e-05\n",
      "Step 13125 | Loss: 0.54168 | LR: 8.02e-05\n",
      "Step 13150 | Loss: 0.51322 | LR: 7.88e-05\n",
      "Step 13175 | Loss: 0.51607 | LR: 7.74e-05\n",
      "val loss: 0.5155\n",
      "Step 13200 | Loss: 0.52072 | LR: 7.60e-05\n",
      "Step 13225 | Loss: 0.51978 | LR: 7.46e-05\n",
      "Step 13250 | Loss: 0.50995 | LR: 7.33e-05\n",
      "Step 13275 | Loss: 0.51561 | LR: 7.19e-05\n",
      "val loss: 0.5164\n",
      "Step 13300 | Loss: 0.50842 | LR: 7.06e-05\n",
      "Step 13325 | Loss: 0.51888 | LR: 6.92e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 13350 | Loss: 0.53490 | LR: 6.79e-05\n",
      "Step 13375 | Loss: 0.51492 | LR: 6.66e-05\n",
      "val loss: 0.5133\n",
      "Step 13400 | Loss: 0.52474 | LR: 6.53e-05\n",
      "Step 13425 | Loss: 0.50806 | LR: 6.40e-05\n",
      "Step 13450 | Loss: 0.53592 | LR: 6.28e-05\n",
      "Step 13475 | Loss: 0.50881 | LR: 6.15e-05\n",
      "val loss: 0.5165\n",
      "Step 13500 | Loss: 0.54441 | LR: 6.03e-05\n",
      "Step 13525 | Loss: 0.50795 | LR: 5.90e-05\n",
      "Step 13550 | Loss: 0.49596 | LR: 5.78e-05\n",
      "Step 13575 | Loss: 0.54104 | LR: 5.66e-05\n",
      "val loss: 0.5197\n",
      "Step 13600 | Loss: 0.49745 | LR: 5.54e-05\n",
      "Step 13625 | Loss: 0.53657 | LR: 5.42e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 13650 | Loss: 0.52459 | LR: 5.31e-05\n",
      "Step 13675 | Loss: 0.50916 | LR: 5.19e-05\n",
      "val loss: 0.5172\n",
      "Step 13700 | Loss: 0.49974 | LR: 5.08e-05\n",
      "Step 13725 | Loss: 0.50996 | LR: 4.96e-05\n",
      "Step 13750 | Loss: 0.50410 | LR: 4.85e-05\n",
      "Step 13775 | Loss: 0.50800 | LR: 4.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5182\n",
      "Step 13800 | Loss: 0.52617 | LR: 4.63e-05\n",
      "Step 13825 | Loss: 0.52911 | LR: 4.52e-05\n",
      "Step 13850 | Loss: 0.52365 | LR: 4.41e-05\n",
      "Step 13875 | Loss: 0.54827 | LR: 4.31e-05\n",
      "val loss: 0.5326\n",
      "Step 13900 | Loss: 0.52975 | LR: 4.20e-05\n",
      "Step 13925 | Loss: 0.52629 | LR: 4.10e-05\n",
      "Step 13950 | Loss: 0.53049 | LR: 3.99e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 13975 | Loss: 0.51190 | LR: 3.89e-05\n",
      "val loss: 0.5122\n",
      "Step 14000 | Loss: 0.47888 | LR: 3.79e-05\n",
      "Step 14025 | Loss: 0.52277 | LR: 3.69e-05\n",
      "Step 14050 | Loss: 0.51466 | LR: 3.60e-05\n",
      "Step 14075 | Loss: 0.50443 | LR: 3.50e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5119\n",
      "Step 14100 | Loss: 0.51536 | LR: 3.41e-05\n",
      "Step 14125 | Loss: 0.55690 | LR: 3.31e-05\n",
      "Step 14150 | Loss: 0.52265 | LR: 3.22e-05\n",
      "Step 14175 | Loss: 0.50019 | LR: 3.13e-05\n",
      "val loss: 0.5185\n",
      "Step 14200 | Loss: 0.51237 | LR: 3.04e-05\n",
      "Step 14225 | Loss: 0.52103 | LR: 2.95e-05\n",
      "Step 14250 | Loss: 0.51526 | LR: 2.86e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 14275 | Loss: 0.50923 | LR: 2.78e-05\n",
      "val loss: 0.5123\n",
      "Step 14300 | Loss: 0.50706 | LR: 2.69e-05\n",
      "Step 14325 | Loss: 0.53626 | LR: 2.61e-05\n",
      "Step 14350 | Loss: 0.51343 | LR: 2.53e-05\n",
      "Step 14375 | Loss: 0.50552 | LR: 2.44e-05\n",
      "val loss: 0.5157\n",
      "Step 14400 | Loss: 0.50298 | LR: 2.36e-05\n",
      "Step 14425 | Loss: 0.50590 | LR: 2.29e-05\n",
      "Step 14450 | Loss: 0.53625 | LR: 2.21e-05\n",
      "Step 14475 | Loss: 0.52233 | LR: 2.13e-05\n",
      "val loss: 0.5184\n",
      "Step 14500 | Loss: 0.51445 | LR: 2.06e-05\n",
      "Step 14525 | Loss: 0.52072 | LR: 1.99e-05\n",
      "Step 14550 | Loss: 0.53561 | LR: 1.91e-05\n",
      "Step 14575 | Loss: 0.53331 | LR: 1.84e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5123\n",
      "Step 14600 | Loss: 0.51724 | LR: 1.77e-05\n",
      "Step 14625 | Loss: 0.53058 | LR: 1.71e-05\n",
      "Step 14650 | Loss: 0.52588 | LR: 1.64e-05\n",
      "Step 14675 | Loss: 0.50767 | LR: 1.57e-05\n",
      "val loss: 0.5132\n",
      "Step 14700 | Loss: 0.49568 | LR: 1.51e-05\n",
      "Step 14725 | Loss: 0.51723 | LR: 1.45e-05\n",
      "Step 14750 | Loss: 0.51922 | LR: 1.38e-05\n",
      "Step 14775 | Loss: 0.51140 | LR: 1.32e-05\n",
      "val loss: 0.5205\n",
      "Step 14800 | Loss: 0.54857 | LR: 1.27e-05\n",
      "Step 14825 | Loss: 0.51480 | LR: 1.21e-05\n",
      "Step 14850 | Loss: 0.51453 | LR: 1.15e-05\n",
      "Step 14875 | Loss: 0.51015 | LR: 1.10e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5059\n",
      "Step 14900 | Loss: 0.51336 | LR: 1.04e-05\n",
      "Step 14925 | Loss: 0.51001 | LR: 9.91e-06\n",
      "Step 14950 | Loss: 0.50900 | LR: 9.41e-06\n",
      "Step 14975 | Loss: 0.51007 | LR: 8.91e-06\n",
      "val loss: 0.5154\n",
      "Step 15000 | Loss: 0.50417 | LR: 8.43e-06\n",
      "Step 15025 | Loss: 0.51835 | LR: 7.96e-06\n",
      "Step 15050 | Loss: 0.53257 | LR: 7.50e-06\n",
      "Step 15075 | Loss: 0.48906 | LR: 7.06e-06\n",
      "val loss: 0.5129\n",
      "Step 15100 | Loss: 0.52852 | LR: 6.63e-06\n",
      "Step 15125 | Loss: 0.48593 | LR: 6.22e-06\n",
      "Step 15150 | Loss: 0.51060 | LR: 5.81e-06\n",
      "Step 15175 | Loss: 0.53583 | LR: 5.43e-06\n",
      "val loss: 0.5167\n",
      "Step 15200 | Loss: 0.50457 | LR: 5.05e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 15225 | Loss: 0.52786 | LR: 4.69e-06\n",
      "Step 15250 | Loss: 0.50590 | LR: 4.34e-06\n",
      "Step 15275 | Loss: 0.53659 | LR: 4.00e-06\n",
      "val loss: 0.5182\n",
      "Step 15300 | Loss: 0.49960 | LR: 3.68e-06\n",
      "Step 15325 | Loss: 0.52557 | LR: 3.37e-06\n",
      "Step 15350 | Loss: 0.50705 | LR: 3.08e-06\n",
      "Step 15375 | Loss: 0.51249 | LR: 2.80e-06\n",
      "val loss: 0.5132\n",
      "Step 15400 | Loss: 0.51055 | LR: 2.53e-06\n",
      "Step 15425 | Loss: 0.52434 | LR: 2.28e-06\n",
      "Step 15450 | Loss: 0.50256 | LR: 2.03e-06\n",
      "Step 15475 | Loss: 0.51196 | LR: 1.81e-06\n",
      "val loss: 0.5243\n",
      "Step 15500 | Loss: 0.51345 | LR: 1.59e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 15525 | Loss: 0.51427 | LR: 1.39e-06\n",
      "Step 15550 | Loss: 0.52352 | LR: 1.20e-06\n",
      "Step 15575 | Loss: 0.52986 | LR: 1.03e-06\n",
      "val loss: 0.5228\n",
      "Step 15600 | Loss: 0.52118 | LR: 8.71e-07\n",
      "Step 15625 | Loss: 0.52699 | LR: 7.25e-07\n",
      "Step 15650 | Loss: 0.49664 | LR: 5.92e-07\n",
      "Step 15675 | Loss: 0.52227 | LR: 4.73e-07\n",
      "val loss: 0.5144\n",
      "Step 15700 | Loss: 0.51168 | LR: 3.67e-07\n",
      "Step 15725 | Loss: 0.52275 | LR: 2.74e-07\n",
      "Step 15750 | Loss: 0.51726 | LR: 1.96e-07\n",
      "Step 15775 | Loss: 0.52948 | LR: 1.30e-07\n",
      "val loss: 0.5266\n",
      "Step 15800 | Loss: 0.53992 | LR: 7.86e-08\n",
      "Step 15825 | Loss: 0.50365 | LR: 4.04e-08\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 15850 | Loss: 0.49279 | LR: 1.58e-08\n",
      "Step 15875 | Loss: 0.52432 | LR: 4.69e-09\n",
      "val loss: 0.5129\n",
      "=== Epoch 5 Done. Avg Loss: 0.52032 ===\n",
      "Saved final checkpoint: linear_decoder_ckpt_15884_final.pt\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "val_lossi = []\n",
    "total_epoch_loss = 0\n",
    "\n",
    "decoder.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    if step % 100 == 0 or last_step:\n",
    "        biojepa.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 10\n",
    "            for i in range(val_loss_steps):\n",
    "                xc, xct, xt, xtt, p_idx, p_mod, p_mode = val_loader.next_batch()\n",
    "                p_feats = input_bank[p_idx]\n",
    "                B, N = xc.shape\n",
    "\n",
    "                action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "                z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "                target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "                z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "                pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "                real_delta = xt - xc\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_accum / val_loss_steps\n",
    "            val_lossi.append(avg_val_loss)\n",
    "            print(f'val loss: {avg_val_loss:.4f}')\n",
    "        decoder.train()\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0 and not last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    xc, xct, xt, xtt, p_idx, p_mod, p_mode = train_loader.next_batch()\n",
    "    p_feats = input_bank[p_idx]\n",
    "    B, N = xc.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "        action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "    real_delta = xt - xc\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f'Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0:\n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f'=== Epoch {(step + 1) // steps_per_epoch} Done. Avg Loss: {avg_loss:.5f} ===')\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "    if last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}_final.pt')\n",
    "        print(f'Saved final checkpoint: linear_decoder_ckpt_{step}_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-header",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loss-plot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(lossi, alpha=0.7)\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].set_ylabel('Train Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].plot(val_lossi, 'o-', color='orange')\n",
    "axes[1].set_xlabel('Validation Check (every 100 steps)')\n",
    "axes[1].set_ylabel('Val Loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Final train loss: 0.5295\n",
      "Final val loss: 0.5129\n",
      "Checkpoint saved: /Users/djemec/data/jepa/v0_4/checkpoints/linear_decoder_ckpt_15884_final.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*60)\n",
    "print(f'Final train loss: {lossi[-1]:.4f}')\n",
    "print(f'Final val loss: {val_lossi[-1]:.4f}')\n",
    "print(f'Checkpoint saved: {checkpoint_dir / f\"linear_decoder_ckpt_{max_steps-1}_final.pt\"}')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
