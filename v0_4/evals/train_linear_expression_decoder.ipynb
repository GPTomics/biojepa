{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# Train Linear Expression Decoder\n",
    "\n",
    "Trains a linear probe decoder on frozen BioJEPA latent representations to predict expression deltas.\n",
    "\n",
    "The trained decoder is used by evaluation notebooks (eval_1, eval_2, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-header",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import biojepa_ac_v0_4 as model\n",
    "from bio_dataloader import TrainingLoader\n",
    "from linear_expression_decoder import BenchmarkDecoder, BenchmarkDecoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "device",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cpu\n"
     ]
    }
   ],
   "source": [
    "random.seed(1337)\n",
    "\n",
    "def get_device():\n",
    "    device = 'cpu'\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(1337)\n",
    "        device = 'cuda'\n",
    "    print(f'using {device}')\n",
    "    return device\n",
    "\n",
    "DEVICE = get_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "n_genes = 5000\n",
    "n_layers = 2\n",
    "n_heads = 2\n",
    "n_embd = 8\n",
    "pert_latent_dim = 320\n",
    "pert_mode_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "paths",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('/Users/djemec/data/jepa/v0_4')\n",
    "train_dir = data_dir / 'training'\n",
    "checkpoint_dir = data_dir / 'checkpoints'\n",
    "pert_dir = data_dir / 'pert_embd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "load-banks",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Bank (DNA): torch.Size([1250, 1536])\n"
     ]
    }
   ],
   "source": [
    "input_bank = torch.from_numpy(np.load(pert_dir / 'input_embeddings_dna.npy')).float().to(DEVICE)\n",
    "print(f'Input Bank (DNA): {input_bank.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-header",
   "metadata": {},
   "source": [
    "## Load BioJEPA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "load-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision('high')\n",
    "config = model.BioJepaConfig(\n",
    "    num_genes=n_genes,\n",
    "    n_layer=n_layers,\n",
    "    heads=n_heads,\n",
    "    embed_dim=n_embd,\n",
    "    n_pre_layer=n_layers,\n",
    "    pert_latent_dim=pert_latent_dim,\n",
    "    pert_mode_dim=pert_mode_dim\n",
    ")\n",
    "biojepa = model.BioJepa(config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "load-checkpoint",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = checkpoint_dir / 'bio_jepa_ckpt_31769_final.pt'\n",
    "checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "keys = biojepa.load_state_dict(checkpoint['model'])\n",
    "print(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "freeze-model",
   "metadata": {},
   "outputs": [],
   "source": [
    "biojepa.freeze_encoders()\n",
    "biojepa.eval()\n",
    "for param in biojepa.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "data-loaders",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 11 shards for split train\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "found 2 shards for split val\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n"
     ]
    }
   ],
   "source": [
    "train_loader = TrainingLoader(batch_size=batch_size, split='train', data_dir=train_dir, device=DEVICE)\n",
    "val_loader = TrainingLoader(batch_size=batch_size, split='val', data_dir=train_dir, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decoder-header",
   "metadata": {},
   "source": [
    "## Initialize Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "init-decoder",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoder parameters: 9\n"
     ]
    }
   ],
   "source": [
    "decoder_config = BenchmarkDecoderConfig(embed_dim=n_embd)\n",
    "decoder = BenchmarkDecoder(decoder_config).to(DEVICE)\n",
    "print(f'Decoder parameters: {sum(p.numel() for p in decoder.parameters()):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "training-header",
   "metadata": {},
   "source": [
    "## Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "training-config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps per epoch: 3177\n",
      "Total steps: 15885\n"
     ]
    }
   ],
   "source": [
    "lr_decoder = 1e-3\n",
    "epochs = 5\n",
    "\n",
    "train_total_examples = 101682\n",
    "steps_per_epoch = train_total_examples // batch_size\n",
    "max_steps = epochs * steps_per_epoch\n",
    "\n",
    "print(f'Steps per epoch: {steps_per_epoch}')\n",
    "print(f'Total steps: {max_steps}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "optimizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(decoder.parameters(), lr=lr_decoder)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer, max_lr=lr_decoder, total_steps=max_steps, pct_start=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loop-header",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "training-loop",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val loss: 1.8555\n",
      "Step 0 | Loss: 1.89278 | LR: 4.00e-05\n",
      "Step 25 | Loss: 1.79177 | LR: 4.25e-05\n",
      "Step 50 | Loss: 1.86588 | LR: 4.98e-05\n",
      "Step 75 | Loss: 1.79897 | LR: 6.16e-05\n",
      "val loss: 1.8376\n",
      "Step 100 | Loss: 1.84502 | LR: 7.79e-05\n",
      "Step 125 | Loss: 1.92127 | LR: 9.85e-05\n",
      "Step 150 | Loss: 1.70680 | LR: 1.23e-04\n",
      "Step 175 | Loss: 1.79189 | LR: 1.52e-04\n",
      "val loss: 1.7551\n",
      "Step 200 | Loss: 1.80717 | LR: 1.84e-04\n",
      "Step 225 | Loss: 1.65935 | LR: 2.20e-04\n",
      "Step 250 | Loss: 1.66024 | LR: 2.58e-04\n",
      "Step 275 | Loss: 1.66801 | LR: 2.99e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 1.6124\n",
      "Step 300 | Loss: 1.53538 | LR: 3.43e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 325 | Loss: 1.61353 | LR: 3.87e-04\n",
      "Step 350 | Loss: 1.49305 | LR: 4.34e-04\n",
      "Step 375 | Loss: 1.37580 | LR: 4.81e-04\n",
      "val loss: 1.3930\n",
      "Step 400 | Loss: 1.31996 | LR: 5.28e-04\n",
      "Step 425 | Loss: 1.36543 | LR: 5.76e-04\n",
      "Step 450 | Loss: 1.38582 | LR: 6.23e-04\n",
      "Step 475 | Loss: 1.28316 | LR: 6.68e-04\n",
      "val loss: 1.1580\n",
      "Step 500 | Loss: 1.12726 | LR: 7.13e-04\n",
      "Step 525 | Loss: 1.11430 | LR: 7.55e-04\n",
      "Step 550 | Loss: 1.10451 | LR: 7.96e-04\n",
      "Step 575 | Loss: 1.00374 | LR: 8.33e-04\n",
      "val loss: 0.9706\n",
      "Step 600 | Loss: 0.96083 | LR: 8.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 625 | Loss: 0.89210 | LR: 8.98e-04\n",
      "Step 650 | Loss: 0.93468 | LR: 9.26e-04\n",
      "Step 675 | Loss: 0.83612 | LR: 9.49e-04\n",
      "val loss: 0.7814\n",
      "Step 700 | Loss: 0.77407 | LR: 9.68e-04\n",
      "Step 725 | Loss: 0.76564 | LR: 9.83e-04\n",
      "Step 750 | Loss: 0.72529 | LR: 9.93e-04\n",
      "Step 775 | Loss: 0.75461 | LR: 9.99e-04\n",
      "val loss: 0.6876\n",
      "Step 800 | Loss: 0.68865 | LR: 1.00e-03\n",
      "Step 825 | Loss: 0.66995 | LR: 1.00e-03\n",
      "Step 850 | Loss: 0.65726 | LR: 1.00e-03\n",
      "Step 875 | Loss: 0.64894 | LR: 1.00e-03\n",
      "val loss: 0.6186\n",
      "Step 900 | Loss: 0.58071 | LR: 1.00e-03\n",
      "Step 925 | Loss: 0.63612 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 950 | Loss: 0.59640 | LR: 1.00e-03\n",
      "Step 975 | Loss: 0.59811 | LR: 1.00e-03\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "val loss: 0.6068\n",
      "Step 1000 | Loss: 0.57364 | LR: 1.00e-03\n",
      "Step 1025 | Loss: 0.61980 | LR: 9.99e-04\n",
      "Step 1050 | Loss: 0.61210 | LR: 9.99e-04\n",
      "Step 1075 | Loss: 0.60014 | LR: 9.99e-04\n",
      "val loss: 0.5578\n",
      "Step 1100 | Loss: 0.57106 | LR: 9.99e-04\n",
      "Step 1125 | Loss: 0.60490 | LR: 9.99e-04\n",
      "Step 1150 | Loss: 0.55795 | LR: 9.99e-04\n",
      "Step 1175 | Loss: 0.52517 | LR: 9.98e-04\n",
      "val loss: 0.5540\n",
      "Step 1200 | Loss: 0.55269 | LR: 9.98e-04\n",
      "Step 1225 | Loss: 0.52937 | LR: 9.98e-04\n",
      "Step 1250 | Loss: 0.51446 | LR: 9.98e-04\n",
      "Step 1275 | Loss: 0.54386 | LR: 9.97e-04\n",
      "val loss: 0.5311\n",
      "Step 1300 | Loss: 0.55920 | LR: 9.97e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 1325 | Loss: 0.54873 | LR: 9.97e-04\n",
      "Step 1350 | Loss: 0.57035 | LR: 9.97e-04\n",
      "Step 1375 | Loss: 0.50653 | LR: 9.96e-04\n",
      "val loss: 0.5291\n",
      "Step 1400 | Loss: 0.56578 | LR: 9.96e-04\n",
      "Step 1425 | Loss: 0.53386 | LR: 9.96e-04\n",
      "Step 1450 | Loss: 0.52764 | LR: 9.95e-04\n",
      "Step 1475 | Loss: 0.51138 | LR: 9.95e-04\n",
      "val loss: 0.5220\n",
      "Step 1500 | Loss: 0.53016 | LR: 9.95e-04\n",
      "Step 1525 | Loss: 0.53991 | LR: 9.94e-04\n",
      "Step 1550 | Loss: 0.52067 | LR: 9.94e-04\n",
      "Step 1575 | Loss: 0.51404 | LR: 9.93e-04\n",
      "val loss: 0.5243\n",
      "Step 1600 | Loss: 0.51000 | LR: 9.93e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 1625 | Loss: 0.52805 | LR: 9.93e-04\n",
      "Step 1650 | Loss: 0.51363 | LR: 9.92e-04\n",
      "Step 1675 | Loss: 0.52967 | LR: 9.92e-04\n",
      "val loss: 0.5180\n",
      "Step 1700 | Loss: 0.51230 | LR: 9.91e-04\n",
      "Step 1725 | Loss: 0.56346 | LR: 9.91e-04\n",
      "Step 1750 | Loss: 0.52860 | LR: 9.90e-04\n",
      "Step 1775 | Loss: 0.53280 | LR: 9.90e-04\n",
      "val loss: 0.5243\n",
      "Step 1800 | Loss: 0.50229 | LR: 9.89e-04\n",
      "Step 1825 | Loss: 0.51030 | LR: 9.88e-04\n",
      "Step 1850 | Loss: 0.50322 | LR: 9.88e-04\n",
      "Step 1875 | Loss: 0.50091 | LR: 9.87e-04\n",
      "val loss: 0.5212\n",
      "Step 1900 | Loss: 0.53918 | LR: 9.87e-04\n",
      "Step 1925 | Loss: 0.53948 | LR: 9.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 1950 | Loss: 0.53227 | LR: 9.86e-04\n",
      "Step 1975 | Loss: 0.53994 | LR: 9.85e-04\n",
      "val loss: 0.5152\n",
      "Step 2000 | Loss: 0.54862 | LR: 9.84e-04\n",
      "Step 2025 | Loss: 0.48895 | LR: 9.84e-04\n",
      "Step 2050 | Loss: 0.52177 | LR: 9.83e-04\n",
      "Step 2075 | Loss: 0.50093 | LR: 9.82e-04\n",
      "val loss: 0.5252\n",
      "Step 2100 | Loss: 0.49630 | LR: 9.82e-04\n",
      "Step 2125 | Loss: 0.53652 | LR: 9.81e-04\n",
      "Step 2150 | Loss: 0.51422 | LR: 9.80e-04\n",
      "Step 2175 | Loss: 0.52495 | LR: 9.79e-04\n",
      "val loss: 0.5162\n",
      "Step 2200 | Loss: 0.52741 | LR: 9.79e-04\n",
      "Step 2225 | Loss: 0.49242 | LR: 9.78e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 2250 | Loss: 0.54276 | LR: 9.77e-04\n",
      "Step 2275 | Loss: 0.51539 | LR: 9.76e-04\n",
      "val loss: 0.5168\n",
      "Step 2300 | Loss: 0.53853 | LR: 9.76e-04\n",
      "Step 2325 | Loss: 0.52190 | LR: 9.75e-04\n",
      "Step 2350 | Loss: 0.54038 | LR: 9.74e-04\n",
      "Step 2375 | Loss: 0.51078 | LR: 9.73e-04\n",
      "val loss: 0.5177\n",
      "Step 2400 | Loss: 0.50925 | LR: 9.72e-04\n",
      "Step 2425 | Loss: 0.53685 | LR: 9.71e-04\n",
      "Step 2450 | Loss: 0.51898 | LR: 9.71e-04\n",
      "Step 2475 | Loss: 0.51480 | LR: 9.70e-04\n",
      "val loss: 0.5154\n",
      "Step 2500 | Loss: 0.52475 | LR: 9.69e-04\n",
      "Step 2525 | Loss: 0.52499 | LR: 9.68e-04\n",
      "Step 2550 | Loss: 0.50666 | LR: 9.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 2575 | Loss: 0.54667 | LR: 9.66e-04\n",
      "val loss: 0.5136\n",
      "Step 2600 | Loss: 0.52716 | LR: 9.65e-04\n",
      "Step 2625 | Loss: 0.52732 | LR: 9.64e-04\n",
      "Step 2650 | Loss: 0.54258 | LR: 9.63e-04\n",
      "Step 2675 | Loss: 0.53045 | LR: 9.62e-04\n",
      "val loss: 0.5129\n",
      "Step 2700 | Loss: 0.52581 | LR: 9.61e-04\n",
      "Step 2725 | Loss: 0.52280 | LR: 9.60e-04\n",
      "Step 2750 | Loss: 0.51231 | LR: 9.59e-04\n",
      "Step 2775 | Loss: 0.51438 | LR: 9.58e-04\n",
      "val loss: 0.5163\n",
      "Step 2800 | Loss: 0.51800 | LR: 9.57e-04\n",
      "Step 2825 | Loss: 0.53311 | LR: 9.56e-04\n",
      "Step 2850 | Loss: 0.51093 | LR: 9.55e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 2875 | Loss: 0.50535 | LR: 9.54e-04\n",
      "val loss: 0.5202\n",
      "Step 2900 | Loss: 0.52836 | LR: 9.53e-04\n",
      "Step 2925 | Loss: 0.49734 | LR: 9.52e-04\n",
      "Step 2950 | Loss: 0.52454 | LR: 9.50e-04\n",
      "Step 2975 | Loss: 0.53550 | LR: 9.49e-04\n",
      "val loss: 0.5180\n",
      "Step 3000 | Loss: 0.49825 | LR: 9.48e-04\n",
      "Step 3025 | Loss: 0.52776 | LR: 9.47e-04\n",
      "Step 3050 | Loss: 0.51615 | LR: 9.46e-04\n",
      "Step 3075 | Loss: 0.54061 | LR: 9.45e-04\n",
      "val loss: 0.5056\n",
      "Step 3100 | Loss: 0.49491 | LR: 9.43e-04\n",
      "Step 3125 | Loss: 0.53077 | LR: 9.42e-04\n",
      "Step 3150 | Loss: 0.55660 | LR: 9.41e-04\n",
      "Step 3175 | Loss: 0.51330 | LR: 9.40e-04\n",
      "=== Epoch 1 Done. Avg Loss: 0.74119 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5177\n",
      "Step 3200 | Loss: 0.55148 | LR: 9.38e-04\n",
      "Step 3225 | Loss: 0.50784 | LR: 9.37e-04\n",
      "Step 3250 | Loss: 0.54264 | LR: 9.36e-04\n",
      "Step 3275 | Loss: 0.52632 | LR: 9.35e-04\n",
      "val loss: 0.5152\n",
      "Step 3300 | Loss: 0.53997 | LR: 9.33e-04\n",
      "Step 3325 | Loss: 0.50708 | LR: 9.32e-04\n",
      "Step 3350 | Loss: 0.51856 | LR: 9.31e-04\n",
      "Step 3375 | Loss: 0.52446 | LR: 9.29e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5088\n",
      "Step 3400 | Loss: 0.52759 | LR: 9.28e-04\n",
      "Step 3425 | Loss: 0.49149 | LR: 9.27e-04\n",
      "Step 3450 | Loss: 0.49763 | LR: 9.25e-04\n",
      "Step 3475 | Loss: 0.54398 | LR: 9.24e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5165\n",
      "Step 3500 | Loss: 0.52312 | LR: 9.23e-04\n",
      "Step 3525 | Loss: 0.53604 | LR: 9.21e-04\n",
      "Step 3550 | Loss: 0.50523 | LR: 9.20e-04\n",
      "Step 3575 | Loss: 0.51793 | LR: 9.18e-04\n",
      "val loss: 0.5183\n",
      "Step 3600 | Loss: 0.50801 | LR: 9.17e-04\n",
      "Step 3625 | Loss: 0.49838 | LR: 9.16e-04\n",
      "Step 3650 | Loss: 0.49502 | LR: 9.14e-04\n",
      "Step 3675 | Loss: 0.52906 | LR: 9.13e-04\n",
      "val loss: 0.5141\n",
      "Step 3700 | Loss: 0.52604 | LR: 9.11e-04\n",
      "Step 3725 | Loss: 0.50529 | LR: 9.10e-04\n",
      "Step 3750 | Loss: 0.51464 | LR: 9.08e-04\n",
      "Step 3775 | Loss: 0.52243 | LR: 9.07e-04\n",
      "val loss: 0.5210\n",
      "Step 3800 | Loss: 0.53546 | LR: 9.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 3825 | Loss: 0.54490 | LR: 9.04e-04\n",
      "Step 3850 | Loss: 0.52125 | LR: 9.02e-04\n",
      "Step 3875 | Loss: 0.52754 | LR: 9.01e-04\n",
      "val loss: 0.5170\n",
      "Step 3900 | Loss: 0.51779 | LR: 8.99e-04\n",
      "Step 3925 | Loss: 0.53212 | LR: 8.97e-04\n",
      "Step 3950 | Loss: 0.54724 | LR: 8.96e-04\n",
      "Step 3975 | Loss: 0.53673 | LR: 8.94e-04\n",
      "val loss: 0.5130\n",
      "Step 4000 | Loss: 0.47648 | LR: 8.93e-04\n",
      "Step 4025 | Loss: 0.52432 | LR: 8.91e-04\n",
      "Step 4050 | Loss: 0.52052 | LR: 8.89e-04\n",
      "Step 4075 | Loss: 0.51119 | LR: 8.88e-04\n",
      "val loss: 0.5212\n",
      "Step 4100 | Loss: 0.48888 | LR: 8.86e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 4125 | Loss: 0.52823 | LR: 8.84e-04\n",
      "Step 4150 | Loss: 0.53198 | LR: 8.83e-04\n",
      "Step 4175 | Loss: 0.50917 | LR: 8.81e-04\n",
      "val loss: 0.5127\n",
      "Step 4200 | Loss: 0.52176 | LR: 8.79e-04\n",
      "Step 4225 | Loss: 0.52792 | LR: 8.78e-04\n",
      "Step 4250 | Loss: 0.52417 | LR: 8.76e-04\n",
      "Step 4275 | Loss: 0.52821 | LR: 8.74e-04\n",
      "val loss: 0.5249\n",
      "Step 4300 | Loss: 0.51326 | LR: 8.73e-04\n",
      "Step 4325 | Loss: 0.52501 | LR: 8.71e-04\n",
      "Step 4350 | Loss: 0.50439 | LR: 8.69e-04\n",
      "Step 4375 | Loss: 0.51996 | LR: 8.67e-04\n",
      "val loss: 0.5145\n",
      "Step 4400 | Loss: 0.48199 | LR: 8.65e-04\n",
      "Step 4425 | Loss: 0.48148 | LR: 8.64e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 4450 | Loss: 0.51772 | LR: 8.62e-04\n",
      "Step 4475 | Loss: 0.52480 | LR: 8.60e-04\n",
      "val loss: 0.5176\n",
      "Step 4500 | Loss: 0.51220 | LR: 8.58e-04\n",
      "Step 4525 | Loss: 0.52377 | LR: 8.56e-04\n",
      "Step 4550 | Loss: 0.53740 | LR: 8.55e-04\n",
      "Step 4575 | Loss: 0.52990 | LR: 8.53e-04\n",
      "val loss: 0.5107\n",
      "Step 4600 | Loss: 0.51185 | LR: 8.51e-04\n",
      "Step 4625 | Loss: 0.53501 | LR: 8.49e-04\n",
      "Step 4650 | Loss: 0.51586 | LR: 8.47e-04\n",
      "Step 4675 | Loss: 0.51589 | LR: 8.45e-04\n",
      "val loss: 0.5216\n",
      "Step 4700 | Loss: 0.51392 | LR: 8.43e-04\n",
      "Step 4725 | Loss: 0.55292 | LR: 8.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 4750 | Loss: 0.51810 | LR: 8.40e-04\n",
      "Step 4775 | Loss: 0.51130 | LR: 8.38e-04\n",
      "val loss: 0.5150\n",
      "Step 4800 | Loss: 0.52224 | LR: 8.36e-04\n",
      "Step 4825 | Loss: 0.49815 | LR: 8.34e-04\n",
      "Step 4850 | Loss: 0.51024 | LR: 8.32e-04\n",
      "Step 4875 | Loss: 0.50238 | LR: 8.30e-04\n",
      "val loss: 0.5107\n",
      "Step 4900 | Loss: 0.55187 | LR: 8.28e-04\n",
      "Step 4925 | Loss: 0.51757 | LR: 8.26e-04\n",
      "Step 4950 | Loss: 0.51727 | LR: 8.24e-04\n",
      "Step 4975 | Loss: 0.50583 | LR: 8.22e-04\n",
      "val loss: 0.5197\n",
      "Step 5000 | Loss: 0.52123 | LR: 8.20e-04\n",
      "Step 5025 | Loss: 0.52570 | LR: 8.18e-04\n",
      "Step 5050 | Loss: 0.52707 | LR: 8.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 5075 | Loss: 0.52575 | LR: 8.14e-04\n",
      "val loss: 0.5127\n",
      "Step 5100 | Loss: 0.52605 | LR: 8.12e-04\n",
      "Step 5125 | Loss: 0.53327 | LR: 8.10e-04\n",
      "Step 5150 | Loss: 0.50682 | LR: 8.08e-04\n",
      "Step 5175 | Loss: 0.50019 | LR: 8.06e-04\n",
      "val loss: 0.5168\n",
      "Step 5200 | Loss: 0.49845 | LR: 8.04e-04\n",
      "Step 5225 | Loss: 0.56321 | LR: 8.02e-04\n",
      "Step 5250 | Loss: 0.52189 | LR: 8.00e-04\n",
      "Step 5275 | Loss: 0.50312 | LR: 7.98e-04\n",
      "val loss: 0.5103\n",
      "Step 5300 | Loss: 0.54310 | LR: 7.96e-04\n",
      "Step 5325 | Loss: 0.52588 | LR: 7.93e-04\n",
      "Step 5350 | Loss: 0.51023 | LR: 7.91e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 5375 | Loss: 0.50114 | LR: 7.89e-04\n",
      "val loss: 0.5156\n",
      "Step 5400 | Loss: 0.53220 | LR: 7.87e-04\n",
      "Step 5425 | Loss: 0.49485 | LR: 7.85e-04\n",
      "Step 5450 | Loss: 0.53300 | LR: 7.83e-04\n",
      "Step 5475 | Loss: 0.51739 | LR: 7.81e-04\n",
      "val loss: 0.5126\n",
      "Step 5500 | Loss: 0.51210 | LR: 7.78e-04\n",
      "Step 5525 | Loss: 0.52607 | LR: 7.76e-04\n",
      "Step 5550 | Loss: 0.52866 | LR: 7.74e-04\n",
      "Step 5575 | Loss: 0.50727 | LR: 7.72e-04\n",
      "val loss: 0.5137\n",
      "Step 5600 | Loss: 0.49350 | LR: 7.70e-04\n",
      "Step 5625 | Loss: 0.54473 | LR: 7.68e-04\n",
      "Step 5650 | Loss: 0.55404 | LR: 7.65e-04\n",
      "Step 5675 | Loss: 0.49658 | LR: 7.63e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "val loss: 0.5231\n",
      "Step 5700 | Loss: 0.51236 | LR: 7.61e-04\n",
      "Step 5725 | Loss: 0.51813 | LR: 7.59e-04\n",
      "Step 5750 | Loss: 0.52337 | LR: 7.57e-04\n",
      "Step 5775 | Loss: 0.52092 | LR: 7.54e-04\n",
      "val loss: 0.5171\n",
      "Step 5800 | Loss: 0.53625 | LR: 7.52e-04\n",
      "Step 5825 | Loss: 0.52206 | LR: 7.50e-04\n",
      "Step 5850 | Loss: 0.51580 | LR: 7.48e-04\n",
      "Step 5875 | Loss: 0.50942 | LR: 7.45e-04\n",
      "val loss: 0.5144\n",
      "Step 5900 | Loss: 0.52114 | LR: 7.43e-04\n",
      "Step 5925 | Loss: 0.51423 | LR: 7.41e-04\n",
      "Step 5950 | Loss: 0.51393 | LR: 7.38e-04\n",
      "Step 5975 | Loss: 0.54223 | LR: 7.36e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.5096\n",
      "Step 6000 | Loss: 0.53132 | LR: 7.34e-04\n",
      "Step 6025 | Loss: 0.50498 | LR: 7.32e-04\n",
      "Step 6050 | Loss: 0.54979 | LR: 7.29e-04\n",
      "Step 6075 | Loss: 0.53661 | LR: 7.27e-04\n",
      "val loss: 0.5146\n",
      "Step 6100 | Loss: 0.51669 | LR: 7.25e-04\n",
      "Step 6125 | Loss: 0.52266 | LR: 7.22e-04\n",
      "Step 6150 | Loss: 0.51613 | LR: 7.20e-04\n",
      "Step 6175 | Loss: 0.53680 | LR: 7.18e-04\n",
      "val loss: 0.5192\n",
      "Step 6200 | Loss: 0.51164 | LR: 7.15e-04\n",
      "Step 6225 | Loss: 0.51587 | LR: 7.13e-04\n",
      "Step 6250 | Loss: 0.49783 | LR: 7.11e-04\n",
      "Step 6275 | Loss: 0.52314 | LR: 7.08e-04\n",
      "val loss: 0.5221\n",
      "Step 6300 | Loss: 0.52522 | LR: 7.06e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6325 | Loss: 0.51013 | LR: 7.03e-04\n",
      "Step 6350 | Loss: 0.53497 | LR: 7.01e-04\n",
      "=== Epoch 2 Done. Avg Loss: 0.52036 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 6375 | Loss: 0.52221 | LR: 6.99e-04\n",
      "val loss: 0.5204\n",
      "Step 6400 | Loss: 0.51208 | LR: 6.96e-04\n",
      "Step 6425 | Loss: 0.55522 | LR: 6.94e-04\n",
      "Step 6450 | Loss: 0.51586 | LR: 6.91e-04\n",
      "Step 6475 | Loss: 0.52124 | LR: 6.89e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5191\n",
      "Step 6500 | Loss: 0.54232 | LR: 6.87e-04\n",
      "Step 6525 | Loss: 0.49615 | LR: 6.84e-04\n",
      "Step 6550 | Loss: 0.52298 | LR: 6.82e-04\n",
      "Step 6575 | Loss: 0.50763 | LR: 6.79e-04\n",
      "val loss: 0.5205\n",
      "Step 6600 | Loss: 0.56106 | LR: 6.77e-04\n",
      "Step 6625 | Loss: 0.52568 | LR: 6.75e-04\n",
      "Step 6650 | Loss: 0.50078 | LR: 6.72e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 6675 | Loss: 0.53538 | LR: 6.70e-04\n",
      "val loss: 0.5248\n",
      "Step 6700 | Loss: 0.52920 | LR: 6.67e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 6725 | Loss: 0.52834 | LR: 6.65e-04\n",
      "Step 6750 | Loss: 0.51680 | LR: 6.62e-04\n",
      "Step 6775 | Loss: 0.54718 | LR: 6.60e-04\n",
      "val loss: 0.5184\n",
      "Step 6800 | Loss: 0.52306 | LR: 6.57e-04\n",
      "Step 6825 | Loss: 0.50290 | LR: 6.55e-04\n",
      "Step 6850 | Loss: 0.51208 | LR: 6.52e-04\n",
      "Step 6875 | Loss: 0.48130 | LR: 6.50e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5022\n",
      "Step 6900 | Loss: 0.52513 | LR: 6.47e-04\n",
      "Step 6925 | Loss: 0.50532 | LR: 6.45e-04\n",
      "Step 6950 | Loss: 0.48687 | LR: 6.42e-04\n",
      "Step 6975 | Loss: 0.51782 | LR: 6.40e-04\n",
      "val loss: 0.5279\n",
      "Step 7000 | Loss: 0.51122 | LR: 6.37e-04\n",
      "Step 7025 | Loss: 0.52297 | LR: 6.35e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 7050 | Loss: 0.51593 | LR: 6.32e-04\n",
      "Step 7075 | Loss: 0.51719 | LR: 6.30e-04\n",
      "val loss: 0.5145\n",
      "Step 7100 | Loss: 0.52092 | LR: 6.27e-04\n",
      "Step 7125 | Loss: 0.53324 | LR: 6.25e-04\n",
      "Step 7150 | Loss: 0.51178 | LR: 6.22e-04\n",
      "Step 7175 | Loss: 0.53210 | LR: 6.20e-04\n",
      "val loss: 0.5220\n",
      "Step 7200 | Loss: 0.51215 | LR: 6.17e-04\n",
      "Step 7225 | Loss: 0.52264 | LR: 6.15e-04\n",
      "Step 7250 | Loss: 0.52104 | LR: 6.12e-04\n",
      "Step 7275 | Loss: 0.50534 | LR: 6.10e-04\n",
      "val loss: 0.5161\n",
      "Step 7300 | Loss: 0.49693 | LR: 6.07e-04\n",
      "Step 7325 | Loss: 0.55127 | LR: 6.05e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 7350 | Loss: 0.50859 | LR: 6.02e-04\n",
      "Step 7375 | Loss: 0.52681 | LR: 6.00e-04\n",
      "val loss: 0.5107\n",
      "Step 7400 | Loss: 0.50214 | LR: 5.97e-04\n",
      "Step 7425 | Loss: 0.53033 | LR: 5.94e-04\n",
      "Step 7450 | Loss: 0.50669 | LR: 5.92e-04\n",
      "Step 7475 | Loss: 0.52672 | LR: 5.89e-04\n",
      "val loss: 0.5171\n",
      "Step 7500 | Loss: 0.52407 | LR: 5.87e-04\n",
      "Step 7525 | Loss: 0.52661 | LR: 5.84e-04\n",
      "Step 7550 | Loss: 0.51128 | LR: 5.82e-04\n",
      "Step 7575 | Loss: 0.55118 | LR: 5.79e-04\n",
      "val loss: 0.5189\n",
      "Step 7600 | Loss: 0.52009 | LR: 5.76e-04\n",
      "Step 7625 | Loss: 0.52590 | LR: 5.74e-04\n",
      "Step 7650 | Loss: 0.50982 | LR: 5.71e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 7675 | Loss: 0.50613 | LR: 5.69e-04\n",
      "val loss: 0.5199\n",
      "Step 7700 | Loss: 0.51574 | LR: 5.66e-04\n",
      "Step 7725 | Loss: 0.50828 | LR: 5.64e-04\n",
      "Step 7750 | Loss: 0.55755 | LR: 5.61e-04\n",
      "Step 7775 | Loss: 0.48912 | LR: 5.58e-04\n",
      "val loss: 0.5146\n",
      "Step 7800 | Loss: 0.55154 | LR: 5.56e-04\n",
      "Step 7825 | Loss: 0.53577 | LR: 5.53e-04\n",
      "Step 7850 | Loss: 0.48886 | LR: 5.51e-04\n",
      "Step 7875 | Loss: 0.54741 | LR: 5.48e-04\n",
      "val loss: 0.5147\n",
      "Step 7900 | Loss: 0.49237 | LR: 5.45e-04\n",
      "Step 7925 | Loss: 0.56062 | LR: 5.43e-04\n",
      "Step 7950 | Loss: 0.51380 | LR: 5.40e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "Step 7975 | Loss: 0.53419 | LR: 5.38e-04\n",
      "val loss: 0.5122\n",
      "Step 8000 | Loss: 0.50342 | LR: 5.35e-04\n",
      "Step 8025 | Loss: 0.50256 | LR: 5.33e-04\n",
      "Step 8050 | Loss: 0.50819 | LR: 5.30e-04\n",
      "Step 8075 | Loss: 0.50062 | LR: 5.27e-04\n",
      "val loss: 0.5202\n",
      "Step 8100 | Loss: 0.52423 | LR: 5.25e-04\n",
      "Step 8125 | Loss: 0.53115 | LR: 5.22e-04\n",
      "Step 8150 | Loss: 0.53412 | LR: 5.20e-04\n",
      "Step 8175 | Loss: 0.53877 | LR: 5.17e-04\n",
      "val loss: 0.5101\n",
      "Step 8200 | Loss: 0.53525 | LR: 5.14e-04\n",
      "Step 8225 | Loss: 0.51812 | LR: 5.12e-04\n",
      "Step 8250 | Loss: 0.50933 | LR: 5.09e-04\n",
      "Step 8275 | Loss: 0.55329 | LR: 5.07e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "val loss: 0.5203\n",
      "Step 8300 | Loss: 0.52894 | LR: 5.04e-04\n",
      "Step 8325 | Loss: 0.54015 | LR: 5.01e-04\n",
      "Step 8350 | Loss: 0.49713 | LR: 4.99e-04\n",
      "Step 8375 | Loss: 0.52304 | LR: 4.96e-04\n",
      "val loss: 0.5190\n",
      "Step 8400 | Loss: 0.52245 | LR: 4.94e-04\n",
      "Step 8425 | Loss: 0.54090 | LR: 4.91e-04\n",
      "Step 8450 | Loss: 0.47633 | LR: 4.88e-04\n",
      "Step 8475 | Loss: 0.51620 | LR: 4.86e-04\n",
      "val loss: 0.5257\n",
      "Step 8500 | Loss: 0.50424 | LR: 4.83e-04\n",
      "Step 8525 | Loss: 0.53025 | LR: 4.81e-04\n",
      "Step 8550 | Loss: 0.53771 | LR: 4.78e-04\n",
      "Step 8575 | Loss: 0.54962 | LR: 4.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "val loss: 0.5179\n",
      "Step 8600 | Loss: 0.52554 | LR: 4.73e-04\n",
      "Step 8625 | Loss: 0.51160 | LR: 4.70e-04\n",
      "Step 8650 | Loss: 0.53780 | LR: 4.68e-04\n",
      "Step 8675 | Loss: 0.53136 | LR: 4.65e-04\n",
      "val loss: 0.5138\n",
      "Step 8700 | Loss: 0.49418 | LR: 4.62e-04\n",
      "Step 8725 | Loss: 0.49223 | LR: 4.60e-04\n",
      "Step 8750 | Loss: 0.57277 | LR: 4.57e-04\n",
      "Step 8775 | Loss: 0.52487 | LR: 4.55e-04\n",
      "val loss: 0.5066\n",
      "Step 8800 | Loss: 0.51581 | LR: 4.52e-04\n",
      "Step 8825 | Loss: 0.51038 | LR: 4.49e-04\n",
      "Step 8850 | Loss: 0.53030 | LR: 4.47e-04\n",
      "Step 8875 | Loss: 0.53348 | LR: 4.44e-04\n",
      "val loss: 0.5179\n",
      "Step 8900 | Loss: 0.52735 | LR: 4.42e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 8925 | Loss: 0.50776 | LR: 4.39e-04\n",
      "Step 8950 | Loss: 0.52554 | LR: 4.36e-04\n",
      "Step 8975 | Loss: 0.53178 | LR: 4.34e-04\n",
      "val loss: 0.5164\n",
      "Step 9000 | Loss: 0.53901 | LR: 4.31e-04\n",
      "Step 9025 | Loss: 0.51705 | LR: 4.29e-04\n",
      "Step 9050 | Loss: 0.51612 | LR: 4.26e-04\n",
      "Step 9075 | Loss: 0.53085 | LR: 4.24e-04\n",
      "val loss: 0.5180\n",
      "Step 9100 | Loss: 0.53736 | LR: 4.21e-04\n",
      "Step 9125 | Loss: 0.52522 | LR: 4.18e-04\n",
      "Step 9150 | Loss: 0.50838 | LR: 4.16e-04\n",
      "Step 9175 | Loss: 0.52534 | LR: 4.13e-04\n",
      "val loss: 0.5136\n",
      "Step 9200 | Loss: 0.53162 | LR: 4.11e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 9225 | Loss: 0.50554 | LR: 4.08e-04\n",
      "Step 9250 | Loss: 0.51297 | LR: 4.06e-04\n",
      "Step 9275 | Loss: 0.50251 | LR: 4.03e-04\n",
      "val loss: 0.5177\n",
      "Step 9300 | Loss: 0.52505 | LR: 4.00e-04\n",
      "Step 9325 | Loss: 0.51925 | LR: 3.98e-04\n",
      "Step 9350 | Loss: 0.51945 | LR: 3.95e-04\n",
      "Step 9375 | Loss: 0.50098 | LR: 3.93e-04\n",
      "val loss: 0.5151\n",
      "Step 9400 | Loss: 0.50908 | LR: 3.90e-04\n",
      "Step 9425 | Loss: 0.52208 | LR: 3.88e-04\n",
      "Step 9450 | Loss: 0.52836 | LR: 3.85e-04\n",
      "Step 9475 | Loss: 0.50857 | LR: 3.83e-04\n",
      "val loss: 0.5191\n",
      "Step 9500 | Loss: 0.55206 | LR: 3.80e-04\n",
      "Step 9525 | Loss: 0.53210 | LR: 3.78e-04\n",
      "=== Epoch 3 Done. Avg Loss: 0.52035 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 9550 | Loss: 0.51942 | LR: 3.75e-04\n",
      "Step 9575 | Loss: 0.53146 | LR: 3.73e-04\n",
      "val loss: 0.5145\n",
      "Step 9600 | Loss: 0.51737 | LR: 3.70e-04\n",
      "Step 9625 | Loss: 0.54474 | LR: 3.68e-04\n",
      "Step 9650 | Loss: 0.54954 | LR: 3.65e-04\n",
      "Step 9675 | Loss: 0.53061 | LR: 3.63e-04\n",
      "val loss: 0.5128\n",
      "Step 9700 | Loss: 0.54221 | LR: 3.60e-04\n",
      "Step 9725 | Loss: 0.51755 | LR: 3.58e-04\n",
      "Step 9750 | Loss: 0.54708 | LR: 3.55e-04\n",
      "Step 9775 | Loss: 0.52006 | LR: 3.53e-04\n",
      "val loss: 0.5201\n",
      "Step 9800 | Loss: 0.50062 | LR: 3.50e-04\n",
      "Step 9825 | Loss: 0.54213 | LR: 3.48e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 9850 | Loss: 0.53444 | LR: 3.45e-04\n",
      "Step 9875 | Loss: 0.52907 | LR: 3.43e-04\n",
      "val loss: 0.5149\n",
      "Step 9900 | Loss: 0.53432 | LR: 3.40e-04\n",
      "Step 9925 | Loss: 0.49257 | LR: 3.38e-04\n",
      "Step 9950 | Loss: 0.52064 | LR: 3.35e-04\n",
      "Step 9975 | Loss: 0.51821 | LR: 3.33e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5158\n",
      "Step 10000 | Loss: 0.52528 | LR: 3.30e-04\n",
      "Step 10025 | Loss: 0.50140 | LR: 3.28e-04\n",
      "Step 10050 | Loss: 0.52654 | LR: 3.26e-04\n",
      "Step 10075 | Loss: 0.51367 | LR: 3.23e-04\n",
      "val loss: 0.5317\n",
      "Step 10100 | Loss: 0.53730 | LR: 3.21e-04\n",
      "Step 10125 | Loss: 0.51322 | LR: 3.18e-04\n",
      "Step 10150 | Loss: 0.54179 | LR: 3.16e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "Step 10175 | Loss: 0.48087 | LR: 3.13e-04\n",
      "val loss: 0.5174\n",
      "Step 10200 | Loss: 0.51854 | LR: 3.11e-04\n",
      "Step 10225 | Loss: 0.49911 | LR: 3.09e-04\n",
      "Step 10250 | Loss: 0.52651 | LR: 3.06e-04\n",
      "Step 10275 | Loss: 0.53551 | LR: 3.04e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5162\n",
      "Step 10300 | Loss: 0.52218 | LR: 3.01e-04\n",
      "Step 10325 | Loss: 0.49391 | LR: 2.99e-04\n",
      "Step 10350 | Loss: 0.53934 | LR: 2.97e-04\n",
      "Step 10375 | Loss: 0.52690 | LR: 2.94e-04\n",
      "val loss: 0.5154\n",
      "Step 10400 | Loss: 0.51156 | LR: 2.92e-04\n",
      "Step 10425 | Loss: 0.49105 | LR: 2.90e-04\n",
      "Step 10450 | Loss: 0.51817 | LR: 2.87e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 10475 | Loss: 0.49601 | LR: 2.85e-04\n",
      "val loss: 0.5260\n",
      "Step 10500 | Loss: 0.54846 | LR: 2.82e-04\n",
      "Step 10525 | Loss: 0.50675 | LR: 2.80e-04\n",
      "Step 10550 | Loss: 0.50348 | LR: 2.78e-04\n",
      "Step 10575 | Loss: 0.52469 | LR: 2.75e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5265\n",
      "Step 10600 | Loss: 0.50646 | LR: 2.73e-04\n",
      "Step 10625 | Loss: 0.50329 | LR: 2.71e-04\n",
      "Step 10650 | Loss: 0.50956 | LR: 2.68e-04\n",
      "Step 10675 | Loss: 0.50995 | LR: 2.66e-04\n",
      "val loss: 0.5134\n",
      "Step 10700 | Loss: 0.50403 | LR: 2.64e-04\n",
      "Step 10725 | Loss: 0.53179 | LR: 2.62e-04\n",
      "Step 10750 | Loss: 0.51061 | LR: 2.59e-04\n",
      "Step 10775 | Loss: 0.54624 | LR: 2.57e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "val loss: 0.5222\n",
      "Step 10800 | Loss: 0.51000 | LR: 2.55e-04\n",
      "Step 10825 | Loss: 0.51450 | LR: 2.53e-04\n",
      "Step 10850 | Loss: 0.51985 | LR: 2.50e-04\n",
      "Step 10875 | Loss: 0.53496 | LR: 2.48e-04\n",
      "val loss: 0.5192\n",
      "Step 10900 | Loss: 0.50423 | LR: 2.46e-04\n",
      "Step 10925 | Loss: 0.51922 | LR: 2.44e-04\n",
      "Step 10950 | Loss: 0.51029 | LR: 2.41e-04\n",
      "Step 10975 | Loss: 0.51267 | LR: 2.39e-04\n",
      "val loss: 0.5143\n",
      "Step 11000 | Loss: 0.54718 | LR: 2.37e-04\n",
      "Step 11025 | Loss: 0.53601 | LR: 2.35e-04\n",
      "Step 11050 | Loss: 0.52494 | LR: 2.32e-04\n",
      "Step 11075 | Loss: 0.50890 | LR: 2.30e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "val loss: 0.5179\n",
      "Step 11100 | Loss: 0.53281 | LR: 2.28e-04\n",
      "Step 11125 | Loss: 0.50498 | LR: 2.26e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 11150 | Loss: 0.54439 | LR: 2.24e-04\n",
      "Step 11175 | Loss: 0.51537 | LR: 2.22e-04\n",
      "val loss: 0.5106\n",
      "Step 11200 | Loss: 0.51860 | LR: 2.19e-04\n",
      "Step 11225 | Loss: 0.51303 | LR: 2.17e-04\n",
      "Step 11250 | Loss: 0.51189 | LR: 2.15e-04\n",
      "Step 11275 | Loss: 0.52999 | LR: 2.13e-04\n",
      "val loss: 0.5178\n",
      "Step 11300 | Loss: 0.50861 | LR: 2.11e-04\n",
      "Step 11325 | Loss: 0.50930 | LR: 2.09e-04\n",
      "Step 11350 | Loss: 0.51234 | LR: 2.07e-04\n",
      "Step 11375 | Loss: 0.51558 | LR: 2.04e-04\n",
      "val loss: 0.5164\n",
      "Step 11400 | Loss: 0.51086 | LR: 2.02e-04\n",
      "Step 11425 | Loss: 0.51534 | LR: 2.00e-04\n",
      "Step 11450 | Loss: 0.53423 | LR: 1.98e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 11475 | Loss: 0.49373 | LR: 1.96e-04\n",
      "val loss: 0.5161\n",
      "Step 11500 | Loss: 0.55399 | LR: 1.94e-04\n",
      "Step 11525 | Loss: 0.50163 | LR: 1.92e-04\n",
      "Step 11550 | Loss: 0.50064 | LR: 1.90e-04\n",
      "Step 11575 | Loss: 0.51227 | LR: 1.88e-04\n",
      "val loss: 0.5209\n",
      "Step 11600 | Loss: 0.49160 | LR: 1.86e-04\n",
      "Step 11625 | Loss: 0.52711 | LR: 1.84e-04\n",
      "Step 11650 | Loss: 0.52929 | LR: 1.82e-04\n",
      "Step 11675 | Loss: 0.51028 | LR: 1.80e-04\n",
      "val loss: 0.5190\n",
      "Step 11700 | Loss: 0.51766 | LR: 1.78e-04\n",
      "Step 11725 | Loss: 0.52018 | LR: 1.76e-04\n",
      "Step 11750 | Loss: 0.52181 | LR: 1.74e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 11775 | Loss: 0.51989 | LR: 1.72e-04\n",
      "val loss: 0.5277\n",
      "Step 11800 | Loss: 0.53430 | LR: 1.70e-04\n",
      "Step 11825 | Loss: 0.51666 | LR: 1.68e-04\n",
      "Step 11850 | Loss: 0.54441 | LR: 1.66e-04\n",
      "Step 11875 | Loss: 0.51902 | LR: 1.64e-04\n",
      "val loss: 0.5203\n",
      "Step 11900 | Loss: 0.54358 | LR: 1.62e-04\n",
      "Step 11925 | Loss: 0.51272 | LR: 1.60e-04\n",
      "Step 11950 | Loss: 0.52622 | LR: 1.58e-04\n",
      "Step 11975 | Loss: 0.51395 | LR: 1.57e-04\n",
      "val loss: 0.5168\n",
      "Step 12000 | Loss: 0.52034 | LR: 1.55e-04\n",
      "Step 12025 | Loss: 0.53649 | LR: 1.53e-04\n",
      "Step 12050 | Loss: 0.52166 | LR: 1.51e-04\n",
      "Step 12075 | Loss: 0.53520 | LR: 1.49e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "val loss: 0.5161\n",
      "Step 12100 | Loss: 0.50118 | LR: 1.47e-04\n",
      "Step 12125 | Loss: 0.53220 | LR: 1.45e-04\n",
      "Step 12150 | Loss: 0.51437 | LR: 1.44e-04\n",
      "Step 12175 | Loss: 0.52300 | LR: 1.42e-04\n",
      "val loss: 0.5156\n",
      "Step 12200 | Loss: 0.55773 | LR: 1.40e-04\n",
      "Step 12225 | Loss: 0.50041 | LR: 1.38e-04\n",
      "Step 12250 | Loss: 0.52937 | LR: 1.36e-04\n",
      "Step 12275 | Loss: 0.51388 | LR: 1.35e-04\n",
      "val loss: 0.5155\n",
      "Step 12300 | Loss: 0.49050 | LR: 1.33e-04\n",
      "Step 12325 | Loss: 0.50210 | LR: 1.31e-04\n",
      "Step 12350 | Loss: 0.52001 | LR: 1.29e-04\n",
      "Step 12375 | Loss: 0.53427 | LR: 1.28e-04\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5138\n",
      "Step 12400 | Loss: 0.53062 | LR: 1.26e-04\n",
      "Step 12425 | Loss: 0.51270 | LR: 1.24e-04\n",
      "Step 12450 | Loss: 0.50351 | LR: 1.22e-04\n",
      "Step 12475 | Loss: 0.50332 | LR: 1.21e-04\n",
      "val loss: 0.5157\n",
      "Step 12500 | Loss: 0.52251 | LR: 1.19e-04\n",
      "Step 12525 | Loss: 0.52663 | LR: 1.17e-04\n",
      "Step 12550 | Loss: 0.52561 | LR: 1.16e-04\n",
      "Step 12575 | Loss: 0.50755 | LR: 1.14e-04\n",
      "val loss: 0.5158\n",
      "Step 12600 | Loss: 0.54433 | LR: 1.12e-04\n",
      "Step 12625 | Loss: 0.52377 | LR: 1.11e-04\n",
      "Step 12650 | Loss: 0.49989 | LR: 1.09e-04\n",
      "Step 12675 | Loss: 0.52814 | LR: 1.07e-04\n",
      "val loss: 0.5138\n",
      "Step 12700 | Loss: 0.48851 | LR: 1.06e-04\n",
      "=== Epoch 4 Done. Avg Loss: 0.52033 ===\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0006.npz\n",
      "Step 12725 | Loss: 0.50659 | LR: 1.04e-04\n",
      "Step 12750 | Loss: 0.54257 | LR: 1.03e-04\n",
      "Step 12775 | Loss: 0.54590 | LR: 1.01e-04\n",
      "val loss: 0.5129\n",
      "Step 12800 | Loss: 0.51410 | LR: 9.95e-05\n",
      "Step 12825 | Loss: 0.49914 | LR: 9.79e-05\n",
      "Step 12850 | Loss: 0.52207 | LR: 9.64e-05\n",
      "Step 12875 | Loss: 0.52665 | LR: 9.49e-05\n",
      "val loss: 0.5055\n",
      "Step 12900 | Loss: 0.49416 | LR: 9.34e-05\n",
      "Step 12925 | Loss: 0.52260 | LR: 9.18e-05\n",
      "Step 12950 | Loss: 0.51565 | LR: 9.03e-05\n",
      "Step 12975 | Loss: 0.53066 | LR: 8.89e-05\n",
      "val loss: 0.5123\n",
      "Step 13000 | Loss: 0.51829 | LR: 8.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0004.npz\n",
      "Step 13025 | Loss: 0.54866 | LR: 8.59e-05\n",
      "Step 13050 | Loss: 0.48917 | LR: 8.45e-05\n",
      "Step 13075 | Loss: 0.53109 | LR: 8.30e-05\n",
      "val loss: 0.5181\n",
      "Step 13100 | Loss: 0.50680 | LR: 8.16e-05\n",
      "Step 13125 | Loss: 0.49659 | LR: 8.02e-05\n",
      "Step 13150 | Loss: 0.51463 | LR: 7.88e-05\n",
      "Step 13175 | Loss: 0.53004 | LR: 7.74e-05\n",
      "val loss: 0.5178\n",
      "Step 13200 | Loss: 0.53206 | LR: 7.60e-05\n",
      "Step 13225 | Loss: 0.53187 | LR: 7.46e-05\n",
      "Step 13250 | Loss: 0.53279 | LR: 7.33e-05\n",
      "Step 13275 | Loss: 0.54245 | LR: 7.19e-05\n",
      "val loss: 0.5146\n",
      "Step 13300 | Loss: 0.52539 | LR: 7.06e-05\n",
      "Step 13325 | Loss: 0.51038 | LR: 6.92e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0005.npz\n",
      "Step 13350 | Loss: 0.52720 | LR: 6.79e-05\n",
      "Step 13375 | Loss: 0.49967 | LR: 6.66e-05\n",
      "val loss: 0.5146\n",
      "Step 13400 | Loss: 0.53093 | LR: 6.53e-05\n",
      "Step 13425 | Loss: 0.50531 | LR: 6.40e-05\n",
      "Step 13450 | Loss: 0.52099 | LR: 6.28e-05\n",
      "Step 13475 | Loss: 0.52017 | LR: 6.15e-05\n",
      "val loss: 0.5167\n",
      "Step 13500 | Loss: 0.52967 | LR: 6.03e-05\n",
      "Step 13525 | Loss: 0.51335 | LR: 5.90e-05\n",
      "Step 13550 | Loss: 0.53101 | LR: 5.78e-05\n",
      "Step 13575 | Loss: 0.51622 | LR: 5.66e-05\n",
      "val loss: 0.5157\n",
      "Step 13600 | Loss: 0.51110 | LR: 5.54e-05\n",
      "Step 13625 | Loss: 0.50660 | LR: 5.42e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0007.npz\n",
      "Step 13650 | Loss: 0.50199 | LR: 5.31e-05\n",
      "Step 13675 | Loss: 0.53930 | LR: 5.19e-05\n",
      "val loss: 0.5174\n",
      "Step 13700 | Loss: 0.53557 | LR: 5.08e-05\n",
      "Step 13725 | Loss: 0.53163 | LR: 4.96e-05\n",
      "Step 13750 | Loss: 0.52073 | LR: 4.85e-05\n",
      "Step 13775 | Loss: 0.52969 | LR: 4.74e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0001.npz\n",
      "val loss: 0.5181\n",
      "Step 13800 | Loss: 0.52829 | LR: 4.63e-05\n",
      "Step 13825 | Loss: 0.52176 | LR: 4.52e-05\n",
      "Step 13850 | Loss: 0.52874 | LR: 4.41e-05\n",
      "Step 13875 | Loss: 0.50834 | LR: 4.31e-05\n",
      "val loss: 0.5206\n",
      "Step 13900 | Loss: 0.51713 | LR: 4.20e-05\n",
      "Step 13925 | Loss: 0.52090 | LR: 4.10e-05\n",
      "Step 13950 | Loss: 0.53688 | LR: 3.99e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0001.npz\n",
      "Step 13975 | Loss: 0.53457 | LR: 3.89e-05\n",
      "val loss: 0.5226\n",
      "Step 14000 | Loss: 0.52103 | LR: 3.79e-05\n",
      "Step 14025 | Loss: 0.49897 | LR: 3.69e-05\n",
      "Step 14050 | Loss: 0.53101 | LR: 3.60e-05\n",
      "Step 14075 | Loss: 0.52707 | LR: 3.50e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/val/shard_k562e_val_0000.npz\n",
      "val loss: 0.5197\n",
      "Step 14100 | Loss: 0.50129 | LR: 3.41e-05\n",
      "Step 14125 | Loss: 0.55263 | LR: 3.31e-05\n",
      "Step 14150 | Loss: 0.52211 | LR: 3.22e-05\n",
      "Step 14175 | Loss: 0.51519 | LR: 3.13e-05\n",
      "val loss: 0.5232\n",
      "Step 14200 | Loss: 0.52469 | LR: 3.04e-05\n",
      "Step 14225 | Loss: 0.57405 | LR: 2.95e-05\n",
      "Step 14250 | Loss: 0.52519 | LR: 2.86e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0002.npz\n",
      "Step 14275 | Loss: 0.52034 | LR: 2.78e-05\n",
      "val loss: 0.5242\n",
      "Step 14300 | Loss: 0.51275 | LR: 2.69e-05\n",
      "Step 14325 | Loss: 0.52450 | LR: 2.61e-05\n",
      "Step 14350 | Loss: 0.51795 | LR: 2.53e-05\n",
      "Step 14375 | Loss: 0.52383 | LR: 2.44e-05\n",
      "val loss: 0.5150\n",
      "Step 14400 | Loss: 0.52668 | LR: 2.36e-05\n",
      "Step 14425 | Loss: 0.53952 | LR: 2.29e-05\n",
      "Step 14450 | Loss: 0.52784 | LR: 2.21e-05\n",
      "Step 14475 | Loss: 0.50194 | LR: 2.13e-05\n",
      "val loss: 0.5127\n",
      "Step 14500 | Loss: 0.49346 | LR: 2.06e-05\n",
      "Step 14525 | Loss: 0.52146 | LR: 1.99e-05\n",
      "Step 14550 | Loss: 0.52629 | LR: 1.91e-05\n",
      "Step 14575 | Loss: 0.49894 | LR: 1.84e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0009.npz\n",
      "val loss: 0.5183\n",
      "Step 14600 | Loss: 0.53194 | LR: 1.77e-05\n",
      "Step 14625 | Loss: 0.51435 | LR: 1.71e-05\n",
      "Step 14650 | Loss: 0.50287 | LR: 1.64e-05\n",
      "Step 14675 | Loss: 0.51370 | LR: 1.57e-05\n",
      "val loss: 0.5144\n",
      "Step 14700 | Loss: 0.51350 | LR: 1.51e-05\n",
      "Step 14725 | Loss: 0.49707 | LR: 1.45e-05\n",
      "Step 14750 | Loss: 0.53741 | LR: 1.38e-05\n",
      "Step 14775 | Loss: 0.50933 | LR: 1.32e-05\n",
      "val loss: 0.5058\n",
      "Step 14800 | Loss: 0.52302 | LR: 1.27e-05\n",
      "Step 14825 | Loss: 0.51789 | LR: 1.21e-05\n",
      "Step 14850 | Loss: 0.53721 | LR: 1.15e-05\n",
      "Step 14875 | Loss: 0.52839 | LR: 1.10e-05\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0008.npz\n",
      "val loss: 0.5213\n",
      "Step 14900 | Loss: 0.51165 | LR: 1.04e-05\n",
      "Step 14925 | Loss: 0.52670 | LR: 9.91e-06\n",
      "Step 14950 | Loss: 0.56130 | LR: 9.41e-06\n",
      "Step 14975 | Loss: 0.54526 | LR: 8.91e-06\n",
      "val loss: 0.5140\n",
      "Step 15000 | Loss: 0.52406 | LR: 8.43e-06\n",
      "Step 15025 | Loss: 0.50202 | LR: 7.96e-06\n",
      "Step 15050 | Loss: 0.53081 | LR: 7.50e-06\n",
      "Step 15075 | Loss: 0.51867 | LR: 7.06e-06\n",
      "val loss: 0.5128\n",
      "Step 15100 | Loss: 0.50356 | LR: 6.63e-06\n",
      "Step 15125 | Loss: 0.53118 | LR: 6.22e-06\n",
      "Step 15150 | Loss: 0.51509 | LR: 5.81e-06\n",
      "Step 15175 | Loss: 0.49513 | LR: 5.43e-06\n",
      "val loss: 0.5106\n",
      "Step 15200 | Loss: 0.50676 | LR: 5.05e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0003.npz\n",
      "Step 15225 | Loss: 0.52680 | LR: 4.69e-06\n",
      "Step 15250 | Loss: 0.54433 | LR: 4.34e-06\n",
      "Step 15275 | Loss: 0.51840 | LR: 4.00e-06\n",
      "val loss: 0.5160\n",
      "Step 15300 | Loss: 0.54039 | LR: 3.68e-06\n",
      "Step 15325 | Loss: 0.50509 | LR: 3.37e-06\n",
      "Step 15350 | Loss: 0.51693 | LR: 3.08e-06\n",
      "Step 15375 | Loss: 0.52640 | LR: 2.80e-06\n",
      "val loss: 0.5175\n",
      "Step 15400 | Loss: 0.48835 | LR: 2.53e-06\n",
      "Step 15425 | Loss: 0.52488 | LR: 2.28e-06\n",
      "Step 15450 | Loss: 0.51984 | LR: 2.03e-06\n",
      "Step 15475 | Loss: 0.48535 | LR: 1.81e-06\n",
      "val loss: 0.5230\n",
      "Step 15500 | Loss: 0.51623 | LR: 1.59e-06\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0000.npz\n",
      "Step 15525 | Loss: 0.52383 | LR: 1.39e-06\n",
      "Step 15550 | Loss: 0.49101 | LR: 1.20e-06\n",
      "Step 15575 | Loss: 0.51964 | LR: 1.03e-06\n",
      "val loss: 0.5172\n",
      "Step 15600 | Loss: 0.54473 | LR: 8.71e-07\n",
      "Step 15625 | Loss: 0.52094 | LR: 7.25e-07\n",
      "Step 15650 | Loss: 0.53564 | LR: 5.92e-07\n",
      "Step 15675 | Loss: 0.54168 | LR: 4.73e-07\n",
      "val loss: 0.5202\n",
      "Step 15700 | Loss: 0.50608 | LR: 3.67e-07\n",
      "Step 15725 | Loss: 0.50325 | LR: 2.74e-07\n",
      "Step 15750 | Loss: 0.51609 | LR: 1.96e-07\n",
      "Step 15775 | Loss: 0.50109 | LR: 1.30e-07\n",
      "val loss: 0.5175\n",
      "Step 15800 | Loss: 0.57156 | LR: 7.86e-08\n",
      "Step 15825 | Loss: 0.52629 | LR: 4.04e-08\n",
      "loading /Users/djemec/data/jepa/v0_4/training/train/shard_k562e_train_0010.npz\n",
      "Step 15850 | Loss: 0.52946 | LR: 1.58e-08\n",
      "Step 15875 | Loss: 0.51448 | LR: 4.69e-09\n",
      "val loss: 0.5190\n",
      "=== Epoch 5 Done. Avg Loss: 0.52029 ===\n",
      "Saved final checkpoint: linear_decoder_ckpt_15884_final.pt\n"
     ]
    }
   ],
   "source": [
    "lossi = []\n",
    "val_lossi = []\n",
    "total_epoch_loss = 0\n",
    "\n",
    "decoder.train()\n",
    "\n",
    "for step in range(max_steps):\n",
    "    last_step = (step == max_steps - 1)\n",
    "\n",
    "    if step % 100 == 0 or last_step:\n",
    "        biojepa.eval()\n",
    "        with torch.no_grad():\n",
    "            val_loss_accum = 0.0\n",
    "            val_loss_steps = 10\n",
    "            for i in range(val_loss_steps):\n",
    "                xc, xct, xt, xtt, p_idx, p_mod, p_mode = val_loader.next_batch()\n",
    "                p_feats = input_bank[p_idx]\n",
    "                B, N = xc.shape\n",
    "\n",
    "                action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "                z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "                target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "                z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "                pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "                real_delta = xt - xc\n",
    "                loss = F.mse_loss(pred_delta, real_delta)\n",
    "                val_loss_accum += loss.item()\n",
    "\n",
    "            avg_val_loss = val_loss_accum / val_loss_steps\n",
    "            val_lossi.append(avg_val_loss)\n",
    "            print(f'val loss: {avg_val_loss:.4f}')\n",
    "        decoder.train()\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0 and not last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}.pt')\n",
    "\n",
    "    xc, xct, xt, xtt, p_idx, p_mod, p_mode = train_loader.next_batch()\n",
    "    p_feats = input_bank[p_idx]\n",
    "    B, N = xc.shape\n",
    "\n",
    "    with torch.no_grad():\n",
    "        z_context = biojepa.student(xc, xct, mask_idx=None)\n",
    "        action_latents = biojepa.composer(p_feats, p_mod, p_mode)\n",
    "        target_indices = torch.arange(N, device=DEVICE).expand(B, N)\n",
    "        z_pred_mu, _ = biojepa.predictor(z_context, action_latents, target_indices)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred_delta = decoder(z_pred_mu) - decoder(z_context)\n",
    "    real_delta = xt - xc\n",
    "    loss = F.mse_loss(pred_delta, real_delta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    lossi.append(loss.item())\n",
    "    total_epoch_loss += loss.item()\n",
    "\n",
    "    if step % 25 == 0:\n",
    "        print(f'Step {step} | Loss: {loss.item():.5f} | LR: {scheduler.get_last_lr()[0]:.2e}')\n",
    "\n",
    "    if step > 0 and (step + 1) % steps_per_epoch == 0:\n",
    "        avg_loss = total_epoch_loss / steps_per_epoch\n",
    "        print(f'=== Epoch {(step + 1) // steps_per_epoch} Done. Avg Loss: {avg_loss:.5f} ===')\n",
    "        total_epoch_loss = 0\n",
    "\n",
    "    if last_step:\n",
    "        torch.save({\n",
    "            'model': decoder.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'step': step\n",
    "        }, checkpoint_dir / f'linear_decoder_ckpt_{step}_final.pt')\n",
    "        print(f'Saved final checkpoint: linear_decoder_ckpt_{step}_final.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "plot-header",
   "metadata": {},
   "source": [
    "## Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "loss-plot",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "axes[0].plot(lossi, alpha=0.7)\n",
    "axes[0].set_xlabel('Step')\n",
    "axes[0].set_ylabel('Train Loss')\n",
    "axes[0].set_title('Training Loss')\n",
    "axes[0].set_yscale('log')\n",
    "\n",
    "axes[1].plot(val_lossi, 'o-', color='orange')\n",
    "axes[1].set_xlabel('Validation Check (every 100 steps)')\n",
    "axes[1].set_ylabel('Val Loss')\n",
    "axes[1].set_title('Validation Loss')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "summary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Final train loss: 0.5151\n",
      "Final val loss: 0.5190\n",
      "Checkpoint saved: /Users/djemec/data/jepa/v0_4/checkpoints/linear_decoder_ckpt_15884_final.pt\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print('='*60)\n",
    "print('TRAINING COMPLETE')\n",
    "print('='*60)\n",
    "print(f'Final train loss: {lossi[-1]:.4f}')\n",
    "print(f'Final val loss: {val_lossi[-1]:.4f}')\n",
    "print(f'Checkpoint saved: {checkpoint_dir / f\"linear_decoder_ckpt_{max_steps-1}_final.pt\"}')\n",
    "print('='*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
